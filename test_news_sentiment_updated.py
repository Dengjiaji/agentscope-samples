#!/usr/bin/env python3
"""
æµ‹è¯•æ›´æ–°åçš„ analyze_news_sentiment å·¥å…·
éªŒè¯å®ƒèƒ½æ ¹æ®ä¸åŒçš„APIè¿”å›ä¸åŒæ ¼å¼çš„æ•°æ®
"""

import os
import json
from dotenv import load_dotenv
from src.tools.analysis_tools_unified import analyze_news_sentiment

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()

def print_section(title: str):
    """æ‰“å°åˆ†éš”çº¿"""
    print("\n" + "=" * 80)
    print(f"ğŸ§ª {title}")
    print("=" * 80 + "\n")

def test_finnhub_api():
    """æµ‹è¯•ä½¿ç”¨ Finnhub API çš„æƒ…å†µ"""
    print_section("æµ‹è¯• Finnhub API - åº”è¿”å›æ–°é—»åˆ—è¡¨")
    
    ticker = "META"
    end_date = "2025-11-02"
    api_key = os.environ.get("FINNHUB_API_KEY")
    
    if not api_key:
        print("âŒ FINNHUB_API_KEY æœªé…ç½®")
        return
    
    print(f"ğŸ“Š å‚æ•°:")
    print(f"   è‚¡ç¥¨: {ticker}")
    print(f"   ç»“æŸæ—¥æœŸ: {end_date}")
    print(f"   API: Finnhub")
    
    result = analyze_news_sentiment(
        ticker=ticker,
        end_date=end_date,
        api_key=api_key,
        start_date=None
    )
    
    print(f"\nğŸ“‹ è¿”å›ç»“æœ:")
    print(f"   æ•°æ®æº: {result.get('data_source', 'unknown')}")
    print(f"   ä¿¡å·: {result.get('signal')}")
    
    if result.get('data_source') == 'finnhub':
        print(f"   æ€»æ–°é—»æ•°: {result.get('total_news_count')}")
        print(f"   è¿”å›æ–°é—»æ•°: {len(result.get('news_list', []))}")
        
        print(f"\nğŸ“° æ–°é—»åˆ—è¡¨:")
        for news in result.get('news_list', [])[:5]:  # åªæ˜¾ç¤ºå‰5æ¡
            print(f"\n   [{news['index']}] {news['title']}")
            print(f"       æ¥æº: {news['source']}")
            print(f"       æ—¥æœŸ: {news['date']}")
            print(f"       é“¾æ¥: {news['url'][:60]}...")
        
        print(f"\nğŸ’¡ è¯¦ç»†ä¿¡æ¯:")
        for detail in result.get('details', []):
            print(f"   - {detail}")
        
        print(f"\nğŸ” æ¨ç†:")
        print(f"   {result.get('reasoning')}")
        
        print("\nâœ… Finnhub API æµ‹è¯•é€šè¿‡ - è¿”å›äº†æ–°é—»åˆ—è¡¨æ ¼å¼")
    else:
        print(f"\nâš ï¸  é¢„æœŸè¿”å› finnhub æ ¼å¼ï¼Œä½†å¾—åˆ°: {result.get('data_source')}")
        print(f"\nå®Œæ•´ç»“æœ:")
        print(json.dumps(result, indent=2, ensure_ascii=False))

def test_financial_datasets_api():
    """æµ‹è¯•ä½¿ç”¨ Financial Datasets API çš„æƒ…å†µï¼ˆå¦‚æœæœ‰çš„è¯ï¼‰"""
    print_section("æµ‹è¯• Financial Datasets API - åº”è¿”å›æƒ…ç»ªç»Ÿè®¡")
    
    api_key = os.environ.get("FINANCIAL_DATASETS_API_KEY")
    
    if not api_key:
        print("â„¹ï¸  FINANCIAL_DATASETS_API_KEY æœªé…ç½®ï¼Œè·³è¿‡æ­¤æµ‹è¯•")
        print("   ï¼ˆè¿™æ˜¯æ­£å¸¸çš„ï¼Œå¦‚æœä½ åªä½¿ç”¨ Finnhub APIï¼‰")
        return
    
    ticker = "AAPL"
    end_date = "2025-11-02"
    
    print(f"ğŸ“Š å‚æ•°:")
    print(f"   è‚¡ç¥¨: {ticker}")
    print(f"   ç»“æŸæ—¥æœŸ: {end_date}")
    print(f"   API: Financial Datasets")
    
    # æ³¨æ„ï¼šè¿™é‡Œéœ€è¦ä¿®æ”¹ get_company_news çš„è°ƒç”¨æ–¹å¼æ¥æŒ‡å®š data_source
    # ç›®å‰çš„å®ç°ä¼šè‡ªåŠ¨æ£€æµ‹ï¼Œä½†æˆ‘ä»¬å¯ä»¥é€šè¿‡ç»“æœæ¥éªŒè¯
    result = analyze_news_sentiment(
        ticker=ticker,
        end_date=end_date,
        api_key=api_key,
        start_date=None
    )
    
    print(f"\nğŸ“‹ è¿”å›ç»“æœ:")
    print(f"   æ•°æ®æº: {result.get('data_source', 'unknown')}")
    print(f"   ä¿¡å·: {result.get('signal')}")
    
    if result.get('data_source') == 'financial_datasets':
        metrics = result.get('metrics', {})
        print(f"\nğŸ“Š æƒ…ç»ªç»Ÿè®¡:")
        print(f"   æ€»æ–°é—»æ•°: {metrics.get('total_articles')}")
        print(f"   æ­£é¢æ–°é—»: {metrics.get('positive_articles')} ({metrics.get('positive_ratio')}%)")
        print(f"   è´Ÿé¢æ–°é—»: {metrics.get('negative_articles')} ({metrics.get('negative_ratio')}%)")
        print(f"   ä¸­æ€§æ–°é—»: {metrics.get('neutral_articles')} ({metrics.get('neutral_ratio')}%)")
        
        print(f"\nğŸ’¡ è¯¦ç»†ä¿¡æ¯:")
        for detail in result.get('details', []):
            print(f"   - {detail}")
        
        print(f"\nğŸ” æ¨ç†:")
        print(f"   {result.get('reasoning')}")
        
        print("\nâœ… Financial Datasets API æµ‹è¯•é€šè¿‡ - è¿”å›äº†ç»Ÿè®¡æ ¼å¼")
    else:
        print(f"\nâš ï¸  é¢„æœŸè¿”å› financial_datasets æ ¼å¼ï¼Œä½†å¾—åˆ°: {result.get('data_source')}")
        print(f"\nå®Œæ•´ç»“æœ:")
        print(json.dumps(result, indent=2, ensure_ascii=False))

def test_json_serialization():
    """æµ‹è¯•è¿”å›ç»“æœæ˜¯å¦å¯ä»¥æ­£ç¡®åºåˆ—åŒ–ä¸ºJSON"""
    print_section("æµ‹è¯• JSON åºåˆ—åŒ–")
    
    ticker = "AMZN"
    end_date = "2025-11-02"
    api_key = os.environ.get("FINNHUB_API_KEY")
    
    if not api_key:
        print("âŒ FINNHUB_API_KEY æœªé…ç½®")
        return
    
    result = analyze_news_sentiment(
        ticker=ticker,
        end_date=end_date,
        api_key=api_key
    )
    
    try:
        json_str = json.dumps(result, indent=2, ensure_ascii=False)
        print("âœ… JSON åºåˆ—åŒ–æˆåŠŸ")
        print(f"\nğŸ“„ JSON å¤§å°: {len(json_str)} å­—ç¬¦")
        print(f"\nå‰500ä¸ªå­—ç¬¦:")
        print(json_str[:500])
        print("...")
    except Exception as e:
        print(f"âŒ JSON åºåˆ—åŒ–å¤±è´¥: {e}")

def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    print("\n" + "=" * 80)
    print("ğŸš€ analyze_news_sentiment å·¥å…·æ›´æ–°æµ‹è¯•")
    print("=" * 80)
    
    # æµ‹è¯• Finnhub API
    test_finnhub_api()
    
    # æµ‹è¯• Financial Datasets APIï¼ˆå¦‚æœé…ç½®äº†ï¼‰
    test_financial_datasets_api()
    
    # æµ‹è¯• JSON åºåˆ—åŒ–
    test_json_serialization()
    
    print("\n" + "=" * 80)
    print("âœ… æ‰€æœ‰æµ‹è¯•å®Œæˆ!")
    print("=" * 80)
    print("\nğŸ’¡ æ€»ç»“:")
    print("   - Finnhub API: è¿”å›æ–°é—»åˆ—è¡¨ï¼ˆæ ‡é¢˜ã€æ¥æºã€æ—¥æœŸã€é“¾æ¥ï¼‰")
    print("   - Financial Datasets API: è¿”å›æƒ…ç»ªç»Ÿè®¡ï¼ˆæ­£é¢/è´Ÿé¢/ä¸­æ€§æ¯”ä¾‹ï¼‰")
    print("   - LLM å¯ä»¥æ ¹æ® data_source å­—æ®µåˆ¤æ–­å¦‚ä½•å¤„ç†æ•°æ®")
    print()

if __name__ == "__main__":
    main()

