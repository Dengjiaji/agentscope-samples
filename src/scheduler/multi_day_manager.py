"""
å¤šæ—¥æŠ•èµ„ç­–ç•¥ç®¡ç†å™¨
åŸºäºŽInvestingAgentsé¡¹ç›®çš„è®¾è®¡æ¨¡å¼ï¼Œå®žçŽ°å¤šæ—¥å¾ªçŽ¯åˆ†æžå’ŒçŠ¶æ€æŒç»­åŒ–
"""

import os
import json
import pandas as pd
from datetime import datetime, timedelta
from dateutil.relativedelta import relativedelta
from typing import Dict, List, Optional, Any, Callable
from pathlib import Path

from src.tools.api import (
    get_price_data,
    get_prices,
    get_financial_metrics,
    get_insider_trades,
    get_company_news,
)


class MultiDayManager:
    """å¤šæ—¥æŠ•èµ„ç­–ç•¥ç®¡ç†å™¨"""
    
    def __init__(
        self,
        engine,  # AdvancedInvestmentAnalysisEngineå®žä¾‹
        base_output_dir: str = "/root/wuyue.wy/Project/IA/analysis_results_logs/",
        max_communication_cycles: int = 3,
        prefetch_data: bool = True
    ):
        """
        åˆå§‹åŒ–å¤šæ—¥ç®¡ç†å™¨
        
        Args:
            engine: æŠ•èµ„åˆ†æžå¼•æ“Žå®žä¾‹
            base_output_dir: åŸºç¡€è¾“å‡ºç›®å½•
            max_communication_cycles: æ¯æ—¥æœ€å¤§æ²Ÿé€šè½®æ•°
            prefetch_data: æ˜¯å¦é¢„å–æ•°æ®
        """
        self.engine = engine
        self.base_output_dir = base_output_dir
        self.max_communication_cycles = max_communication_cycles
        self.prefetch_data = prefetch_data
        
        # çŠ¶æ€è¿½è¸ª
        self.session_id = None
        self.daily_results = []
        self.analyst_memory_state = None
        self.communication_logs_state = None
        self.portfolio_state = None
        
        # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
        os.makedirs(base_output_dir, exist_ok=True)
    
    def create_session_id(self) -> str:
        """ç”Ÿæˆä¼šè¯ID"""
        return f"multi_day_session_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
    
    def prefetch_all_data(self, tickers: List[str], start_date: str, end_date: str):
        """é¢„å–å¤šæ—¥åˆ†æžæ‰€éœ€çš„æ‰€æœ‰æ•°æ®"""
        if not self.prefetch_data:
            return
            
        print(f"\nðŸ“¦ é¢„å–æ•°æ®ä¸­ ({start_date} åˆ° {end_date})...")
        
        # æ‰©å±•æ•°æ®èŽ·å–èŒƒå›´ï¼Œç¡®ä¿æœ‰è¶³å¤Ÿçš„åŽ†å²æ•°æ®
        end_date_dt = datetime.strptime(end_date, "%Y-%m-%d")
        extended_start_dt = end_date_dt - relativedelta(years=1)
        extended_start = extended_start_dt.strftime("%Y-%m-%d")
        
        for ticker in tickers:
            try:
                # é¢„å–ä»·æ ¼æ•°æ®
                get_prices(ticker, extended_start, end_date)
                
                # é¢„å–è´¢åŠ¡æŒ‡æ ‡
                get_financial_metrics(ticker, end_date, limit=20)
                
                # é¢„å–å†…éƒ¨äº¤æ˜“æ•°æ®
                get_insider_trades(ticker, end_date, start_date=start_date, limit=1000)
                
                # é¢„å–æ–°é—»æ•°æ®
                get_company_news(ticker, end_date, start_date=start_date, limit=1000)
                
            except Exception as e:
                print(f"âš ï¸ é¢„å– {ticker} æ•°æ®æ—¶å‡ºé”™: {e}")
                
        print("âœ… æ•°æ®é¢„å–å®Œæˆ")
    
    def save_daily_state(self, date_str: str, results: Dict[str, Any], state: Dict[str, Any]):
        """ä¿å­˜å•æ—¥çŠ¶æ€åˆ°æ–‡ä»¶"""
        daily_file = f"{self.base_output_dir}/{self.session_id}_daily_{date_str}.json"
        
        # ç¡®ä¿é€šä¿¡æ—¥å¿—åŒ…å«æ‰€æœ‰å¿…è¦å­—æ®µ
        comm_logs = state.get("data", {}).get("communication_logs", {})
        complete_comm_logs = {
            "decisions": comm_logs.get("decisions", []),
            "private_chats": comm_logs.get("private_chats", []),
            "meetings": comm_logs.get("meetings", []),
            "notifications": comm_logs.get("notifications", []),
            "communication_decisions": comm_logs.get("communication_decisions", [])
        }
        
        daily_state = {
            "session_id": self.session_id,
            "date": date_str,
            "timestamp": datetime.now().isoformat(),
            "results": results,
            "analyst_memory": state.get("data", {}).get("analyst_memory"),
            "communication_logs": complete_comm_logs,
            "portfolio_snapshot": state.get("data", {}).get("portfolio"),
            "metadata": state.get("metadata", {})
        }
        
        try:
            with open(daily_file, 'w', encoding='utf-8') as f:
                json.dump(daily_state, f, ensure_ascii=False, indent=2, default=str)
        except Exception as e:
            print(f"âš ï¸ ä¿å­˜æ—¥çŠ¶æ€å¤±è´¥ {date_str}: {e}")
    
    def load_previous_state(self, date_str: str) -> Optional[Dict[str, Any]]:
        """åŠ è½½å‰ä¸€æ—¥çš„çŠ¶æ€"""
        # æŸ¥æ‰¾æœ€è¿‘çš„çŠ¶æ€æ–‡ä»¶
        pattern = f"{self.session_id}_daily_*.json"
        daily_files = list(Path(self.base_output_dir).glob(pattern))
        
        if not daily_files:
            return None
            
        # æŒ‰æ—¥æœŸæŽ’åºï¼ŒèŽ·å–æœ€æ–°çš„
        daily_files.sort(key=lambda x: x.name)
        latest_file = daily_files[-1]
        
        try:
            with open(latest_file, 'r', encoding='utf-8') as f:
                return json.load(f)
        except Exception as e:
            print(f"âš ï¸ åŠ è½½å‰çŠ¶æ€å¤±è´¥: {e}")
            return None
    
    def restore_state_to_engine(self, previous_state: Dict[str, Any], current_state: Dict[str, Any]):
        """å°†å‰ä¸€æ—¥çŠ¶æ€æ¢å¤åˆ°å½“å‰å¼•æ“ŽçŠ¶æ€"""
        if not previous_state:
            return
            
        # æ¢å¤åˆ†æžå¸ˆè®°å¿†
        if previous_state.get("analyst_memory"):
            current_state["data"]["analyst_memory"] = previous_state["analyst_memory"]
        
        # æ¢å¤æ²Ÿé€šæ—¥å¿—ï¼ˆç»§æ‰¿åŽ†å²å†³ç­–ä¸Šä¸‹æ–‡ï¼‰
        if previous_state.get("communication_logs"):
            # ä¿ç•™åŽ†å²æ²Ÿé€šè®°å½•ä½œä¸ºä¸Šä¸‹æ–‡ï¼Œç¡®ä¿æ‰€æœ‰å¿…è¦å­—æ®µéƒ½å­˜åœ¨
            current_state["data"]["communication_logs"] = {
                "decisions": previous_state["communication_logs"].get("decisions", []),
                "private_chats": previous_state["communication_logs"].get("private_chats", []),
                "meetings": previous_state["communication_logs"].get("meetings", []),
                "notifications": previous_state["communication_logs"].get("notifications", []),
                "communication_decisions": previous_state["communication_logs"].get("communication_decisions", [])
            }
        else:
            # å¦‚æžœæ²¡æœ‰åŽ†å²è®°å½•ï¼Œç¡®ä¿åˆ›å»ºå®Œæ•´çš„é€šä¿¡æ—¥å¿—ç»“æž„
            if "communication_logs" not in current_state["data"]:
                current_state["data"]["communication_logs"] = {}
            
            # ç¡®ä¿æ‰€æœ‰å¿…è¦çš„å­å­—æ®µéƒ½å­˜åœ¨
            comm_logs = current_state["data"]["communication_logs"]
            if "decisions" not in comm_logs:
                comm_logs["decisions"] = []
            if "private_chats" not in comm_logs:
                comm_logs["private_chats"] = []
            if "meetings" not in comm_logs:
                comm_logs["meetings"] = []
            if "notifications" not in comm_logs:
                comm_logs["notifications"] = []
            if "communication_decisions" not in comm_logs:
                comm_logs["communication_decisions"] = []
        
        # æ¢å¤æŠ•èµ„ç»„åˆçŠ¶æ€ï¼ˆå…³é”®ï¼šä¿æŒä»“ä½è¿žç»­æ€§ï¼‰
        if previous_state.get("portfolio_snapshot"):
            current_state["data"]["portfolio"] = previous_state["portfolio_snapshot"]
            
        print(f"âœ… å·²æ¢å¤å‰ä¸€äº¤æ˜“æ—¥çŠ¶æ€")
    
    def run_multi_day_strategy(
        self,
        tickers: List[str],
        start_date: str,
        end_date: str,
        enable_communications: bool = True,
        enable_notifications: bool = True,
        show_reasoning: bool = False,
        progress_callback: Optional[Callable] = None
    ) -> Dict[str, Any]:
        """
        è¿è¡Œå¤šæ—¥æŠ•èµ„ç­–ç•¥
        
        Args:
            tickers: è‚¡ç¥¨ä»£ç åˆ—è¡¨
            start_date: å¼€å§‹æ—¥æœŸ (YYYY-MM-DD)
            end_date: ç»“æŸæ—¥æœŸ (YYYY-MM-DD)
            enable_communications: æ˜¯å¦å¯ç”¨æ²Ÿé€šæœºåˆ¶
            enable_notifications: æ˜¯å¦å¯ç”¨é€šçŸ¥æœºåˆ¶
            show_reasoning: æ˜¯å¦æ˜¾ç¤ºè¯¦ç»†æŽ¨ç†è¿‡ç¨‹
            progress_callback: è¿›åº¦å›žè°ƒå‡½æ•°
            
        Returns:
            å¤šæ—¥åˆ†æžæ±‡æ€»ç»“æžœ
        """
        
        # åˆå§‹åŒ–ä¼šè¯
        self.session_id = self.create_session_id()
        print(f"ðŸš€ å¼€å§‹å¤šæ—¥ç­–ç•¥åˆ†æž (ä¼šè¯ID: {self.session_id})")
        print(f"ðŸ“… æ—¶é—´èŒƒå›´: {start_date} åˆ° {end_date}")
        print(f"ðŸ“Š åˆ†æžæ ‡çš„: {', '.join(tickers)}")
        
        # é¢„å–æ•°æ®
        if self.prefetch_data:
            self.prefetch_all_data(tickers, start_date, end_date)
        
        # ç”Ÿæˆäº¤æ˜“æ—¥åºåˆ—ï¼ˆè·³è¿‡å‘¨æœ«ï¼‰
        trading_dates = pd.date_range(start_date, end_date, freq="B")
        
        if len(trading_dates) == 0:
            raise ValueError(f"æŒ‡å®šæ—¥æœŸèŒƒå›´å†…æ— äº¤æ˜“æ—¥: {start_date} åˆ° {end_date}")
        
        print(f"ðŸ“ˆ å…± {len(trading_dates)} ä¸ªäº¤æ˜“æ—¥å¾…åˆ†æž")
        
        # åˆå§‹åŒ–æ±‡æ€»ç»Ÿè®¡
        total_days = len(trading_dates)
        successful_days = 0
        failed_days = 0
        self.daily_results = []
        
        # é€æ—¥æ‰§è¡Œåˆ†æž
        for i, current_date in enumerate(trading_dates):
            current_date_str = current_date.strftime("%Y-%m-%d")
            print(f"\n{'='*60}")
            print(f"ðŸ“… ç¬¬ {i+1}/{total_days} æ—¥åˆ†æž: {current_date_str}")
            print(f"{'='*60}")
            
            # å‘é€è¿›åº¦æ›´æ–°
            if progress_callback:
                progress_callback({
                    "type": "daily_progress",
                    "current_date": current_date_str,
                    "progress": (i + 1) / total_days,
                    "day_number": i + 1,
                    "total_days": total_days
                })
            
            try:
                # è®¾ç½®å½“æ—¥åˆ†æžçš„æ—¶é—´çª—å£ï¼ˆå›žçœ‹30å¤©æ•°æ®ï¼‰
                lookback_start = (current_date - timedelta(days=30)).strftime("%Y-%m-%d")
                
                # åˆ›å»ºå½“æ—¥åˆ†æžçŠ¶æ€
                daily_state = self.engine.create_base_state(tickers, lookback_start, current_date_str)
                daily_state["metadata"]["communication_enabled"] = enable_communications
                daily_state["metadata"]["notifications_enabled"] = enable_notifications
                daily_state["metadata"]["show_reasoning"] = show_reasoning
                daily_state["metadata"]["max_communication_cycles"] = self.max_communication_cycles
                daily_state["metadata"]["session_id"] = self.session_id
                daily_state["metadata"]["trading_date"] = current_date_str
                daily_state["metadata"]["day_number"] = i + 1
                
                # è®¾ç½®å½“æ—¥è¾“å‡ºæ–‡ä»¶
                daily_output_file = f"{self.base_output_dir}/{self.session_id}_daily_{current_date_str}.json"
                daily_state["metadata"]["output_file"] = daily_output_file
                
                # æ¢å¤å‰ä¸€æ—¥çŠ¶æ€ï¼ˆå¦‚æžœæœ‰ï¼‰
                if i > 0:
                    previous_state = self.load_previous_state(current_date_str)
                    self.restore_state_to_engine(previous_state, daily_state)
                
                # æ‰§è¡Œå½“æ—¥å®Œæ•´åˆ†æžæµç¨‹
                daily_results = self.engine.run_full_analysis_with_communications(
                    tickers=tickers,
                    start_date=lookback_start,
                    end_date=current_date_str,
                    enable_communications=enable_communications,
                    enable_notifications=enable_notifications,
                    state=daily_state
                )
                
                # ä¿å­˜å½“æ—¥çŠ¶æ€
                self.save_daily_state(current_date_str, daily_results, daily_state)
                
                # è®°å½•æˆåŠŸ
                successful_days += 1
                self.daily_results.append({
                    "date": current_date_str,
                    "status": "success",
                    "results": daily_results,
                    "output_file": daily_output_file
                })
                
                print(f"âœ… {current_date_str} åˆ†æžå®Œæˆ")
                
                # å‘é€å•æ—¥ç»“æžœ
                if progress_callback:
                    progress_callback({
                        "type": "daily_result",
                        "date": current_date_str,
                        "status": "success",
                        "data": daily_results
                    })
                
            except Exception as e:
                print(f"âŒ {current_date_str} åˆ†æžå¤±è´¥: {str(e)}")
                failed_days += 1
                self.daily_results.append({
                    "date": current_date_str,
                    "status": "failed",
                    "error": str(e),
                    "output_file": None
                })
                
                # å‘é€å¤±è´¥é€šçŸ¥
                if progress_callback:
                    progress_callback({
                        "type": "daily_result",
                        "date": current_date_str,
                        "status": "failed",
                        "error": str(e)
                    })
                
                # ä¸¥é‡é”™è¯¯æ—¶å¯é€‰æ‹©åœæ­¢
                # continue  # ç»§ç»­ä¸‹ä¸€æ—¥
        
        # ç”Ÿæˆå¤šæ—¥æ±‡æ€»æŠ¥å‘Š
        summary_results = self.generate_multi_day_summary()
        
        print(f"\nðŸ å¤šæ—¥ç­–ç•¥åˆ†æžå®Œæˆ!")
        print(f"âœ… æˆåŠŸ: {successful_days} æ—¥")
        print(f"âŒ å¤±è´¥: {failed_days} æ—¥")
        print(f"ðŸ“Š æˆåŠŸçŽ‡: {successful_days/total_days*100:.1f}%")
        
        return summary_results
    
    def generate_multi_day_summary(self) -> Dict[str, Any]:
        """ç”Ÿæˆå¤šæ—¥æ±‡æ€»æŠ¥å‘Š"""
        summary_file = f"{self.base_output_dir}/{self.session_id}_summary.json"
        
        # è®¡ç®—æ±‡æ€»ç»Ÿè®¡
        successful_results = [r for r in self.daily_results if r["status"] == "success"]
        
        # æå–å…³é”®æŒ‡æ ‡æ—¶é—´åºåˆ—
        portfolio_values = []
        communication_stats = []
        
        for daily_result in successful_results:
            date = daily_result["date"]
            results = daily_result.get("results", {})
            
            # æŠ•èµ„ç»„åˆä»·å€¼å˜åŒ–
            if "portfolio_management_results" in results:
                pm_results = results["portfolio_management_results"]
                portfolio_values.append({
                    "date": date,
                    "total_value": pm_results.get("portfolio_summary", {}).get("total_value", 0),
                    "cash": pm_results.get("portfolio_summary", {}).get("cash", 0),
                    "positions_value": pm_results.get("portfolio_summary", {}).get("positions_value", 0)
                })
            
            # æ²Ÿé€šç»Ÿè®¡
            if "communication_logs" in results:
                comm_logs = results["communication_logs"]
                communication_stats.append({
                    "date": date,
                    "decisions_count": len(comm_logs.get("decisions", [])),
                    "private_chats_count": len(comm_logs.get("private_chats", [])),
                    "meetings_count": len(comm_logs.get("meetings", [])),
                    "notifications_count": len(comm_logs.get("notifications", []))
                })
        
        # ç”Ÿæˆæ±‡æ€»ç»“æžœ
        summary = {
            "session_id": self.session_id,
            "summary_timestamp": datetime.now().isoformat(),
            "period": {
                "start_date": self.daily_results[0]["date"] if self.daily_results else None,
                "end_date": self.daily_results[-1]["date"] if self.daily_results else None,
                "total_days": len(self.daily_results),
                "successful_days": len(successful_results),
                "failed_days": len([r for r in self.daily_results if r["status"] == "failed"])
            },
            "daily_results": self.daily_results,
            "time_series": {
                "portfolio_values": portfolio_values,
                "communication_stats": communication_stats
            },
            "performance_analysis": self.calculate_performance_metrics(portfolio_values)
        }
        
        # ä¿å­˜æ±‡æ€»æ–‡ä»¶
        try:
            with open(summary_file, 'w', encoding='utf-8') as f:
                json.dump(summary, f, ensure_ascii=False, indent=2, default=str)
            print(f"ðŸ“„ å¤šæ—¥æ±‡æ€»æŠ¥å‘Šå·²ä¿å­˜: {summary_file}")
        except Exception as e:
            print(f"âš ï¸ ä¿å­˜æ±‡æ€»æŠ¥å‘Šå¤±è´¥: {e}")
        
        return summary
    
    def calculate_performance_metrics(self, portfolio_values: List[Dict[str, Any]]) -> Dict[str, Any]:
        """è®¡ç®—å¤šæ—¥ç»©æ•ˆæŒ‡æ ‡"""
        if len(portfolio_values) < 2:
            return {"error": "æ•°æ®ä¸è¶³ï¼Œæ— æ³•è®¡ç®—ç»©æ•ˆæŒ‡æ ‡"}
        
        try:
            # è½¬æ¢ä¸ºDataFrameä¾¿äºŽè®¡ç®—
            df = pd.DataFrame(portfolio_values)
            df['date'] = pd.to_datetime(df['date'])
            df = df.set_index('date').sort_index()
            
            # è®¡ç®—æ”¶ç›ŠçŽ‡
            df['daily_return'] = df['total_value'].pct_change()
            df['cumulative_return'] = (df['total_value'] / df['total_value'].iloc[0] - 1) * 100
            
            # åŸºç¡€æŒ‡æ ‡
            total_return = df['cumulative_return'].iloc[-1]
            volatility = df['daily_return'].std() * (252 ** 0.5) * 100  # å¹´åŒ–æ³¢åŠ¨çŽ‡
            
            # æœ€å¤§å›žæ’¤
            rolling_max = df['total_value'].cummax()
            drawdown = (df['total_value'] - rolling_max) / rolling_max * 100
            max_drawdown = drawdown.min()
            
            # å¤æ™®æ¯”çŽ‡ï¼ˆå‡è®¾æ— é£Žé™©åˆ©çŽ‡4%ï¼‰
            excess_returns = df['daily_return'] - 0.04/252
            sharpe_ratio = excess_returns.mean() / excess_returns.std() * (252 ** 0.5) if excess_returns.std() > 0 else 0
            
            return {
                "total_return_pct": round(total_return, 2),
                "annualized_volatility_pct": round(volatility, 2),
                "max_drawdown_pct": round(max_drawdown, 2),
                "sharpe_ratio": round(sharpe_ratio, 3),
                "total_trading_days": len(df),
                "start_value": df['total_value'].iloc[0],
                "end_value": df['total_value'].iloc[-1]
            }
            
        except Exception as e:
            return {"error": f"ç»©æ•ˆè®¡ç®—å¤±è´¥: {str(e)}"}
