"""
å¤šæ—¥æŠ•èµ„ç­–ç•¥ç®¡ç†å™¨
åŸºäºInvestingAgentsé¡¹ç›®çš„è®¾è®¡æ¨¡å¼ï¼Œå®ç°å¤šæ—¥å¾ªç¯åˆ†æå’ŒçŠ¶æ€æŒç»­åŒ–
"""

import os
import json
import pandas as pd
from datetime import datetime, timedelta
from dateutil.relativedelta import relativedelta
from typing import Dict, List, Optional, Any, Callable
from pathlib import Path
import pdb
# å°è¯•å¯¼å…¥ç¾å›½äº¤æ˜“æ—¥å†åŒ…
try:
    import pandas_market_calendars as mcal
    US_TRADING_CALENDAR_AVAILABLE = True
except ImportError:
    try:
        import exchange_calendars as xcals
        US_TRADING_CALENDAR_AVAILABLE = True
    except ImportError:
        US_TRADING_CALENDAR_AVAILABLE = False

from src.tools.api import (
    get_price_data,
    get_prices,
    get_financial_metrics,
    get_insider_trades,
    get_company_news,
)
from src.communication.analyst_memory_mem0 import memory_manager_mem0_adapter as memory_manager
from src.okr.okr_manager import OKRManager


class MultiDayManager:
    """å¤šæ—¥æŠ•èµ„ç­–ç•¥ç®¡ç†å™¨"""
    
    def __init__(
        self,
        engine,  # AdvancedInvestmentAnalysisEngineå®ä¾‹
        base_output_dir: str = "/root/wuyue.wy/Project/IA/analysis_results_logs/",
        max_communication_cycles: int = 3,
        prefetch_data: bool = True,
        okr_enabled: bool = False,
        custom_session_id: str = None,
        data_source: str = "finnhub"
    ):
        """
        åˆå§‹åŒ–å¤šæ—¥ç®¡ç†å™¨
        
        Args:
            engine: æŠ•èµ„åˆ†æå¼•æ“å®ä¾‹
            base_output_dir: åŸºç¡€è¾“å‡ºç›®å½•
            max_communication_cycles: æ¯æ—¥æœ€å¤§æ²Ÿé€šè½®æ•°
            prefetch_data: æ˜¯å¦é¢„å–æ•°æ®
            okr_enabled: æ˜¯å¦å¯ç”¨OKR
            custom_session_id: è‡ªå®šä¹‰ä¼šè¯ID
            data_source: æ•°æ®æº ("finnhub" æˆ– "financial_datasets", é»˜è®¤: "finnhub")
        """
        self.engine = engine
        self.base_output_dir = base_output_dir
        self.max_communication_cycles = max_communication_cycles
        self.prefetch_data = prefetch_data
        self.okr_enabled = okr_enabled
        self.data_source = data_source
        
        # çŠ¶æ€è¿½è¸ª
        self.session_id = custom_session_id
        self.daily_results = []
        self.analyst_memory_state = None
        self.communication_logs_state = None
        self.okr_manager = None  # å°†åœ¨éœ€è¦æ—¶åˆå§‹åŒ–
        
        # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
        os.makedirs(base_output_dir, exist_ok=True)
    
    def create_session_id(self) -> str:
        """ç”Ÿæˆä¼šè¯ID"""
        return f"multi_day_session_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
    
    def get_us_trading_dates(self, start_date: str, end_date: str) -> pd.DatetimeIndex:
        """
        è·å–ç¾å›½è‚¡å¸‚äº¤æ˜“æ—¥åºåˆ—
        
        Args:
            start_date: å¼€å§‹æ—¥æœŸ (YYYY-MM-DD)
            end_date: ç»“æŸæ—¥æœŸ (YYYY-MM-DD)
            
        Returns:
            pd.DatetimeIndex: äº¤æ˜“æ—¥åºåˆ—
        """
        if US_TRADING_CALENDAR_AVAILABLE:
            try:
                # ä¼˜å…ˆå°è¯•ä½¿ç”¨ pandas_market_calendars
                if 'mcal' in globals():
                    nyse = mcal.get_calendar('NYSE')
                    trading_dates = nyse.valid_days(start_date=start_date, end_date=end_date)
                    print(f"âœ… ä½¿ç”¨NYSEäº¤æ˜“æ—¥å† (pandas_market_calendars)")
                    return trading_dates
                
                # å¤‡é€‰ï¼šä½¿ç”¨ exchange_calendars
                elif 'xcals' in globals():
                    nyse = xcals.get_calendar('XNYS')  # NYSEçš„ISOä»£ç 
                    trading_dates = nyse.sessions_in_range(start_date, end_date)
                    print(f"âœ… ä½¿ç”¨NYSEäº¤æ˜“æ—¥å† (exchange_calendars)")
                    return trading_dates
                    
            except Exception as e:
                print(f"âš ï¸ ç¾å›½äº¤æ˜“æ—¥å†è·å–å¤±è´¥ï¼Œå›é€€åˆ°ç®€å•å·¥ä½œæ—¥: {e}")
        else:
            print(f"âš ï¸ æœªå®‰è£…ç¾å›½äº¤æ˜“æ—¥å†åŒ…ï¼Œä½¿ç”¨ç®€å•å·¥ä½œæ—¥")
            print(f"   å»ºè®®å®‰è£…: pip install pandas_market_calendars")
        
        # å›é€€åˆ°åŸæ¥çš„ç®€å•å·¥ä½œæ—¥æ–¹æ³•
        return pd.date_range(start_date, end_date, freq="B")
    
    def prefetch_all_data(self, tickers: List[str], start_date: str, end_date: str):
        """é¢„å–å¤šæ—¥åˆ†ææ‰€éœ€çš„æ‰€æœ‰æ•°æ®"""
        if not self.prefetch_data:
            return
            
        print(f"\né¢„å–æ•°æ®ä¸­ ({start_date} åˆ° {end_date})...")
        
        # æ‰©å±•æ•°æ®è·å–èŒƒå›´ï¼Œç¡®ä¿æœ‰è¶³å¤Ÿçš„å†å²æ•°æ®
        end_date_dt = datetime.strptime(end_date, "%Y-%m-%d")
        extended_start_dt = end_date_dt - relativedelta(years=1)
        extended_start = extended_start_dt.strftime("%Y-%m-%d")
        
        for ticker in tickers:
            try:
                # é¢„å–ä»·æ ¼æ•°æ®
                get_prices(ticker, extended_start, end_date)
                
                # é¢„å–è´¢åŠ¡æŒ‡æ ‡
                get_financial_metrics(ticker, end_date, limit=20)
                
                # é¢„å–å†…éƒ¨äº¤æ˜“æ•°æ®
                get_insider_trades(ticker, end_date, start_date=start_date, limit=1000)
                
                # é¢„å–æ–°é—»æ•°æ®
                get_company_news(ticker, end_date, start_date=start_date, limit=1000)
                
            except Exception as e:
                print(f"è­¦å‘Š: é¢„å– {ticker} æ•°æ®æ—¶å‡ºé”™: {e}")
                
        print("æ•°æ®é¢„å–å®Œæˆ")
    
    def save_daily_state(self, date_str: str, results: Dict[str, Any], state: Dict[str, Any]):
        """ä¿å­˜å•æ—¥çŠ¶æ€åˆ°æ–‡ä»¶"""
        daily_file = f"{self.base_output_dir}/{self.session_id}_daily_{date_str}.json"
        
        # ç¡®ä¿é€šä¿¡æ—¥å¿—åŒ…å«æ‰€æœ‰å¿…è¦å­—æ®µ
        comm_logs = state.get("data", {}).get("communication_logs", {})
        complete_comm_logs = {
            "decisions": comm_logs.get("decisions", []),
            "private_chats": comm_logs.get("private_chats", []),
            "meetings": comm_logs.get("meetings", []),
            "notifications": comm_logs.get("notifications", []),
            "communication_decisions": comm_logs.get("communication_decisions", [])
        }
        
        daily_state = {
            "session_id": self.session_id,
            "date": date_str,
            "timestamp": datetime.now().isoformat(),
            "results": results,
            "analyst_memory": state.get("data", {}).get("analyst_memory"),
            "communication_logs": complete_comm_logs,
            "metadata": state.get("metadata", {}),
            "okr_state": state.get("data", {}).get("okr_state"),
            "portfolio": state.get("data", {}).get("portfolio")  # ä¿å­˜æŠ•èµ„ç»„åˆçŠ¶æ€
        }
        
        try:
            with open(daily_file, 'w', encoding='utf-8') as f:
                json.dump(daily_state, f, ensure_ascii=False, indent=2, default=str)
        except Exception as e:
            print(f"è­¦å‘Š: ä¿å­˜æ—¥çŠ¶æ€å¤±è´¥ {date_str}: {e}")
    
    def load_previous_state(self, date_str: str) -> Optional[Dict[str, Any]]:
        """åŠ è½½å‰ä¸€æ—¥çš„çŠ¶æ€"""
        # æŸ¥æ‰¾æœ€è¿‘çš„çŠ¶æ€æ–‡ä»¶
        pattern = f"{self.session_id}_daily_*.json"
        daily_files = list(Path(self.base_output_dir).glob(pattern))
        
        if not daily_files:
            return None
            
        # æŒ‰æ—¥æœŸæ’åºï¼Œè·å–æœ€æ–°çš„
        daily_files.sort(key=lambda x: x.name)
        latest_file = daily_files[-1]
        
        try:
            with open(latest_file, 'r', encoding='utf-8') as f:
                return json.load(f)
        except Exception as e:
            print(f"è­¦å‘Š: åŠ è½½å‰çŠ¶æ€å¤±è´¥: {e}")
            return None
    
    def restore_state_to_engine(self, previous_state: Dict[str, Any], current_state: Dict[str, Any]):
        """å°†å‰ä¸€æ—¥PortfolioçŠ¶æ€æ¢å¤åˆ°å½“å‰å¼•æ“çŠ¶æ€"""
        if not previous_state:
            return
        
        # åªæ¢å¤æŠ•èµ„ç»„åˆçŠ¶æ€ï¼ˆPortfolioæ¨¡å¼ï¼‰
        if previous_state.get("portfolio"):
            current_state["data"]["portfolio"] = previous_state["portfolio"]
            positions_count = len([p for p in previous_state["portfolio"].get("positions", {}).values() 
                                  if p.get("long", 0) > 0 or p.get("short", 0) > 0])
            print(f"âœ… å·²æ¢å¤PortfolioçŠ¶æ€ - ç°é‡‘: ${previous_state['portfolio'].get('cash', 0):,.2f}, æŒä»“æ•°: {positions_count}")

    def _init_okr_manager(self):
        """åˆå§‹åŒ–OKRç®¡ç†å™¨"""
        if self.okr_manager is None and self.okr_enabled:
            analyst_ids = list(self.engine.core_analysts.keys())
            self.okr_manager = OKRManager(analyst_ids)
            print(f"OKRç®¡ç†å™¨å·²åˆå§‹åŒ–ï¼Œç®¡ç† {len(analyst_ids)} ä¸ªåˆ†æå¸ˆ")

    
    def run_multi_day_strategy(
        self,
        tickers: List[str],
        start_date: str,
        end_date: str,
        enable_communications: bool = True,
        enable_notifications: bool = True,
        show_reasoning: bool = False,
        progress_callback: Optional[Callable] = None,
        mode: str = "signal",
        **kwargs
    ) -> Dict[str, Any]:
        """
        è¿è¡Œå¤šæ—¥æŠ•èµ„ç­–ç•¥
        
        Args:
            tickers: è‚¡ç¥¨ä»£ç åˆ—è¡¨
            start_date: å¼€å§‹æ—¥æœŸ (YYYY-MM-DD)
            end_date: ç»“æŸæ—¥æœŸ (YYYY-MM-DD)
            enable_communications: æ˜¯å¦å¯ç”¨æ²Ÿé€šæœºåˆ¶
            enable_notifications: æ˜¯å¦å¯ç”¨é€šçŸ¥æœºåˆ¶
            show_reasoning: æ˜¯å¦æ˜¾ç¤ºè¯¦ç»†æ¨ç†è¿‡ç¨‹
            progress_callback: è¿›åº¦å›è°ƒå‡½æ•°
            mode: è¿è¡Œæ¨¡å¼ ("signal" æˆ– "portfolio")
            **kwargs: å…¶ä»–å‚æ•°
            
        Returns:
            å¤šæ—¥åˆ†ææ±‡æ€»ç»“æœ
        """
        
        # åˆå§‹åŒ–ä¼šè¯
        if self.session_id is None:
            self.session_id = self.create_session_id()
        print(f"å¼€å§‹å¤šæ—¥ç­–ç•¥åˆ†æ (ä¼šè¯ID: {self.session_id})")
        print(f"æ—¶é—´èŒƒå›´: {start_date} åˆ° {end_date}")
        print(f"åˆ†ææ ‡çš„: {', '.join(tickers)}")
        
        # é¢„å–æ•°æ®
        if self.prefetch_data:
            self.prefetch_all_data(tickers, start_date, end_date)
        
        # ç”Ÿæˆç¾å›½è‚¡å¸‚äº¤æ˜“æ—¥åºåˆ—ï¼ˆè€ƒè™‘èŠ‚å‡æ—¥ï¼‰
        trading_dates = self.get_us_trading_dates(start_date, end_date)
        
        if len(trading_dates) == 0:
            raise ValueError(f"æŒ‡å®šæ—¥æœŸèŒƒå›´å†…æ— äº¤æ˜“æ—¥: {start_date} åˆ° {end_date}")
        
        print(f"å…± {len(trading_dates)} ä¸ªäº¤æ˜“æ—¥å¾…åˆ†æ")
        
        # åˆå§‹åŒ–æ±‡æ€»ç»Ÿè®¡
        total_days = len(trading_dates)
        successful_days = 0
        failed_days = 0
        self.daily_results = []
        
        # é€æ—¥æ‰§è¡Œåˆ†æ
        for i, current_date in enumerate(trading_dates):
            current_date_str = current_date.strftime("%Y-%m-%d")
            # print(f"\n{'='*60}")
            # print(f"ç¬¬ {i+1}/{total_days} æ—¥åˆ†æ: {current_date_str}")
            # print(f"{'='*60}")
            
            # å‘é€è¿›åº¦æ›´æ–°
            if progress_callback:
                progress_callback({
                    "type": "daily_progress",
                    "current_date": current_date_str,
                    "progress": (i + 1) / total_days,
                    "day_number": i + 1,
                    "total_days": total_days
                })
            
            try:
                # è®¾ç½®å½“æ—¥åˆ†æçš„æ—¶é—´çª—å£ï¼ˆå›çœ‹30å¤©æ•°æ®ï¼‰
                lookback_start = (current_date - timedelta(days=30)).strftime("%Y-%m-%d")
                
                # åˆ›å»ºå½“æ—¥åˆ†æçŠ¶æ€
                daily_state = self.engine.create_base_state(tickers, lookback_start, current_date_str)
                daily_state["metadata"]["communication_enabled"] = enable_communications
                daily_state["metadata"]["notifications_enabled"] = enable_notifications
                daily_state["metadata"]["show_reasoning"] = show_reasoning
                daily_state["metadata"]["max_communication_cycles"] = self.max_communication_cycles
                daily_state["metadata"]["session_id"] = self.session_id
                daily_state["metadata"]["mode"] = mode
                # Portfolioæ¨¡å¼å‚æ•°
                if mode == "portfolio":
                    daily_state["metadata"]["initial_cash"] = kwargs.get("initial_cash", 100000.0)
                    daily_state["metadata"]["margin_requirement"] = kwargs.get("margin_requirement", 0.0)
                daily_state["metadata"]["trading_date"] = current_date_str
                daily_state["metadata"]["day_number"] = i + 1
                
                # è®¾ç½®å½“æ—¥è¾“å‡ºæ–‡ä»¶
                daily_output_file = f"{self.base_output_dir}/{self.session_id}_daily_{current_date_str}.json"
                daily_state["metadata"]["output_file"] = daily_output_file
                
                # æ¢å¤å‰ä¸€æ—¥çŠ¶æ€ï¼ˆå¦‚æœæœ‰ï¼‰
                if i > 0:
                    previous_state = self.load_previous_state(current_date_str)
                    self.restore_state_to_engine(previous_state, daily_state)
                else:
                    # ç¬¬ä¸€å¤©ï¼šå°è¯•åŠ è½½previous stateï¼ˆå¯èƒ½æ˜¯å¤šæ—¥è¿è¡Œçš„continuationï¼‰
                    previous_state = self.load_previous_state(current_date_str)
                    
                    if previous_state:
                        # å¦‚æœæœ‰previous stateï¼Œæ¢å¤å®ƒï¼ˆåŒ…æ‹¬portfolioã€analyst_memoryç­‰ï¼‰
                        print(f"ğŸ”„ æ£€æµ‹åˆ°å†å²çŠ¶æ€ï¼Œæ­£åœ¨æ¢å¤...")
                        self.restore_state_to_engine(previous_state, daily_state)
                    elif mode == "portfolio":
                        # çœŸæ­£çš„ç¬¬ä¸€å¤©ï¼šåˆå§‹åŒ–æ–°PortfolioçŠ¶æ€
                        initial_cash = kwargs.get("initial_cash", 100000.0)
                        margin_requirement = kwargs.get("margin_requirement", 0.0)
                        
                        if "data" not in daily_state:
                            daily_state["data"] = {}
                        
                        daily_state["data"]["portfolio"] = {
                            "cash": initial_cash,
                            "positions": {},
                            "margin_requirement": margin_requirement,
                            "margin_used": 0.0
                        }
                        print(f"å·²åˆå§‹åŒ–æŠ•èµ„ç»„åˆ (ç°é‡‘: ${initial_cash:,.2f}, ä¿è¯é‡‘è¦æ±‚: {margin_requirement*100:.1f}%)")
                
                # OKRï¼šåœ¨è¿è¡Œåˆ†æå‰ï¼ŒåŸºäºè¿‡å¾€æ•°æ®æ›´æ–°æƒé‡ï¼Œå¹¶æ³¨å…¥åˆ°stateä¸­
                if self.okr_enabled:
                    self._init_okr_manager()
                    
                    # æ¯5ä¸ªäº¤æ˜“æ—¥ï¼ˆiåŸºäº0ï¼‰æ›´æ–°ä¸€æ¬¡æƒé‡ï¼Œä½¿å…¶ä½œç”¨äºä¸‹ä¸€é˜¶æ®µï¼ˆå½“å‰æ—¥ï¼‰
                    if (i % 5) == 0 and i > 0:
                        weights = self.okr_manager.update_weights_5day_review(current_date_str)
                        print(f"OKRï¼šæ›´æ–°åˆ†æå¸ˆæƒé‡ {weights}")
                    
                    # æ¯30ä¸ªäº¤æ˜“æ—¥è¿›è¡Œä¸€æ¬¡OKRè¯„ä¼°ä¸è®°å¿†é‡ç½®
                    if (i % 30) == 0 and i > 0:
                        eliminated_analyst = self.okr_manager.perform_30day_okr_evaluation(current_date_str)
                        if eliminated_analyst:
                            print(f"OKRè¯„ä¼°ï¼šæ·˜æ±°å¹¶é‡ç½® {eliminated_analyst}ï¼Œæ ‡è®°ä¸ºæ–°å…¥èŒåˆ†æå¸ˆ")
                    
                    # æ³¨å…¥åˆ°stateä¾›åç»­æç¤ºä½¿ç”¨
                    daily_state.setdefault("data", {})["okr_state"] = self.okr_manager.export_okr_data()
                    daily_state["data"]["analyst_weights"] = self.okr_manager.get_analyst_weights_for_prompt()
                
                # æ‰§è¡Œå½“æ—¥å®Œæ•´åˆ†ææµç¨‹
                daily_results = self.engine.run_full_analysis_with_communications(
                    tickers=tickers,
                    start_date=lookback_start,
                    end_date=current_date_str,
                    enable_communications=enable_communications,
                    enable_notifications=enable_notifications,
                    mode=mode,
                    state=daily_state
                )
                
                # OKRï¼šè®°å½•ä»Šæ—¥ä¿¡å·ï¼ˆåˆ†æ•°åœ¨æœªæ¥æ—¥è¡¥å…¨ï¼‰
                if self.okr_enabled and self.okr_manager:
                    try:
                        # è®°å½•ä»Šæ—¥åˆ†æå¸ˆä¿¡å·åˆ°OKRç®¡ç†å™¨
                        analyst_signals = daily_state.get("data", {}).get("analyst_signals", {})
                        self.okr_manager.record_daily_signals(current_date_str, analyst_signals)
                        # å°†æœ€æ–°OKRçŠ¶æ€ä¿å­˜åœ¨daily_stateä¸­ï¼Œä¾¿äºè·¨æ—¥æŒä¹…åŒ–
                        daily_state["data"]["okr_state"] = self.okr_manager.export_okr_data()
                    except Exception as e:
                        print(f"è­¦å‘Š: è®°å½•OKRä¿¡å·å¤±è´¥: {e}")
                
                # ä¿å­˜å½“æ—¥çŠ¶æ€ï¼ˆåŒ…æ‹¬æŠ•èµ„ç»„åˆï¼‰
                self.save_daily_state(current_date_str, daily_results, daily_state)
                
                # è®°å½•æˆåŠŸ
                successful_days += 1
                self.daily_results.append({
                    "date": current_date_str,
                    "status": "success",
                    "results": daily_results,
                    "output_file": daily_output_file
                })
                
                print(f"{current_date_str} åˆ†æå®Œæˆ")
                
                # å‘é€å•æ—¥ç»“æœ
                if progress_callback:
                    progress_callback({
                        "type": "daily_result",
                        "date": current_date_str,
                        "status": "success",
                        "data": daily_results
                    })
                
            except Exception as e:
                import traceback
                error_msg = str(e)
                full_traceback = traceback.format_exc()
                
                # æ£€æŸ¥æ˜¯å¦æ˜¯JSONåºåˆ—åŒ–ç›¸å…³é”™è¯¯
                is_json_error = ("JSON" in error_msg and "serializable" in error_msg) or \
                               ("Object of type" in error_msg and "is not JSON serializable" in error_msg)
                
                if is_json_error:
                    # JSONåºåˆ—åŒ–é”™è¯¯åº”è¯¥å·²ç»è¢«æˆ‘ä»¬çš„ä¿®å¤å¤„ç†äº†ï¼Œå¦‚æœè¿˜å‡ºç°è¯´æ˜æœ‰é—æ¼
                    print(f"è­¦å‘Š: {current_date_str} å‘ç°æœªå¤„ç†çš„JSONåºåˆ—åŒ–é—®é¢˜:")
                    print(f"   é”™è¯¯: {error_msg}")
                    print("   å»ºè®®æ£€æŸ¥æ˜¯å¦æœ‰é—æ¼çš„json.dumpsè°ƒç”¨éœ€è¦æ›¿æ¢ä¸ºquiet_json_dumps")
                else:
                    # å…¶ä»–çœŸæ­£çš„ä¸šåŠ¡é€»è¾‘é”™è¯¯
                    print(f"é”™è¯¯: {current_date_str} åˆ†æå¤±è´¥: {error_msg}")
                
                failed_days += 1
                self.daily_results.append({
                    "date": current_date_str,
                    "status": "failed",
                    "error": error_msg,
                    "full_traceback": full_traceback,
                    "output_file": None
                })
                
                # å‘é€å¤±è´¥é€šçŸ¥
                if progress_callback:
                    progress_callback({
                        "type": "daily_result",
                        "date": current_date_str,
                        "status": "failed",
                        "error": str(e)
                    })
                
                # ä¸¥é‡é”™è¯¯æ—¶å¯é€‰æ‹©åœæ­¢
                # continue  # ç»§ç»­ä¸‹ä¸€æ—¥
        
        # ç”Ÿæˆå¤šæ—¥æ±‡æ€»æŠ¥å‘Š
        summary_results = self.generate_multi_day_summary()
        
        print(f"\nå¤šæ—¥ç­–ç•¥åˆ†æå®Œæˆ!")
        print(f"æˆåŠŸ: {successful_days} æ—¥")
        print(f"å¤±è´¥: {failed_days} æ—¥")
        print(f"æˆåŠŸç‡: {successful_days/total_days*100:.1f}%")
        
        return summary_results
    
    def generate_multi_day_summary(self) -> Dict[str, Any]:
        """ç”Ÿæˆå¤šæ—¥æ±‡æ€»æŠ¥å‘Š"""
        summary_file = f"{self.base_output_dir}/{self.session_id}_summary.json"
        
        # è®¡ç®—æ±‡æ€»ç»Ÿè®¡
        successful_results = [r for r in self.daily_results if r["status"] == "success"]
        
        # æå–å…³é”®æŒ‡æ ‡æ—¶é—´åºåˆ—
        portfolio_values = []
        communication_stats = []
        
        for daily_result in successful_results:
            date = daily_result["date"]
            results = daily_result.get("results", {})
            
            # æŠ•èµ„ç»„åˆä»·å€¼å˜åŒ–
            if "portfolio_management_results" in results:
                pm_results = results["portfolio_management_results"]
                portfolio_values.append({
                    "date": date,
                    "total_value": pm_results.get("portfolio_summary", {}).get("total_value", 0),
                    "cash": pm_results.get("portfolio_summary", {}).get("cash", 0),
                    "positions_value": pm_results.get("portfolio_summary", {}).get("positions_value", 0)
                })
            
            # æ²Ÿé€šç»Ÿè®¡
            if "communication_logs" in results:
                comm_logs = results["communication_logs"]
                communication_stats.append({
                    "date": date,
                    "decisions_count": len(comm_logs.get("decisions", [])),
                    "private_chats_count": len(comm_logs.get("private_chats", [])),
                    "meetings_count": len(comm_logs.get("meetings", [])),
                    "notifications_count": len(comm_logs.get("notifications", []))
                })
        
        # è·å–è‚¡ç¥¨åˆ—è¡¨ï¼ˆä»ç¬¬ä¸€ä¸ªæˆåŠŸçš„ç»“æœä¸­æå–ï¼‰
        tickers = []
        for daily_result in successful_results:
            results = daily_result.get("results", {})
            portfolio_results = results.get("portfolio_management_results", {})
            if "final_decisions" in portfolio_results:
                tickers = list(portfolio_results["final_decisions"].keys())
                break
        # pdb.set_trace()
        # ç”Ÿæˆæ±‡æ€»ç»“æœ
        summary = {
            "session_id": self.session_id,
            "summary_timestamp": datetime.now().isoformat(),
            "period": {
                "start_date": self.daily_results[0]["date"] if self.daily_results else None,
                "end_date": self.daily_results[-1]["date"] if self.daily_results else None,
                "total_days": len(self.daily_results),
                "successful_days": len(successful_results),
                "failed_days": len([r for r in self.daily_results if r["status"] == "failed"])
            },
            "daily_results": self.daily_results,
            "time_series": {
                "portfolio_values": portfolio_values,
                "communication_stats": communication_stats
            },
            "performance_analysis": {
                "individual_stocks": self.calculate_individual_stock_performance(successful_results, tickers) if tickers else {}
            }
        }
        
        # ä¿å­˜æ±‡æ€»æ–‡ä»¶
        try:
            with open(summary_file, 'w', encoding='utf-8') as f:
                json.dump(summary, f, ensure_ascii=False, indent=2, default=str)
            print(f"å¤šæ—¥æ±‡æ€»æŠ¥å‘Šå·²ä¿å­˜: {summary_file}")
        except Exception as e:
            print(f"è­¦å‘Š: ä¿å­˜æ±‡æ€»æŠ¥å‘Šå¤±è´¥: {e}")
        
        return summary
    
    def calculate_performance_metrics(self, portfolio_values: List[Dict[str, Any]]) -> Dict[str, Any]:
        """è®¡ç®—å¤šæ—¥ç»©æ•ˆæŒ‡æ ‡ - åŸºäºç®€åŒ–çš„æ—¥æ”¶ç›Šç‡æ–¹æ³•"""
        if len(portfolio_values) < 2:
            return {"error": "æ•°æ®ä¸è¶³ï¼Œæ— æ³•è®¡ç®—ç»©æ•ˆæŒ‡æ ‡"}
        
        try:
            # è½¬æ¢ä¸ºDataFrameä¾¿äºè®¡ç®—
            df = pd.DataFrame(portfolio_values)
            df['date'] = pd.to_datetime(df['date'])
            df = df.set_index('date').sort_index()
            
            # ç®€åŒ–è®¡ç®—ï¼šç›´æ¥ä½¿ç”¨æ—¥æ”¶ç›Šç‡
            # å‡è®¾æ¯æ—¥å†³ç­–éƒ½æ˜¯åŸºäºå•ä½èµ„äº§ï¼Œæ”¶ç›Šç‡ç›´æ¥ç­‰äºä»·æ ¼å˜åŒ–ç‡
            df['daily_return'] = df['total_value'].pct_change()
            df['cumulative_return'] = (1 + df['daily_return']).cumprod() - 1
            
            # åŸºç¡€æŒ‡æ ‡
            total_return = df['cumulative_return'].iloc[-1] * 100  # è½¬æ¢ä¸ºç™¾åˆ†æ¯”
            mean_daily_return = df['daily_return'].mean()
            volatility = df['daily_return'].std() * (252 ** 0.5) * 100  # å¹´åŒ–æ³¢åŠ¨ç‡
            
            # å¹´åŒ–æ”¶ç›Šç‡ï¼ˆåŸºäºæ—¥å‡æ”¶ç›Šç‡ï¼‰
            annualized_return = mean_daily_return * 252 * 100
            
            # æœ€å¤§å›æ’¤ï¼ˆåŸºäºç´¯è®¡æ”¶ç›Šç‡ï¼‰
            cumulative_returns = (1 + df['daily_return']).cumprod()
            rolling_max = cumulative_returns.cummax()
            drawdown = (cumulative_returns - rolling_max) / rolling_max * 100
            max_drawdown = drawdown.min()
            
            # å¤æ™®æ¯”ç‡ï¼ˆå‡è®¾æ— é£é™©åˆ©ç‡4%ï¼‰
            excess_returns = df['daily_return'] - 0.04/252
            sharpe_ratio = excess_returns.mean() / excess_returns.std() * (252 ** 0.5) if excess_returns.std() > 0 else 0
            
            # è®¡ç®—äº¤æ˜“æœŸé—´
            trading_days = len(df)
            trading_period_years = trading_days / 252  # 252ä¸ªäº¤æ˜“æ—¥ä¸ºä¸€å¹´
            
            return {
                "total_return_pct": round(total_return, 2),
                "annualized_return_pct": round(annualized_return, 2),
                "annualized_volatility_pct": round(volatility, 2),
                "max_drawdown_pct": round(max_drawdown, 2),
                "sharpe_ratio": round(sharpe_ratio, 3),
                "total_trading_days": trading_days,
                "trading_period_years": round(trading_period_years, 2),
                "mean_daily_return_pct": round(mean_daily_return * 100, 4),  # æ–°å¢ï¼šæ—¥å‡æ”¶ç›Šç‡
                "start_value": df['total_value'].iloc[0],
                "end_value": df['total_value'].iloc[-1]
            }
            
        except Exception as e:
            return {"error": f"ç»©æ•ˆè®¡ç®—å¤±è´¥: {str(e)}"}
    
    def calculate_individual_stock_performance(self, daily_results: List[Dict[str, Any]], tickers: List[str]) -> Dict[str, Dict[str, Any]]:
        """è®¡ç®—æ¯åªè‚¡ç¥¨çš„å•ç‹¬ç»©æ•ˆæŒ‡æ ‡ï¼ˆåŸºäºæ–¹å‘ä¿¡å·ï¼‰"""
        stock_performance = {}
        
        for ticker in tickers:
            # æ”¶é›†è¯¥è‚¡ç¥¨çš„æ¯æ—¥å†³ç­–å’Œæ”¶ç›Šæ•°æ®
            daily_decisions = []
            daily_returns = []
            
            for daily_result in daily_results:
                if daily_result["status"] != "success":
                    continue
                    
                results = daily_result.get("results", {})
                portfolio_results = results.get("portfolio_management_results", {})
                
                # ä»æœ€ç»ˆå†³ç­–ä¸­æå–æ–¹å‘ä¿¡å·
                final_decisions = portfolio_results.get("final_decisions", {})
                if ticker in final_decisions:
                    decision = final_decisions[ticker]
                    action = decision.get("action", "hold")
                    confidence = decision.get("confidence", 0)
                    
                    daily_decisions.append({
                        "date": daily_result["date"],
                        "action": action,
                        "confidence": confidence
                    })
                    
                    # åŸºäºæ–¹å‘ä¿¡å·è®¡ç®—æ—¥æ”¶ç›Šç‡
                    daily_return,real_return,close_price = self._calculate_stock_daily_return_from_signal(
                        ticker, daily_result["date"], action
                    )
                    daily_returns.append(daily_return)
            
            if len(daily_returns) > 1:
                # è®¡ç®—è¯¥è‚¡ç¥¨çš„ç»©æ•ˆæŒ‡æ ‡
                returns_series = pd.Series(daily_returns)
                # pdb.set_trace()
                # è®¡ç®—ç´¯è®¡æ”¶ç›Šç‡
                cumulative_returns = (1 + returns_series).cumprod()
                total_return = cumulative_returns.iloc[-1] - 1
                
                # è®¡ç®—æœ€å¤§å›æ’¤
                rolling_max = cumulative_returns.cummax()
                drawdowns = (cumulative_returns - rolling_max) / rolling_max
                max_drawdown = drawdowns.min()
                
                # è®¡ç®—å¤æ™®æ¯”ç‡ï¼ˆå‡è®¾æ— é£é™©åˆ©ç‡4%ï¼‰
                excess_returns = returns_series - 0.04/252
                sharpe_ratio = excess_returns.mean() / excess_returns.std() * (252 ** 0.5) if excess_returns.std() > 0 else 0
                
                stock_performance[ticker] = {
                    "total_return_pct": round(total_return * 100, 4),
                    "mean_daily_return_pct": round(returns_series.mean() * 100, 4),
                    "annualized_return_pct": round(returns_series.mean() * 252 * 100, 2),
                    "volatility_pct": round(returns_series.std() * (252 ** 0.5) * 100, 2),
                    "sharpe_ratio": round(sharpe_ratio, 3),
                    "max_drawdown_pct": round(max_drawdown * 100, 2),
                    "total_decisions": len(daily_decisions),
                    "long_decisions": len([d for d in daily_decisions if d["action"] == "long"]),
                    "short_decisions": len([d for d in daily_decisions if d["action"] == "short"]),
                    "hold_decisions": len([d for d in daily_decisions if d["action"] == "hold"]),
                    "avg_confidence": round(sum(d["confidence"] for d in daily_decisions) / len(daily_decisions), 2) if daily_decisions else 0,
                    "win_rate": round(len([r for r in daily_returns if r > 0]) / len(daily_returns) * 100, 2),
                    "trading_days": len(daily_returns)
                }
            else:
                stock_performance[ticker] = {
                    "error": "æ•°æ®ä¸è¶³ï¼Œæ— æ³•è®¡ç®—è¯¥è‚¡ç¥¨ç»©æ•ˆæŒ‡æ ‡"
                }
        
        
        return stock_performance
    
    def _calculate_stock_daily_return_from_signal(self, ticker: str, date, action: str) -> float:
        """åŸºäºæ–¹å‘ä¿¡å·è®¡ç®—å•åªè‚¡ç¥¨çš„æ—¥æ”¶ç›Šç‡
        
        Args:
            ticker: è‚¡ç¥¨ä»£ç 
            date: æ—¥æœŸï¼Œå¯ä»¥æ˜¯å­—ç¬¦ä¸² (YYYY-MM-DD) æˆ– datetime.date å¯¹è±¡
            action: äº¤æ˜“åŠ¨ä½œ ('long', 'short', 'hold')
        """
        # è·å–è¯¥è‚¡ç¥¨çš„ä»·æ ¼æ•°æ®ï¼ˆè·å–æ›´å¤§èŒƒå›´ä»¥ç¡®ä¿æœ‰è¶³å¤Ÿæ•°æ®è®¡ç®—æ”¶ç›Šç‡ï¼‰
        from datetime import datetime, timedelta
        import datetime as dt
        
        # å¤„ç†æ—¥æœŸå‚æ•°ï¼Œç¡®ä¿è½¬æ¢ä¸º date å¯¹è±¡
        if isinstance(date, str):
            target_date = pd.to_datetime(date).date()
        elif isinstance(date, dt.date):
            target_date = date
        elif isinstance(date, dt.datetime):
            target_date = date.date()
        
        # ä½¿ç”¨ç›¸å¯¹è·¯å¾„è·å–æ•°æ®æ–‡ä»¶
        current_dir = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))  # è·å–IA/srcç›®å½•
        data_path = os.path.join(current_dir, 'data', 'ret_data', f'{ticker}.csv')
        
        if not os.path.exists(data_path):
            print(f"è­¦å‘Š: æ•°æ®æ–‡ä»¶ä¸å­˜åœ¨ {data_path}ï¼Œä½¿ç”¨æ¨¡æ‹Ÿæ”¶ç›Šç‡")
            return self._fallback_simulated_return(ticker, str(target_date), action)
            
        prices_df = pd.read_csv(data_path)
        
        if prices_df.empty:
            print(f"è­¦å‘Š: æ— æ³•è·å– {ticker} åœ¨ {target_date} çš„ä»·æ ¼æ•°æ®ï¼Œä½¿ç”¨æ¨¡æ‹Ÿæ”¶ç›Šç‡")
            return self._fallback_simulated_return(ticker, str(target_date), action)
        
        # è®¡ç®—æ—¥æ”¶ç›Šç‡
        # prices_df['ret'] = prices_df['close'].pct_change()
        
        # æŸ¥æ‰¾æŒ‡å®šæ—¥æœŸçš„æ”¶ç›Šç‡
        prices_df.index = pd.to_datetime(prices_df['time']).dt.date
        # pdb.set_trace()
        # æ‰¾åˆ°æœ€æ¥è¿‘ç›®æ ‡æ—¥æœŸçš„æ”¶ç›Šç‡
        market_return = prices_df.loc[target_date, 'ret']
        price = prices_df.loc[target_date, 'close']
        
        # æ ¹æ®äº¤æ˜“æ–¹å‘è®¡ç®—æœ€ç»ˆæ”¶ç›Šç‡
        if action == "long":
            return float(market_return), float(market_return), float(price) # åšå¤šï¼šè·å¾—å¸‚åœºæ”¶ç›Šç‡
        elif action == "short":
            return float(-market_return) ,float(market_return),float(price) # åšç©ºï¼šè·å¾—å¸‚åœºæ”¶ç›Šç‡çš„ç›¸åæ”¶ç›Š
        else:  # hold
            return 0.0,float(market_return), float(price)# æŒæœ‰ï¼šæ— æ”¶ç›Š
                
   
    

