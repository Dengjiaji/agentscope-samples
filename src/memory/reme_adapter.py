#!/usr/bin/env python3
"""
ReMe è®°å¿†æ¡†æž¶é€‚é…å™¨
å°† ReMe (flowllm) æ¡†æž¶é€‚é…åˆ°ç»Ÿä¸€çš„è®°å¿†æŽ¥å£
"""

import os
import logging
from typing import Dict, List, Any, Optional
from pathlib import Path

from src.memory.memory_interface import MemoryInterface

# å°è¯•å¯¼å…¥ReMeç›¸å…³æ¨¡å—
try:
    from flowllm.storage.vector_store import ChromaVectorStore
    from flowllm.embedding_model import OpenAICompatibleEmbeddingModel
    from flowllm.schema.vector_node import VectorNode
    REME_AVAILABLE = True
except ImportError as e:
    REME_AVAILABLE = False
    print(f"âš ï¸ ReMeæ¡†æž¶æœªå®‰è£…: {e}")
    print("æç¤º: è¯·å®‰è£… flowllm åŒ…ä»¥ä½¿ç”¨ReMeæ¡†æž¶")


class ReMeAdapter(MemoryInterface):
    """ReMeæ¡†æž¶é€‚é…å™¨"""
    
    def __init__(self, base_dir: str):
        """
        åˆå§‹åŒ–ReMeé€‚é…å™¨
        
        Args:
            base_dir: åŸºç¡€ç›®å½• (config_name)
        """
        if not REME_AVAILABLE:
            raise ImportError("ReMeæ¡†æž¶æœªå®‰è£…ï¼Œæ— æ³•ä½¿ç”¨ReMeAdapter")
        
        self.base_dir = os.path.join("logs_and_memory", base_dir)
        self.store_dir = os.path.join(self.base_dir, "memory_data", "reme_vector_store")
        
        # ç¡®ä¿ç›®å½•å­˜åœ¨
        os.makedirs(self.store_dir, exist_ok=True)
        
        # è®¾ç½®æ—¥å¿—
        self._setup_logging()
        
        # ðŸ”§ åŠ è½½ ReMe çŽ¯å¢ƒå˜é‡é…ç½®
        self._load_reme_env()
        
        # åˆå§‹åŒ–embeddingæ¨¡åž‹
        embedding_model_name = os.getenv("MEMORY_EMBEDDING_MODEL", "text-embedding-v4")
        embedding_dimensions = int(os.getenv("REME_EMBEDDING_DIMENSIONS", "1024"))
        
        self.logger.info(f"ReMeé…ç½®: model={embedding_model_name}, dimensions={embedding_dimensions}")
        self.logger.info(f"ReMe API: base_url={os.getenv('FLOW_EMBEDDING_BASE_URL', 'Not set')}")
        
        self.embedding_model = OpenAICompatibleEmbeddingModel(
            dimensions=embedding_dimensions,
            model_name=embedding_model_name
        )
        # åˆå§‹åŒ–å‘é‡å­˜å‚¨
        self.vector_store = ChromaVectorStore(
            embedding_model=self.embedding_model,
            store_dir=self.store_dir,
            batch_size=1024
        )
        
        self.logger.info(f"ReMeé€‚é…å™¨å·²åˆå§‹åŒ– (å­˜å‚¨ç›®å½•: {self.store_dir})")
    
    def _load_reme_env(self):
        """
        åŠ è½½ ReMe çŽ¯å¢ƒå˜é‡
        ReMe ä½¿ç”¨ FLOW_ å‰ç¼€çš„çŽ¯å¢ƒå˜é‡ï¼Œéœ€è¦æ˜ å°„åˆ° OpenAI å…¼å®¹çš„çŽ¯å¢ƒå˜é‡
        """
        # å¦‚æžœå·²ç»è®¾ç½®äº† FLOW_ çŽ¯å¢ƒå˜é‡ï¼Œæ˜ å°„åˆ° OpenAI å…¼å®¹çš„å˜é‡
        flow_embedding_api_key = os.getenv("FLOW_EMBEDDING_API_KEY")
        flow_embedding_base_url = os.getenv("FLOW_EMBEDDING_BASE_URL")
        flow_llm_api_key = os.getenv("FLOW_LLM_API_KEY")
        flow_llm_base_url = os.getenv("FLOW_LLM_BASE_URL")
        
        # æ˜ å°„ FLOW_ å˜é‡åˆ° OPENAI_ å˜é‡ï¼ˆå¦‚æžœ OPENAI_ å˜é‡æœªè®¾ç½®ï¼‰
        if flow_embedding_api_key and not os.getenv("OPENAI_API_KEY"):
            os.environ["OPENAI_API_KEY"] = flow_embedding_api_key
            self.logger.info("å·²ä»Ž FLOW_EMBEDDING_API_KEY è®¾ç½® OPENAI_API_KEY")
        
        if flow_embedding_base_url and not os.getenv("OPENAI_BASE_URL"):
            os.environ["OPENAI_BASE_URL"] = flow_embedding_base_url
            self.logger.info(f"å·²ä»Ž FLOW_EMBEDDING_BASE_URL è®¾ç½® OPENAI_BASE_URL: {flow_embedding_base_url}")
        
        # æ£€æŸ¥å¿…éœ€çš„çŽ¯å¢ƒå˜é‡
        if not os.getenv("OPENAI_API_KEY"):
            self.logger.warning("âš ï¸ æœªè®¾ç½® OPENAI_API_KEY æˆ– FLOW_EMBEDDING_API_KEY")
            self.logger.warning("   ReMe éœ€è¦ API key æ‰èƒ½ç”Ÿæˆ embedding")
        
        if not os.getenv("OPENAI_BASE_URL"):
            self.logger.warning("âš ï¸ æœªè®¾ç½® OPENAI_BASE_URL æˆ– FLOW_EMBEDDING_BASE_URL")
            self.logger.warning("   å°†ä½¿ç”¨é»˜è®¤ OpenAI API: https://api.openai.com/v1")
    
    def _setup_logging(self):
        """è®¾ç½®æ—¥å¿—"""
        logging.basicConfig(
            level=logging.INFO,
            format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
        )
        self.logger = logging.getLogger(__name__)
    
    def _get_workspace_id(self, user_id: str) -> str:
        """èŽ·å–workspace IDï¼Œç›´æŽ¥ä½¿ç”¨user_idä½œä¸ºworkspace_id"""
        return user_id
    
    def _ensure_workspace_exists(self, workspace_id: str):
        """ç¡®ä¿workspaceå­˜åœ¨"""
        if not self.vector_store.exist_workspace(workspace_id):
            self.vector_store.create_workspace(workspace_id)
            self.logger.info(f"åˆ›å»ºworkspace: {workspace_id}")
    
    def _convert_numpy_types(self, obj):
        """
        é€’å½’è½¬æ¢å¯¹è±¡ä¸­çš„numpyç±»åž‹ä¸ºPythonåŽŸç”Ÿç±»åž‹
        """
        try:
            import numpy as np
            
            if isinstance(obj, np.integer):
                return int(obj)
            elif isinstance(obj, np.floating):
                return float(obj)
            elif isinstance(obj, np.ndarray):
                return obj.tolist()
            elif isinstance(obj, dict):
                return {key: self._convert_numpy_types(value) for key, value in obj.items()}
            elif isinstance(obj, (list, tuple)):
                return [self._convert_numpy_types(item) for item in obj]
            else:
                return obj
        except ImportError:
            # å¦‚æžœæ²¡æœ‰numpyï¼Œç›´æŽ¥è¿”å›žåŽŸå€¼
            return obj
    
    def _normalize_metadata(self, metadata: Dict[str, Any]) -> Dict[str, Any]:
        """
        æ ‡å‡†åŒ–metadataï¼Œå°†ä¸æ”¯æŒçš„ç±»åž‹è½¬æ¢ä¸ºå­—ç¬¦ä¸²
        ChromaDBåªæ”¯æŒ: str, int, float, bool (æ³¨æ„ï¼šå®žé™…ä¸æ”¯æŒ None!)
        """
        if metadata is None:
            return {}
        
        import json
        
        # å°è¯•å¯¼å…¥numpyç”¨äºŽç±»åž‹æ£€æŸ¥
        try:
            import numpy as np
            has_numpy = True
        except ImportError:
            has_numpy = False
        
        normalized = {}
        for key, value in metadata.items():
            # âš ï¸ è·³è¿‡ None å€¼ - ChromaDB å®žé™…ä¸æŽ¥å— None
            if value is None:
                continue  # ä¸æ·»åŠ è¿™ä¸ªé”®å€¼å¯¹
            elif isinstance(value, (str, bool)):
                # å­—ç¬¦ä¸²å’Œå¸ƒå°”å€¼ä¿æŒä¸å˜
                normalized[key] = value
            elif isinstance(value, (int, float)):
                # PythonåŽŸç”Ÿæ•°å­—ç±»åž‹ä¿æŒä¸å˜
                normalized[key] = value
            elif has_numpy and isinstance(value, (np.integer, np.floating)):
                # numpyæ•°å­—ç±»åž‹è½¬æ¢ä¸ºPythonåŽŸç”Ÿç±»åž‹
                if isinstance(value, np.integer):
                    normalized[key] = int(value)
                else:
                    normalized[key] = float(value)
            elif isinstance(value, (list, tuple, dict)) or (has_numpy and isinstance(value, np.ndarray)):
                # å¤æ‚ç±»åž‹ï¼šå…ˆè½¬æ¢numpyç±»åž‹ï¼Œå†è½¬JSONå­—ç¬¦ä¸²
                try:
                    converted_value = self._convert_numpy_types(value)
                    normalized[key] = json.dumps(converted_value, ensure_ascii=False)
                except (TypeError, ValueError) as e:
                    # å¦‚æžœJSONåºåˆ—åŒ–å¤±è´¥ï¼Œç›´æŽ¥è½¬å­—ç¬¦ä¸²
                    normalized[key] = str(value)
            else:
                # å…¶ä»–ç±»åž‹è½¬æ¢ä¸ºå­—ç¬¦ä¸²
                normalized[key] = str(value)
        
        return normalized
    
    def add(self, messages: str | List[Dict[str, Any]], user_id: str, metadata: Optional[Dict[str, Any]] = None, infer: bool = False, **kwargs) -> Dict[str, Any]:
        """
        æ·»åŠ è®°å¿†
        
        Args:
            messages: æ¶ˆæ¯å†…å®¹
            user_id: ç”¨æˆ·ID
            metadata: å…ƒæ•°æ®
            infer: Mem0å‚æ•°ï¼ŒReMeä¸­å¿½ç•¥
            **kwargs: å…¶ä»–å…¼å®¹æ€§å‚æ•°ï¼ŒReMeä¸­å¿½ç•¥
        """
        workspace_id = self._get_workspace_id(user_id)
        self._ensure_workspace_exists(workspace_id)
        
        # å¤„ç†æ¶ˆæ¯æ ¼å¼
        if isinstance(messages, str):
            content = messages
        elif isinstance(messages, list):
            # æå–æ¶ˆæ¯å†…å®¹
            content = "\n".join([
                f"{msg.get('role', 'user')}: {msg.get('content', '')}" 
                for msg in messages
            ])
        else:
            content = str(messages)
        
        # åˆ›å»ºVectorNode
        import uuid
        node_id = str(uuid.uuid4())
        
        node_metadata = metadata or {}
        node_metadata['user_id'] = user_id
        
        # æ ‡å‡†åŒ–metadataï¼Œç¡®ä¿æ‰€æœ‰å€¼éƒ½æ˜¯æ”¯æŒçš„ç±»åž‹
        node_metadata = self._normalize_metadata(node_metadata)
        
        node = VectorNode(
            unique_id=node_id,
            workspace_id=workspace_id,
            content=content,
            metadata=node_metadata
        )
        
        # æ’å…¥èŠ‚ç‚¹
        self.vector_store.insert([node], workspace_id)
        
        # è‡ªåŠ¨ä¿å­˜workspace
        print(f"ðŸ’¾ å‡†å¤‡ä¿å­˜ workspace: {workspace_id}")
        print(f"   ä¿å­˜è·¯å¾„: {self.store_dir}")
        # âš ï¸ å¿…é¡»ä¼ å…¥ path å‚æ•°ï¼Œå¦åˆ™ä¼šä¿å­˜åˆ°å½“å‰å·¥ä½œç›®å½•
        self.vector_store.dump_workspace(workspace_id, path=self.store_dir)
        
        self.logger.info(f"æ·»åŠ è®°å¿†: user={user_id}, id={node_id} (å·²ä¿å­˜)")
        
        return {
            'status': 'success',
            'results': [{'id': node_id, 'memory': content}]
        }
    
    def search(self, query: str, user_id: str, top_k: int = 5, **kwargs) -> Dict[str, Any]:
        """æœç´¢è®°å¿†"""
        workspace_id = self._get_workspace_id(user_id)
        
        # æ£€æŸ¥workspaceæ˜¯å¦å­˜åœ¨
        if not self.vector_store.exist_workspace(workspace_id):
            self.logger.warning(f"Workspaceä¸å­˜åœ¨: {workspace_id}")
            return {'results': []}
        
        # æœç´¢
        nodes = self.vector_store.search(query, workspace_id, top_k=top_k)
        
        # è½¬æ¢ä¸ºæ ‡å‡†æ ¼å¼
        results = []
        for node in nodes:
            result = {
                'id': node.unique_id,
                'memory': node.content,
                'metadata': node.metadata,
                'score': node.metadata.get('score', 0.0)
            }
            results.append(result)
        
        self.logger.info(f"æœç´¢è®°å¿†: user={user_id}, query='{query[:50]}...', æ‰¾åˆ°{len(results)}æ¡")
        
        return {'results': results}
    
    def update(self, memory_id: str, data: str | Dict[str, Any], workspace_id: Optional[str] = None) -> Dict[str, Any]:
        """
        æ›´æ–°è®°å¿†
        é€šè¿‡æ’å…¥ç›¸åŒunique_idçš„VectorNodeæ¥è¦†ç›–æ›´æ–°
        
        Args:
            memory_id: è®°å¿†ID (unique_id)
            data: æ–°çš„è®°å¿†å†…å®¹
            workspace_id: workspace IDï¼Œå¦‚æžœæœªæä¾›åˆ™å¿…é¡»åœ¨ data ä¸­æŒ‡å®š user_id
            
        Returns:
            æ›´æ–°ç»“æžœ
        """
        # å¦‚æžœæ²¡æœ‰æä¾›workspace_idï¼Œä»Ždataä¸­èŽ·å–user_idå¹¶ç”Ÿæˆworkspace_id
        if workspace_id is None:
            if isinstance(data, dict) and 'user_id' in data:
                user_id = data['user_id']
                workspace_id = self._get_workspace_id(user_id)
            else:
                raise ValueError("å¿…é¡»æä¾› workspace_id æˆ–åœ¨ data ä¸­æŒ‡å®š user_id")
        
        # å¤„ç†æ•°æ®æ ¼å¼
        if isinstance(data, str):
            content = data
            metadata = {}
        elif isinstance(data, dict):
            content = data.get('content', str(data))
            metadata = data.get('metadata', {})
        else:
            content = str(data)
            metadata = {}
        
        # æ ‡å‡†åŒ–metadata
        metadata = self._normalize_metadata(metadata)
        
        # åˆ›å»ºæ–°çš„VectorNodeï¼Œä½¿ç”¨ç›¸åŒçš„unique_idæ¥è¦†ç›–
        updated_node = VectorNode(
            unique_id=memory_id,  # ä½¿ç”¨ç›¸åŒçš„IDå®žçŽ°è¦†ç›–
            workspace_id=workspace_id,
            content=content,
            metadata=metadata
        )
        
        # æ’å…¥èŠ‚ç‚¹ï¼ˆä¼šè¦†ç›–åŒIDçš„æ—§èŠ‚ç‚¹ï¼‰
        self.vector_store.insert([updated_node], workspace_id)
        
        # è‡ªåŠ¨ä¿å­˜workspace
        self.vector_store.dump_workspace(workspace_id, path=self.store_dir)
        
        self.logger.info(f"æ›´æ–°è®°å¿†: workspace={workspace_id}, id={memory_id} (å·²ä¿å­˜)")
        
        return {
            'status': 'success',
            'message': f'å·²æ›´æ–°è®°å¿† {memory_id}',
            'memory_id': memory_id
        }
    
    def delete(self, memory_id: str, workspace_id: Optional[str] = None) -> Dict[str, Any]:
        """
        åˆ é™¤è®°å¿†
        
        Args:
            memory_id: è®°å¿†ID
            workspace_id: workspace IDï¼Œå¿…é¡»æä¾›
            
        Returns:
            åˆ é™¤ç»“æžœ
        """
        if workspace_id is None:
            raise ValueError("å¿…é¡»æä¾› workspace_id æ¥åˆ é™¤è®°å¿†")
        
        # æ‰§è¡Œåˆ é™¤
        self.vector_store.delete([memory_id], workspace_id)
        
        # è‡ªåŠ¨ä¿å­˜workspace
        self.vector_store.dump_workspace(workspace_id, path=self.store_dir)
        
        self.logger.info(f"åˆ é™¤è®°å¿†: workspace={workspace_id}, id={memory_id} (å·²ä¿å­˜)")
        
        return {
            'status': 'success',
            'message': f'å·²åˆ é™¤è®°å¿† {memory_id}'
        }
    
    def delete_by_workspace(self, memory_id: str, workspace_id: str) -> Dict[str, Any]:
        """
        æŒ‰workspaceåˆ é™¤è®°å¿†ï¼ˆReMeç‰¹å®šæ–¹æ³•ï¼‰
        
        Args:
            memory_id: è®°å¿†ID
            workspace_id: workspace ID
            
        Returns:
            åˆ é™¤ç»“æžœ
        """
        self.vector_store.delete([memory_id], workspace_id)
        
        # è‡ªåŠ¨ä¿å­˜workspace
        self.vector_store.dump_workspace(workspace_id, path=self.store_dir)
        
        self.logger.info(f"åˆ é™¤è®°å¿†: workspace={workspace_id}, id={memory_id} (å·²ä¿å­˜)")
        
        return {
            'status': 'success',
            'message': f'å·²åˆ é™¤è®°å¿† {memory_id}'
        }
    
    def get_all(self, user_id: str, **kwargs) -> Dict[str, Any]:
        """èŽ·å–æ‰€æœ‰è®°å¿†"""
        workspace_id = self._get_workspace_id(user_id)
        
        # æ£€æŸ¥workspaceæ˜¯å¦å­˜åœ¨
        if not self.vector_store.exist_workspace(workspace_id):
            return {'results': []}
        
        # ä½¿ç”¨ iter_workspace_nodes() æ–¹æ³•èŽ·å–workspaceä¸­çš„æ‰€æœ‰èŠ‚ç‚¹
        # è¿™æ˜¯ä¸€ä¸ªç”Ÿæˆå™¨ï¼Œéœ€è¦è½¬æ¢ä¸ºåˆ—è¡¨
        workspace_nodes = list(self.vector_store.iter_workspace_nodes(workspace_id))
        
        # è½¬æ¢ä¸ºæ ‡å‡†æ ¼å¼
        results = []
        for node in workspace_nodes:
            result = {
                'id': node.unique_id,
                'memory': node.content,
                'metadata': node.metadata
            }
            results.append(result)
        
        self.logger.info(f"èŽ·å–æ‰€æœ‰è®°å¿†: user={user_id}, å…±{len(results)}æ¡")
        
        return {'results': results}
    
    def reset(self, user_id: Optional[str] = None) -> Dict[str, Any]:
        """é‡ç½®è®°å¿†"""
        if user_id:
            workspace_id = self._get_workspace_id(user_id)
            if self.vector_store.exist_workspace(workspace_id):
                self.vector_store.delete_workspace(workspace_id)
                # æ³¨æ„ï¼šåˆ é™¤workspaceåŽæ— éœ€dumpï¼Œå› ä¸ºworkspaceå·²ä¸å­˜åœ¨
                self.logger.info(f"é‡ç½®è®°å¿†: user={user_id} (å·²åˆ é™¤workspace)")
                return {
                    'status': 'success',
                    'message': f'å·²é‡ç½® {user_id} çš„è®°å¿†'
                }
            else:
                return {
                    'status': 'success',
                    'message': f'{user_id} æ²¡æœ‰è®°å¿†éœ€è¦é‡ç½®'
                }
        else:
            # é‡ç½®æ‰€æœ‰ï¼ˆéœ€è¦çŸ¥é“æ‰€æœ‰workspaceï¼‰
            self.logger.warning("ReMeæ¡†æž¶é‡ç½®æ‰€æœ‰è®°å¿†éœ€è¦æ‰‹åŠ¨å¤„ç†")
            return {
                'status': 'partial_support',
                'message': 'è¯·æŒ‡å®šuser_idè¿›è¡Œé‡ç½®'
            }
    
    def get_framework_name(self) -> str:
        """èŽ·å–æ¡†æž¶åç§°"""
        return "reme"
    
    def export_workspace(self, user_id: str, export_path: Optional[str] = None) -> Dict[str, Any]:
        """
        å¯¼å‡ºworkspaceï¼ˆReMeç‰¹å®šåŠŸèƒ½ï¼‰
        
        Args:
            user_id: ç”¨æˆ·ID
            export_path: å¯¼å‡ºè·¯å¾„ï¼Œå¦‚æžœä¸ºNoneåˆ™ä½¿ç”¨é»˜è®¤è·¯å¾„
            
        Returns:
            å¯¼å‡ºç»“æžœ
        """
        workspace_id = self._get_workspace_id(user_id)
        
        if not export_path:
            export_path = os.path.join(self.store_dir, f"{workspace_id}.jsonl")
        
        result = self.vector_store.dump_workspace(workspace_id, path=export_path)
        
        self.logger.info(f"å¯¼å‡ºworkspace: {workspace_id} -> {export_path}")
        
        return {
            'status': 'success',
            'export_path': export_path,
            'result': result
        }
    
    def import_workspace(self, user_id: str, import_path: str) -> Dict[str, Any]:
        """
        å¯¼å…¥workspaceï¼ˆReMeç‰¹å®šåŠŸèƒ½ï¼‰
        
        Args:
            user_id: ç”¨æˆ·ID
            import_path: å¯¼å…¥è·¯å¾„
            
        Returns:
            å¯¼å…¥ç»“æžœ
        """
        workspace_id = self._get_workspace_id(user_id)
        
        result = self.vector_store.load_workspace(workspace_id, path=import_path)
        
        self.logger.info(f"å¯¼å…¥workspace: {import_path} -> {workspace_id}")
        
        return {
            'status': 'success',
            'import_path': import_path,
            'result': result
        }

