import os
from typing import Dict, Any

# from live_trading_thinking_fund import LLM_AVAILABLE, MEMORY_TOOLS_AVAILABLE
from src.llm.models import get_model


MEMORY_AVAILABLE = True
LLM_AVAILABLE = True
MEMORY_TOOLS_AVAILABLE = True


class LLMMemoryDecisionSystem:
    """åŸºäºLLMçš„è®°å¿†ç®¡ç†å†³ç­–ç³»ç»Ÿ"""

    def __init__(self):
        self.memory_tools = []

        if LLM_AVAILABLE and MEMORY_TOOLS_AVAILABLE:
            model_name = os.getenv('MEMORY_LLM_MODEL', 'gpt-4o-mini')
            model_provider_str = os.getenv('MEMORY_LLM_PROVIDER', 'OPENAI')
            from src.llm.models import ModelProvider

            # è½¬æ¢ä¸ºModelProvideræšä¸¾
            if hasattr(ModelProvider, model_provider_str):
                model_provider = getattr(ModelProvider, model_provider_str)
            else:
                print(f"æœªçŸ¥çš„æ¨¡å‹æä¾›å•†: {model_provider_str}ï¼Œä½¿ç”¨é»˜è®¤OPENAI")
                model_provider = ModelProvider.OPENAI

            api_keys = {}
            if model_provider == ModelProvider.OPENAI:
                api_keys['OPENAI_API_KEY'] = os.getenv('OPENAI_API_KEY')
            elif model_provider == ModelProvider.ANTHROPIC:
                api_keys['ANTHROPIC_API_KEY'] = os.getenv('ANTHROPIC_API_KEY')

            # è·å–è®°å¿†ç®¡ç†å·¥å…·
            from src.tools.memory_tools import get_memory_tools
            self.memory_tools = get_memory_tools()
            # ä½¿ç”¨ AgentScope æ¨¡å‹
            self.llm = get_model(model_name, model_provider, api_keys)
            # æ³¨æ„ï¼šAgentScope ä¸ä½¿ç”¨ bind_toolsï¼Œè€Œæ˜¯é€šè¿‡ function calling æˆ–ç›´æ¥è°ƒç”¨
            # è¿™é‡Œä¿æŒå¼•ç”¨ä»¥ä¾¿åç»­è¿ç§»
            self.llm_with_tools = self.llm
            self.llm_available = True
            print(f"LLMè®°å¿†å†³ç­–ç³»ç»Ÿå·²å¯ç”¨ï¼ˆ{model_provider_str}: {model_name}ï¼‰")
            print(f"å·²åŠ è½½ {len(self.memory_tools)} ä¸ªè®°å¿†ç®¡ç†å·¥å…·")

    def generate_memory_decision_prompt(self, performance_data: Dict[str, Any], date: str) -> str:
        """ç”ŸæˆLLMè®°å¿†å†³ç­–çš„prompt"""

        prompt = f"""ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„Portfolio Managerï¼Œè´Ÿè´£ç®¡ç†åˆ†æå¸ˆå›¢é˜Ÿçš„è®°å¿†ç³»ç»Ÿã€‚åŸºäº{date}çš„äº¤æ˜“å¤ç›˜ç»“æœï¼Œè¯·åˆ†æåˆ†æå¸ˆçš„è¡¨ç°å¹¶å†³å®šæ˜¯å¦éœ€è¦ä½¿ç”¨è®°å¿†ç®¡ç†å·¥å…·ã€‚

# å¤ç›˜æ•°æ®åˆ†æ

## åˆ†æå¸ˆä¿¡å· vs å®é™…ç»“æœå¯¹æ¯”

### Portfolio Manageræœ€ç»ˆå†³ç­–:
"""

        pm_signals = performance_data.get('pm_signals', {})
        actual_returns = performance_data.get('actual_returns', {})
        analyst_signals = performance_data.get('analyst_signals', {})
        tickers = performance_data.get('tickers', [])

        # æ·»åŠ PMä¿¡å·å’Œå®é™…ç»“æœ
        for ticker in tickers:
            pm_signal = pm_signals.get(ticker, {})
            actual_return = actual_returns.get(ticker, 0)

            prompt += f"\n{ticker}:"
            prompt += f"\n  PMå†³ç­–: {pm_signal.get('signal', 'N/A')} (ç½®ä¿¡åº¦: {pm_signal.get('confidence', 'N/A')}%)"
            prompt += f"\n  å®é™…æ”¶ç›Š: {actual_return:.2%}"

        prompt += "\n\n### å„åˆ†æå¸ˆçš„é¢„æµ‹è¡¨ç°:"

        # æ·»åŠ åˆ†æå¸ˆè¡¨ç°
        for analyst, signals in analyst_signals.items():
            prompt += f"\n\n**{analyst}:**"
            total_count = 0
            for ticker in tickers:
                if ticker in signals and ticker in actual_returns:
                    analyst_signal = signals[ticker]
                    actual_return = actual_returns[ticker]
                    total_count += 1

                    prompt += f"\n  {ticker}: é¢„æµ‹ {analyst_signal}, å®é™… {actual_return:.2%}"

        prompt += f"""

# è®°å¿†ç®¡ç†å†³ç­–æŒ‡å¯¼

è¯·åˆ†æå„åˆ†æå¸ˆçš„è¡¨ç°ï¼Œå¹¶å†³å®šæ˜¯å¦éœ€è¦æ‰§è¡Œè®°å¿†ç®¡ç†æ“ä½œï¼š

- **è¡¨ç°æå·®** (å¤šä¸ªä¸¥é‡é”™è¯¯)ï¼šä½¿ç”¨search_and_delete_analyst_memoryåˆ é™¤ä¸¥é‡é”™è¯¯è®°å¿†
- **è¡¨ç°ä¸ä½³** (ä¸€ä¸ªæˆ–è€…å¤šä¸ªå¾®å°é”™è¯¯)ï¼šä½¿ç”¨search_and_update_analyst_memoryæ›´æ–°é”™è¯¯è®°å¿†
- **è¡¨ç°ä¼˜ç§€æˆ–æ­£å¸¸**ï¼šæ— éœ€æ“ä½œï¼Œç›´æ¥è¯´æ˜åˆ†æç»“æœå³å¯

å¯ç”¨çš„è®°å¿†ç®¡ç†å·¥å…·ï¼š
1. **search_and_update_analyst_memory**: ä¿®æ­£æ›´æ–°åˆ†æå¸ˆçš„ç›¸å…³è®°å¿†å†…å®¹
2. **search_and_delete_analyst_memory**: åˆ é™¤åˆ†æå¸ˆçš„ç›¸å…³è®°å¿†å†…å®¹

è¯·å…ˆåˆ†æå„åˆ†æå¸ˆçš„è¡¨ç°ï¼Œç„¶åå¦‚æœéœ€è¦è®°å¿†æ“ä½œï¼Œç›´æ¥è°ƒç”¨ç›¸åº”çš„å·¥å…·ã€‚å¦‚æœä¸éœ€è¦ä»»ä½•æ“ä½œï¼Œè¯·è¯´æ˜ä½ çš„åˆ†æç»“æœã€‚
"""

        return prompt

    def make_llm_memory_decision_with_tools(self, performance_data: Dict[str, Any], date: str) -> Dict[str, Any]:
        """ä½¿ç”¨LLMè¿›è¡Œè®°å¿†ç®¡ç†å†³ç­–"""

        if not getattr(self, "llm_available", False):
            print("âš ï¸ LLMä¸å¯ç”¨ï¼Œè·³è¿‡è®°å¿†ç®¡ç†")
            return {'status': 'skipped', 'reason': 'LLMä¸å¯ç”¨'}

        try:
            # ç”Ÿæˆprompt
            prompt = self.generate_memory_decision_prompt(performance_data, date)

            print(f"\nğŸ¤– æ­£åœ¨è¯·æ±‚LLMè¿›è¡Œè®°å¿†ç®¡ç†å†³ç­–...")
            print(f"ğŸ“ Prompté•¿åº¦: {len(prompt)} å­—ç¬¦")

            # è°ƒç”¨ LLMï¼ˆä½¿ç”¨ AgentScope æ ¼å¼ï¼‰
            messages = [{"role": "user", "content": prompt}]
            response = self.llm(messages)

            # å°†å“åº”è½¬æ¢ä¸ºå…¼å®¹æ ¼å¼
            class ResponseWrapper:
                def __init__(self, content):
                    self.content = content
                    self.tool_calls = None  # AgentScope ç›®å‰ä¸æ”¯æŒè‡ªåŠ¨ tool calling

            response = ResponseWrapper(response.get("content", ""))

            print(f"ğŸ“¥ LLMå“åº”ç±»å‹: {type(response)}")

            # æ£€æŸ¥æ˜¯å¦æœ‰å·¥å…·è°ƒç”¨
            tool_calls = []
            if hasattr(response, 'tool_calls') and response.tool_calls:
                tool_calls = response.tool_calls
                print(f"ğŸ› ï¸ LLMå†³å®šæ‰§è¡Œ {len(tool_calls)} ä¸ªå·¥å…·è°ƒç”¨")

                # æ‰§è¡Œå·¥å…·è°ƒç”¨
                execution_results = []
                for tool_call in tool_calls:
                    tool_name = tool_call['name']
                    tool_args = tool_call['args']

                    print(f"  ğŸ“ è°ƒç”¨å·¥å…·: {tool_name}")
                    print(f"     å‚æ•°: {tool_args}")

                    # ç›´æ¥è°ƒç”¨å¯¹åº”çš„å·¥å…·å‡½æ•°
                    tool_function = next(
                        (tool for tool in self.memory_tools if tool.name == tool_name),
                        None
                    )

                    if tool_function:
                        result = tool_function.invoke(tool_args)
                        execution_results.append({
                            'tool_name': tool_name,
                            'args': tool_args,
                            'result': result
                        })
                    else:
                        print(f"    âŒ æœªæ‰¾åˆ°å·¥å…·: {tool_name}")
                        execution_results.append({
                            'tool_name': tool_name,
                            'args': tool_args,
                            'result': {'status': 'failed', 'error': f'Tool not found: {tool_name}'}
                        })

                return {
                    'status': 'success',
                    'mode': 'operations_executed',
                    'operations_count': len(tool_calls),
                    'execution_results': execution_results,
                    'llm_reasoning': response.content,
                    'date': date
                }
            else:
                # æ²¡æœ‰å·¥å…·è°ƒç”¨ï¼ŒLLMå¯èƒ½è®¤ä¸ºä¸éœ€è¦æ“ä½œ
                reasoning = response.content if hasattr(response, 'content') else str(response)
                print(f"ğŸ’­ LLMåˆ†æ: {reasoning}")

                return {
                    'status': 'success',
                    'mode': 'no_action',
                    'reasoning': reasoning,
                    'date': date
                }

        except Exception as e:
            print(f"âŒ LLMè®°å¿†ç®¡ç†å†³ç­–å¤±è´¥: {str(e)}")
            import traceback
            traceback.print_exc()
            return {
                'status': 'failed',
                'error': str(e),
                'date': date
            }
