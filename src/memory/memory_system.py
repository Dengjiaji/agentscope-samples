import os
from typing import Dict, Any

from src.llm.models import get_model
from src.tools.memory_tools import create_memory_toolkit
from src.agents.prompt_loader import PromptLoader

MEMORY_AVAILABLE = True
LLM_AVAILABLE = True
MEMORY_TOOLS_AVAILABLE = True


class LLMMemoryDecisionSystem:
    """åŸºäºLLMçš„è®°å¿†ç®¡ç†å†³ç­–ç³»ç»Ÿ"""

    def __init__(self):
        self.toolkit = None
        self.prompt_loader = PromptLoader()

        if LLM_AVAILABLE and MEMORY_TOOLS_AVAILABLE:
            model_name = os.getenv('MEMORY_LLM_MODEL', 'gpt-4o-mini')
            model_provider_str = os.getenv('MEMORY_LLM_PROVIDER', 'OPENAI')
            from src.llm.models import ModelProvider

            # è½¬æ¢ä¸ºModelProvideræšä¸¾
            if hasattr(ModelProvider, model_provider_str):
                model_provider = getattr(ModelProvider, model_provider_str)
            else:
                print(f"æœªçŸ¥çš„æ¨¡å‹æä¾›å•†: {model_provider_str}ï¼Œä½¿ç”¨é»˜è®¤OPENAI")
                model_provider = ModelProvider.OPENAI

            api_keys = {}
            if model_provider == ModelProvider.OPENAI:
                api_keys['OPENAI_API_KEY'] = os.getenv('OPENAI_API_KEY')
            elif model_provider == ModelProvider.ANTHROPIC:
                api_keys['ANTHROPIC_API_KEY'] = os.getenv('ANTHROPIC_API_KEY')

            # åˆ›å»ºè®°å¿†ç®¡ç†å·¥å…·åŒ…ï¼ˆAgentScope Toolkitï¼‰
            from src.tools.memory_tools import create_memory_toolkit
            self.toolkit = create_memory_toolkit()
            # ä½¿ç”¨ AgentScope æ¨¡å‹
            self.llm = get_model(model_name, model_provider, api_keys)
            self.llm_with_tools = self.llm
            self.llm_available = True
            print(f"LLMè®°å¿†å†³ç­–ç³»ç»Ÿå·²å¯ç”¨ï¼ˆ{model_provider_str}: {model_name}ï¼‰")
            print(f"å·²åŠ è½½ {len(self.toolkit.tools)} ä¸ªè®°å¿†ç®¡ç†å·¥å…·")

    def generate_memory_decision_prompt(self, performance_data: Dict[str, Any], date: str) -> str:
        """ç”ŸæˆLLMè®°å¿†å†³ç­–çš„prompt"""
        pm_signals = performance_data.get('pm_signals', {})
        actual_returns = performance_data.get('actual_returns', {})
        analyst_signals = performance_data.get('analyst_signals', {})
        tickers = performance_data.get('tickers', [])

        pm_signals_section = self._build_pm_signals_section(tickers, pm_signals, actual_returns)
        analyst_signals_section = self._build_analyst_signals_section(analyst_signals, tickers, actual_returns)

        return self.prompt_loader.load_prompt(
            agent_type="memory",
            prompt_name="memory_decision",
            variables={
                "date": date,
                "pm_signals_section": pm_signals_section,
                "analyst_signals_section": analyst_signals_section,
            }
        )

    def _build_pm_signals_section(self, tickers, pm_signals, actual_returns) -> str:
        """æ„å»ºPMä¿¡å·éƒ¨åˆ†"""
        lines = []
        for ticker in tickers:
            pm_signal = pm_signals.get(ticker, {})
            actual_return = actual_returns.get(ticker, 0)
            lines.append(f"\n{ticker}:")
            lines.append(f"\n  PMå†³ç­–: {pm_signal.get('signal', 'N/A')} (ç½®ä¿¡åº¦: {pm_signal.get('confidence', 'N/A')}%)")
            lines.append(f"\n  å®é™…æ”¶ç›Š: {actual_return:.2%}")
        return "".join(lines)

    def _build_analyst_signals_section(self, analyst_signals, tickers, actual_returns) -> str:
        """æ„å»ºåˆ†æå¸ˆä¿¡å·éƒ¨åˆ†"""
        lines = []
        for analyst, signals in analyst_signals.items():
            lines.append(f"\n\n**{analyst}:**")
            for ticker in tickers:
                if ticker in signals and ticker in actual_returns:
                    analyst_signal = signals[ticker]
                    actual_return = actual_returns[ticker]
                    lines.append(f"\n  {ticker}: é¢„æµ‹ {analyst_signal}, å®é™… {actual_return:.2%}")
        return "".join(lines)

    def _parse_json_response(self, response_content: str) -> dict:
        """è§£æ JSON å“åº”ï¼ˆå¯èƒ½å¸¦æœ‰ ```json``` åŒ…è£¹ï¼‰"""
        import json
        json_start = response_content.find("{")
        json_end = response_content.rfind("}") + 1
        if json_start != -1 and json_end > json_start:
            json_str = response_content[json_start:json_end]
            return json.loads(json_str)
        return json.loads(response_content)

    def make_llm_memory_decision_with_tools(self, performance_data: Dict[str, Any], date: str) -> Dict[str, Any]:
        """ä½¿ç”¨LLMè¿›è¡Œè®°å¿†ç®¡ç†å†³ç­–"""

        if not getattr(self, "llm_available", False):
            print("âš ï¸ LLMä¸å¯ç”¨ï¼Œè·³è¿‡è®°å¿†ç®¡ç†")
            return {'status': 'skipped', 'reason': 'LLMä¸å¯ç”¨'}

        try:
            # ç”Ÿæˆprompt
            prompt = self.generate_memory_decision_prompt(performance_data, date)

            print(f"\nğŸ¤– æ­£åœ¨è¯·æ±‚LLMè¿›è¡Œè®°å¿†ç®¡ç†å†³ç­–...")
            print(f"ğŸ“ Prompté•¿åº¦: {len(prompt)} å­—ç¬¦")

            # è°ƒç”¨ LLMï¼ˆä½¿ç”¨ AgentScope æ ¼å¼ï¼‰
            print(f"   ğŸ“ Prompt:{prompt}")
            messages = [{"role": "user", "content": prompt}]
            response = self.llm(messages)
            response["content"]

            print(f"   ğŸ“¥ LLMå“åº”:{response}")

            # è§£æ JSON å“åº”
            decision_data = self._parse_json_response(response["content"])
            reasoning = decision_data.get("reflection_summary", "")
            need_tool = decision_data.get("need_tool", False)
            
            # æ‰§è¡Œå·¥å…·è°ƒç”¨
            execution_results = []
            if need_tool and "selected_tool" in decision_data:
                selected_tools = decision_data["selected_tool"]
                if not isinstance(selected_tools, list):
                    selected_tools = [selected_tools]
                
                print(f"ğŸ› ï¸ LLMå†³å®šæ‰§è¡Œ {len(selected_tools)} ä¸ªå·¥å…·è°ƒç”¨")
                
                for tool_selection in selected_tools:
                    tool_name = tool_selection.get("tool_name")
                    tool_reason = tool_selection.get("reason", "")
                    tool_params = tool_selection.get("parameters", {})
                    
                    print(f"  ğŸ“ è°ƒç”¨å·¥å…·: {tool_name}")
                    print(f"     é€‰æ‹©ç†ç”±: {tool_reason}")
                    print(f"     å‚æ•°: {tool_params}")
                    
                    try:
                        if tool_name in self.toolkit.tools:
                            tool_func = self.toolkit.tools[tool_name].original_func
                            result = tool_func(**tool_params)
                        else:
                            result = {'status': 'failed', 'error': f'Tool not found: {tool_name}'}
                        
                        execution_results.append({
                            'tool_name': tool_name,
                            'selection_reason': tool_reason,
                            'args': tool_params,
                            'result': result
                        })
                        print(f"  âœ… å·¥å…·æ‰§è¡Œå®Œæˆ: {result.get('status', 'unknown')}")
                    except Exception as e:
                        print(f"  âŒ å·¥å…·æ‰§è¡Œå¤±è´¥: {e}")
                        execution_results.append({
                            'tool_name': tool_name,
                            'selection_reason': tool_reason,
                            'args': tool_params,
                            'error': str(e)
                        })
                
                return {
                    'status': 'success',
                    'mode': 'operations_executed',
                    'operations_count': len(execution_results),
                    'execution_results': execution_results,
                    'llm_reasoning': reasoning,
                    'date': date
                }
            else:
                print(f"ğŸ’­ LLMåˆ†æ: {reasoning}")
                return {
                    'status': 'success',
                    'mode': 'no_action',
                    'reasoning': reasoning,
                    'date': date
                }

        except Exception as e:
            print(f"âŒ LLMè®°å¿†ç®¡ç†å†³ç­–å¤±è´¥: {str(e)}")
            import traceback
            traceback.print_exc()
            return {
                'status': 'failed',
                'error': str(e),
                'date': date
            }
