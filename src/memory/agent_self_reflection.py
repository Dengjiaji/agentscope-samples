#!/usr/bin/env python3
"""
Agentè‡ªæˆ‘å¤ç›˜ç³»ç»Ÿ
æ¯ä¸ªåˆ†æå¸ˆï¼ˆåŒ…æ‹¬PMï¼‰ç‹¬ç«‹è¯„ä¼°è‡ªå·±çš„è¡¨ç°å¹¶ç®¡ç†è®°å¿†
ä½¿ç”¨ç±»ä¼¼ analyst åˆ†æé˜¶æ®µçš„ LLM æ™ºèƒ½å·¥å…·é€‰æ‹©æœºåˆ¶
"""

import os
import json
import logging
from typing import Dict, List, Any, Optional
from datetime import datetime
from pathlib import Path
import pdb
# å°è¯•å¯¼å…¥ AgentScope ç›¸å…³æ¨¡å—
try:
    from src.graph.state import create_message
    from src.llm.agentscope_models import get_model, ModelProvider
    from src.tools.memory_management_tools import get_memory_tools
    LANGCHAIN_AVAILABLE = True  # ä¿æŒå˜é‡åä»¥å‘åå…¼å®¹
except ImportError as e:
    LANGCHAIN_AVAILABLE = False
    print(f"âš ï¸ LangChainæ¨¡å—æœªå®‰è£…: {e}")

logger = logging.getLogger(__name__)


class MemoryOperationLogger:
    """è®°å¿†æ“ä½œæ—¥å¿—è®°å½•å™¨"""
    
    def __init__(self, base_dir: str):
        """
        åˆå§‹åŒ–æ—¥å¿—è®°å½•å™¨
        
        Args:
            base_dir: åŸºç¡€ç›®å½•ï¼ˆconfig_nameï¼‰
        """
        self.log_dir = Path("logs_and_memory") / base_dir / "memory_operations"
        self.log_dir.mkdir(parents=True, exist_ok=True)
        
        # å½“å‰æ—¥æœŸçš„æ—¥å¿—æ–‡ä»¶
        today = datetime.now().strftime("%Y%m%d")
        self.log_file = self.log_dir / f"memory_ops_{today}.jsonl"
    
    def log_operation(
        self,
        agent_id: str,
        operation_type: str,
        tool_name: str,
        args: Dict[str, Any],
        result: Dict[str, Any],
        context: Optional[Dict[str, Any]] = None
    ):
        """
        è®°å½•è®°å¿†æ“ä½œ
        
        Args:
            agent_id: Agent ID
            operation_type: æ“ä½œç±»å‹ (self_reflection, central_review)
            tool_name: å·¥å…·åç§°
            args: å·¥å…·å‚æ•°
            result: æ‰§è¡Œç»“æœ
            context: é¢å¤–ä¸Šä¸‹æ–‡
        """
        log_entry = {
            'timestamp': datetime.now().isoformat(),
            'agent_id': agent_id,
            'operation_type': operation_type,
            'tool_name': tool_name,
            'args': args,
            'result': result,
            'context': context or {}
        }
        
        try:
            with open(self.log_file, 'a', encoding='utf-8') as f:
                f.write(json.dumps(log_entry, ensure_ascii=False) + '\n')
        except Exception as e:
            logger.error(f"è®°å½•æ—¥å¿—å¤±è´¥: {e}")
    
    def get_today_operations(self, agent_id: Optional[str] = None) -> List[Dict[str, Any]]:
        """
        è·å–ä»Šæ—¥çš„è®°å¿†æ“ä½œè®°å½•
        
        Args:
            agent_id: å¦‚æœæŒ‡å®šï¼Œåªè¿”å›è¯¥Agentçš„æ“ä½œ
        
        Returns:
            æ“ä½œè®°å½•åˆ—è¡¨
        """
        if not self.log_file.exists():
            return []
        
        operations = []
        try:
            with open(self.log_file, 'r', encoding='utf-8') as f:
                for line in f:
                    try:
                        entry = json.loads(line.strip())
                        if agent_id is None or entry.get('agent_id') == agent_id:
                            operations.append(entry)
                    except json.JSONDecodeError:
                        continue
        except Exception as e:
            logger.error(f"è¯»å–æ—¥å¿—å¤±è´¥: {e}")
        
        return operations


class AgentSelfReflectionSystem:
    """åˆ†æå¸ˆè‡ªæˆ‘å¤ç›˜ç³»ç»Ÿ - ä½¿ç”¨ LLM æ™ºèƒ½å·¥å…·é€‰æ‹©"""
    
    def __init__(
        self,
        agent_id: str,
        agent_role: str,
        base_dir: str = "mock",
        streamer=None
    ):
        """
        åˆå§‹åŒ–è‡ªæˆ‘å¤ç›˜ç³»ç»Ÿ
        
        Args:
            agent_id: Agent IDï¼ˆå¦‚ 'technical_analyst' æˆ– 'portfolio_manager'ï¼‰
            agent_role: Agentè§’è‰²æè¿°ï¼ˆå¦‚ 'Technical Analyst'ï¼‰
            base_dir: åŸºç¡€ç›®å½•ï¼ˆconfig_nameï¼‰
            streamer: æ¶ˆæ¯å¹¿æ’­å™¨ï¼ˆç”¨äºå‘å‰ç«¯å‘é€memoryæ“ä½œæ¶ˆæ¯ï¼‰
        """
        self.agent_id = agent_id
        self.agent_role = agent_role
        self.base_dir = base_dir
        self.streamer = streamer
        
        # åˆå§‹åŒ–æ—¥å¿—è®°å½•å™¨
        self.logger_system = MemoryOperationLogger(base_dir)
        
        # æ£€æŸ¥LangChainæ˜¯å¦å¯ç”¨
        if not LANGCHAIN_AVAILABLE:
            logger.warning(f"{agent_role} è‡ªæˆ‘å¤ç›˜ç³»ç»Ÿåˆå§‹åŒ–å¤±è´¥ï¼šLangChainä¸å¯ç”¨")
            self.llm_available = False
            return
        
        # åˆå§‹åŒ–LLMï¼ˆä½¿ç”¨ä¸è®°å¿†ç®¡ç†ç›¸åŒçš„é…ç½®ï¼‰
        try:
            model_name = os.getenv('MEMORY_LLM_MODEL', 'gpt-4o-mini')
            model_provider_str = os.getenv('MEMORY_LLM_PROVIDER', 'OPENAI')
            
            # è½¬æ¢ä¸ºModelProvideræšä¸¾
            model_provider = getattr(ModelProvider, model_provider_str, ModelProvider.OPENAI)
            
            api_keys = {}
            if model_provider == ModelProvider.OPENAI:
                api_keys['OPENAI_API_KEY'] = os.getenv('OPENAI_API_KEY')
            elif model_provider == ModelProvider.ANTHROPIC:
                api_keys['ANTHROPIC_API_KEY'] = os.getenv('ANTHROPIC_API_KEY')
            
            # åˆ›å»ºè®°å¿†ç®¡ç†å·¥å…·åŒ…ï¼ˆAgentScope Toolkitï¼‰
            from src.tools.memory_management_tools import create_memory_toolkit
            self.toolkit = create_memory_toolkit()
            
            # è®¾ç½®memoryå·¥å…·çš„streamer
            if self.streamer:
                from src.tools.memory_management_tools import set_memory_tools_streamer
                set_memory_tools_streamer(self.streamer)
            
            # ä½¿ç”¨ AgentScope æ¨¡å‹
            self.llm = get_model(model_name, model_provider, api_keys)
            
            # æ„å»ºå¯ç”¨å·¥å…·çš„æè¿°ï¼ˆç±»ä¼¼ LLMToolSelectorï¼‰
            self.available_memory_tools = self._build_tool_descriptions()
            
            self.llm_available = True
            print(f"âœ… {agent_role} è‡ªæˆ‘å¤ç›˜ç³»ç»Ÿå·²åˆå§‹åŒ–ï¼ˆLLM æ™ºèƒ½å·¥å…·é€‰æ‹©æ¨¡å¼ï¼‰")
            print(f"   å¯ç”¨è®°å¿†å·¥å…·: {', '.join(self.toolkit.list_functions())}")
            
        except Exception as e:
            logger.error(f"{agent_role} è‡ªæˆ‘å¤ç›˜ç³»ç»Ÿåˆå§‹åŒ–å¤±è´¥: {e}")
            self.llm_available = False
    
    def _build_tool_descriptions(self) -> Dict[str, Dict[str, str]]:
        """æ„å»ºè®°å¿†ç®¡ç†å·¥å…·çš„æè¿°ä¿¡æ¯"""
        return {
            "search_and_update_analyst_memory": {
                "name": "search_and_update_analyst_memory",
                "description": "æœç´¢å¹¶æ›´æ–°åˆ†æå¸ˆçš„è®°å¿†å†…å®¹ã€‚é€‚ç”¨äºé¢„æµ‹æ–¹å‘é”™è¯¯ä½†ä¸ç®—ç¦»è°±ã€åˆ†ææ–¹æ³•éœ€è¦å¾®è°ƒä¼˜åŒ–çš„æƒ…å†µã€‚",
                "when_to_use": "é¢„æµ‹é”™è¯¯ä½†ä¸ä¸¥é‡ï¼Œéœ€è¦ä¿®æ­£åˆ†ææ–¹æ³•æˆ–è¡¥å……ç»éªŒæ•™è®­",
                "parameters": "query(æœç´¢å†…å®¹), memory_id(é€šå¸¸å¡«'auto'), analyst_id(ä½ çš„ID), new_content(æ–°è®°å¿†), reason(æ›´æ–°åŸå› )"
            },
            "search_and_delete_analyst_memory": {
                "name": "search_and_delete_analyst_memory",
                "description": "æœç´¢å¹¶åˆ é™¤åˆ†æå¸ˆçš„ä¸¥é‡é”™è¯¯è®°å¿†ã€‚é€‚ç”¨äºè¿ç»­ä¸¥é‡é¢„æµ‹é”™è¯¯ã€ä½¿ç”¨æ ¹æœ¬é”™è¯¯çš„åˆ†æé€»è¾‘çš„æƒ…å†µã€‚",
                "when_to_use": "è¿ç»­å¤šæ¬¡ä¸¥é‡é”™è¯¯ï¼Œåˆ†æé€»è¾‘å­˜åœ¨æ ¹æœ¬æ€§é—®é¢˜",
                "parameters": "query(æœç´¢å†…å®¹), memory_id(é€šå¸¸å¡«'auto'), analyst_id(ä½ çš„ID), reason(åˆ é™¤åŸå› )"
            }
        }
    
    def generate_analyst_reflection_prompt(
        self,
        date: str,
        my_signals: Dict[str, Any],
        actual_returns: Dict[str, float],
        pm_decisions: Dict[str, Any],
        context: Optional[Dict[str, Any]] = None
    ) -> str:
        """
        ç”Ÿæˆåˆ†æå¸ˆè‡ªæˆ‘å¤ç›˜çš„prompt
        
        Args:
            date: äº¤æ˜“æ—¥æœŸ
            my_signals: æˆ‘çš„é¢„æµ‹ä¿¡å·
            actual_returns: å®é™…æ”¶ç›Šç‡
            pm_decisions: PMçš„æœ€ç»ˆå†³ç­–
            context: é¢å¤–ä¸Šä¸‹æ–‡
        """
        prompt = f"""ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„ {self.agent_role}ï¼Œç°åœ¨éœ€è¦å¯¹ {date} çš„åˆ†æè¡¨ç°è¿›è¡Œè‡ªæˆ‘å¤ç›˜ã€‚

# ä½ çš„èŒè´£
ä½œä¸º {self.agent_role}ï¼Œä½ éœ€è¦ï¼š
1. å®¢è§‚è¯„ä¼°è‡ªå·±çš„é¢„æµ‹å‡†ç¡®æ€§
2. åˆ†æé¢„æµ‹é”™è¯¯çš„åŸå› 
3. å†³å®šæ˜¯å¦éœ€è¦æ›´æ–°æˆ–åˆ é™¤é”™è¯¯çš„è®°å¿†
4. æ€»ç»“ç»éªŒæ•™è®­ï¼Œæå‡æœªæ¥è¡¨ç°

# ä»Šæ—¥å¤ç›˜æ•°æ®

## ä½ çš„é¢„æµ‹ä¿¡å·
"""
        
        # æ·»åŠ è‡ªå·±çš„ä¿¡å·
        for ticker, signal_data in my_signals.items():
            actual_return = actual_returns.get(ticker, 0)
            signal = signal_data.get('signal', 'N/A')
            confidence = signal_data.get('confidence', 'N/A')
            reasoning = signal_data.get('reasoning', '')
            
            # åˆ¤æ–­é¢„æµ‹æ˜¯å¦æ­£ç¡®
            is_correct = self._evaluate_prediction(signal, actual_return)
            status_emoji = "âœ…" if is_correct else "âŒ"
            
            prompt += f"""
{ticker}: {status_emoji}
  - ä½ çš„ä¿¡å·: {signal} (ç½®ä¿¡åº¦: {confidence}%)
  - ä½ çš„ç†ç”±: {reasoning[:200] if reasoning else 'N/A'}
  - å®é™…æ”¶ç›Š: {actual_return:.2%}
  - PMæœ€ç»ˆå†³ç­–: {pm_decisions.get(ticker, {}).get('action', 'N/A')}
"""
        
        # æ·»åŠ é¢å¤–ä¸Šä¸‹æ–‡
        if context:
            prompt += "\n## é¢å¤–ä¸Šä¸‹æ–‡\n"
            if 'market_condition' in context:
                prompt += f"- å¸‚åœºç¯å¢ƒ: {context['market_condition']}\n"
        
        prompt += f"""

# è‡ªæˆ‘å¤ç›˜æŒ‡å¯¼

è¯·æŒ‰ä»¥ä¸‹æ ‡å‡†è¯„ä¼°è‡ªå·±çš„è¡¨ç°ï¼š

## è¯„ä¼°æ ‡å‡†
1. **é¢„æµ‹å‡†ç¡®æ€§**: ä¿¡å·æ–¹å‘æ˜¯å¦ä¸å®é™…æ”¶ç›Šä¸€è‡´ï¼Ÿ
2. **ç½®ä¿¡åº¦æ ¡å‡†**: é«˜ç½®ä¿¡åº¦çš„é¢„æµ‹æ˜¯å¦æ›´å‡†ç¡®ï¼Ÿ
3. **åˆ†æé€»è¾‘**: ä½¿ç”¨çš„åˆ†ææ–¹æ³•æ˜¯å¦åˆç†ï¼Ÿ
4. **å¸‚åœºç†è§£**: æ˜¯å¦æ­£ç¡®ç†è§£äº†å¸‚åœºç¯å¢ƒï¼Ÿ

## å¯ç”¨çš„è®°å¿†ç®¡ç†å·¥å…·

ä½ å¯ä»¥é€‰æ‹©ä½¿ç”¨ä»¥ä¸‹å·¥å…·æ¥ç®¡ç†ä½ çš„è®°å¿†ï¼š

### å·¥å…· 1: search_and_update_analyst_memory
- **åŠŸèƒ½**: æœç´¢å¹¶æ›´æ–°è®°å¿†å†…å®¹
- **é€‚ç”¨åœºæ™¯**: é¢„æµ‹æ–¹å‘é”™è¯¯ä½†ä¸ç®—ç¦»è°±ã€åˆ†ææ–¹æ³•éœ€è¦å¾®è°ƒä¼˜åŒ–
- **å‚æ•°**:
  * query: æœç´¢æŸ¥è¯¢å†…å®¹ï¼ˆæè¿°è¦æ‰¾ä»€ä¹ˆè®°å¿†ï¼‰
  * memory_id: å¡« "auto" è®©ç³»ç»Ÿè‡ªåŠ¨æœç´¢
  * analyst_id: "{self.agent_id}"
  * new_content: æ–°çš„æ­£ç¡®è®°å¿†å†…å®¹
  * reason: æ›´æ–°åŸå› 

### å·¥å…· 2: search_and_delete_analyst_memory
- **åŠŸèƒ½**: æœç´¢å¹¶åˆ é™¤ä¸¥é‡é”™è¯¯çš„è®°å¿†
- **é€‚ç”¨åœºæ™¯**: è¿ç»­å¤šæ¬¡ä¸¥é‡é”™è¯¯ã€åˆ†æé€»è¾‘å­˜åœ¨æ ¹æœ¬æ€§é—®é¢˜
- **å‚æ•°**:
  * query: æœç´¢æŸ¥è¯¢å†…å®¹
  * memory_id: å¡« "auto"
  * analyst_id: "{self.agent_id}"
  * reason: åˆ é™¤åŸå› 

## å†³ç­–è¦æ±‚

è¯·æ ¹æ®ä½ çš„è¡¨ç°ï¼Œå†³å®šæ˜¯å¦éœ€è¦è°ƒç”¨è®°å¿†ç®¡ç†å·¥å…·ï¼š

1. **è¡¨ç°è‰¯å¥½** â†’ ä¸éœ€è¦è°ƒç”¨å·¥å…·ï¼Œç›´æ¥æ€»ç»“ç»éªŒå³å¯
2. **è¡¨ç°ä¸€èˆ¬** â†’ è€ƒè™‘ä½¿ç”¨ `search_and_update_analyst_memory` ä¿®æ­£è®°å¿†
3. **è¡¨ç°å¾ˆå·®** â†’ è€ƒè™‘ä½¿ç”¨ `search_and_delete_analyst_memory` åˆ é™¤é”™è¯¯è®°å¿†

## è¾“å‡ºæ ¼å¼

è¯·ä»¥ JSON æ ¼å¼è¿”å›ï¼ŒåŒ…å«ä»¥ä¸‹å­—æ®µï¼š

```json
{{
  "reflection_summary": "ä½ çš„å¤ç›˜æ€»ç»“ï¼ˆ1-2æ®µè¯ï¼‰",
  "need_tool": true/false,
  "selected_tool": {{
    "tool_name": "search_and_update_analyst_memory" æˆ– "search_and_delete_analyst_memory",
    "reason": "ä¸ºä»€ä¹ˆé€‰æ‹©è¿™ä¸ªå·¥å…·",
    "parameters": {{
      "query": "æœç´¢æŸ¥è¯¢",
      "memory_id": "auto",
      "analyst_id": "{self.agent_id}",
      "new_content": "æ–°å†…å®¹ï¼ˆä»…updateéœ€è¦ï¼‰",
      "reason": "æ“ä½œåŸå› "
    }}
  }}
}}
```

**æ³¨æ„ï¼š**
- å¦‚æœ `need_tool` ä¸º falseï¼Œåˆ™ä¸éœ€è¦å¡«å†™ `selected_tool` å­—æ®µ
- åªèƒ½æ“ä½œä½ è‡ªå·±ï¼ˆ{self.agent_id}ï¼‰çš„è®°å¿†
- è°¨æ…å†³ç­–æ˜¯å¦çœŸçš„éœ€è¦è°ƒç”¨å·¥å…·

è¯·åŸºäºä½ çš„ä¸“ä¸šåˆ¤æ–­ï¼Œè¯šå®åœ°è¯„ä¼°è‡ªå·±çš„è¡¨ç°å¹¶åšå‡ºæ˜æ™ºçš„å†³ç­–ã€‚
"""
        
        return prompt
    
    def generate_pm_reflection_prompt(
        self,
        date: str,
        pm_decisions: Dict[str, Any],
        analyst_signals: Dict[str, Dict[str, Any]],
        actual_returns: Dict[str, float],
        portfolio_summary: Dict[str, Any],
        context: Optional[Dict[str, Any]] = None
    ) -> str:
        """
        ç”ŸæˆPortfolio Managerè‡ªæˆ‘å¤ç›˜çš„prompt
        
        Args:
            date: äº¤æ˜“æ—¥æœŸ
            pm_decisions: PMçš„å†³ç­–
            analyst_signals: æ‰€æœ‰åˆ†æå¸ˆçš„ä¿¡å·
            actual_returns: å®é™…æ”¶ç›Šç‡
            portfolio_summary: Portfolioæ€»ç»“
            context: é¢å¤–ä¸Šä¸‹æ–‡
        """
        prompt = f"""ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„ Portfolio Managerï¼Œç°åœ¨éœ€è¦å¯¹ {date} çš„æŠ•èµ„å†³ç­–è¿›è¡Œè‡ªæˆ‘å¤ç›˜ã€‚

# ä½ çš„èŒè´£
ä½œä¸º Portfolio Managerï¼Œä½ éœ€è¦ï¼š
1. è¯„ä¼°è‡ªå·±çš„å†³ç­–è´¨é‡
2. åˆ†æå†³ç­–å¤±è¯¯çš„åŸå› 
3. åæ€æ˜¯å¦æ­£ç¡®ç»¼åˆäº†åˆ†æå¸ˆæ„è§
4. å†³å®šæ˜¯å¦éœ€è¦æ›´æ–°å†³ç­–è®°å¿†
5. æ€»ç»“ç»éªŒæ•™è®­

# ä»Šæ—¥å¤ç›˜æ•°æ®

## Portfolio è¡¨ç°
"""
        
        if portfolio_summary:
            total_value = portfolio_summary.get('total_value', 0)
            pnl_percent = portfolio_summary.get('pnl_percent', 0)
            cash = portfolio_summary.get('cash', 0)
            
            prompt += f"""
- æ€»èµ„äº§: ${total_value:,.2f}
- æ”¶ç›Šç‡: {pnl_percent:+.2f}%
- ç°é‡‘: ${cash:,.2f}
"""
        
        prompt += "\n## ä½ çš„æŠ•èµ„å†³ç­– vs å®é™…ç»“æœ\n"
        
        # æ·»åŠ PMå†³ç­–å’Œå®é™…ç»“æœ
        for ticker, decision_data in pm_decisions.items():
            actual_return = actual_returns.get(ticker, 0)
            action = decision_data.get('action', 'N/A')
            quantity = decision_data.get('quantity', 0)
            confidence = decision_data.get('confidence', 'N/A')
            reasoning = decision_data.get('reasoning', '')
            
            # åˆ¤æ–­å†³ç­–æ˜¯å¦æ­£ç¡®
            is_correct = self._evaluate_pm_decision(action, actual_return)
            status_emoji = "âœ…" if is_correct else "âŒ"
            
            prompt += f"""
{ticker}: {status_emoji}
  - ä½ çš„å†³ç­–: {action}
  - æ•°é‡: {quantity} è‚¡
  - ç½®ä¿¡åº¦: {confidence}%
  - å†³ç­–ç†ç”±: {reasoning[:200] if reasoning else 'N/A'}
  - å®é™…æ”¶ç›Š: {actual_return:.2%}
"""
            
            # æ·»åŠ åˆ†æå¸ˆæ„è§å¯¹æ¯”
            prompt += "  - åˆ†æå¸ˆæ„è§:\n"
            for analyst_id, signals in analyst_signals.items():
                if ticker in signals:
                    analyst_signal = signals[ticker]
                    prompt += f"    * {analyst_id}: {analyst_signal}\n"
        
        # æ·»åŠ é¢å¤–ä¸Šä¸‹æ–‡
        if context:
            prompt += "\n## é¢å¤–ä¸Šä¸‹æ–‡\n"
            if 'market_condition' in context:
                prompt += f"- å¸‚åœºç¯å¢ƒ: {context['market_condition']}\n"
            if 'risk_metrics' in context:
                prompt += f"- é£é™©æŒ‡æ ‡: {context['risk_metrics']}\n"
        # pdb.set_trace()
        prompt += f"""

# è‡ªæˆ‘å¤ç›˜æŒ‡å¯¼

è¯·æŒ‰ä»¥ä¸‹æ ‡å‡†è¯„ä¼°è‡ªå·±çš„è¡¨ç°ï¼š

## è¯„ä¼°æ ‡å‡†
1. **å†³ç­–å‡†ç¡®æ€§**: æŠ•èµ„å†³ç­–æ˜¯å¦å¸¦æ¥æ­£æ”¶ç›Šï¼Ÿ
2. **ä¿¡æ¯æ•´åˆ**: æ˜¯å¦æ­£ç¡®ç»¼åˆäº†åˆ†æå¸ˆæ„è§ï¼Ÿ
3. **é£é™©æ§åˆ¶**: ä»“ä½ç®¡ç†æ˜¯å¦åˆç†ï¼Ÿ
4. **æ‰§è¡Œçºªå¾‹**: æ˜¯å¦éµå¾ªäº†æ—¢å®šç­–ç•¥ï¼Ÿ

## å¯ç”¨çš„è®°å¿†ç®¡ç†å·¥å…·

ä½ å¯ä»¥é€‰æ‹©ä½¿ç”¨ä»¥ä¸‹å·¥å…·æ¥ç®¡ç†ä½ çš„è®°å¿†ï¼š

### å·¥å…· 1: search_and_update_analyst_memory
- **åŠŸèƒ½**: æœç´¢å¹¶æ›´æ–°è®°å¿†å†…å®¹
- **é€‚ç”¨åœºæ™¯**: å†³ç­–æ–¹å‘é”™è¯¯ä½†æŸå¤±å¯æ§ã€ä¿¡æ¯æ•´åˆæ–¹æ³•éœ€è¦ä¼˜åŒ–
- **å‚æ•°**:
  * query: æœç´¢æŸ¥è¯¢å†…å®¹
  * memory_id: å¡« "auto"
  * analyst_id: "portfolio_manager"
  * new_content: æ–°çš„å†³ç­–ç»éªŒ
  * reason: æ›´æ–°åŸå› 

### å·¥å…· 2: search_and_delete_analyst_memory
- **åŠŸèƒ½**: æœç´¢å¹¶åˆ é™¤ä¸¥é‡é”™è¯¯çš„è®°å¿†
- **é€‚ç”¨åœºæ™¯**: å†³ç­–å¯¼è‡´é‡å¤§æŸå¤±ã€ä½¿ç”¨é”™è¯¯å†³ç­–æ¡†æ¶
- **å‚æ•°**:
  * query: æœç´¢æŸ¥è¯¢å†…å®¹
  * memory_id: å¡« "auto"
  * analyst_id: "portfolio_manager"
  * reason: åˆ é™¤åŸå› 

## å†³ç­–è¦æ±‚

è¯·æ ¹æ®ä½ çš„è¡¨ç°ï¼Œå†³å®šæ˜¯å¦éœ€è¦è°ƒç”¨è®°å¿†ç®¡ç†å·¥å…·ï¼š

1. **è¡¨ç°è‰¯å¥½** â†’ ä¸éœ€è¦è°ƒç”¨å·¥å…·ï¼Œæ€»ç»“æˆåŠŸç»éªŒå³å¯
2. **è¡¨ç°ä¸€èˆ¬** â†’ è€ƒè™‘ä½¿ç”¨ `search_and_update_analyst_memory` ä¼˜åŒ–å†³ç­–æ–¹æ³•
3. **è¡¨ç°å¾ˆå·®** â†’ è€ƒè™‘ä½¿ç”¨ `search_and_delete_analyst_memory` åˆ é™¤é”™è¯¯å†³ç­–æ¡†æ¶

## è¾“å‡ºæ ¼å¼

è¯·ä»¥ JSON æ ¼å¼è¿”å›ï¼š

```json
{{
  "reflection_summary": "ä½ çš„å¤ç›˜æ€»ç»“",
  "need_tool": true/false,
  "selected_tool": {{
    "tool_name": "å·¥å…·åç§°",
    "reason": "é€‰æ‹©åŸå› ",
    "parameters": {{
      "query": "æœç´¢æŸ¥è¯¢",
      "memory_id": "auto",
      "analyst_id": "portfolio_manager",
      "new_content": "æ–°å†…å®¹ï¼ˆä»…updateéœ€è¦ï¼‰",
      "reason": "æ“ä½œåŸå› "
    }}
  }}
}}
```

**æ³¨æ„ï¼š**
- å¦‚æœ `need_tool` ä¸º falseï¼Œåˆ™ä¸éœ€è¦ `selected_tool` å­—æ®µ
- è¯šå®è¯„ä¼°å†³ç­–è´¨é‡

è¯·åŸºäºä½ ä½œä¸º Portfolio Manager çš„ä¸“ä¸šåˆ¤æ–­ï¼Œå®¢è§‚è¯„ä¼°è‡ªå·±çš„å†³ç­–å¹¶åšå‡ºæ˜æ™ºçš„é€‰æ‹©ã€‚
"""
        
        return prompt
    
    def _evaluate_prediction(self, signal: str, actual_return: float) -> bool:
        """
        è¯„ä¼°åˆ†æå¸ˆé¢„æµ‹æ˜¯å¦æ­£ç¡®
        
        Args:
            signal: é¢„æµ‹ä¿¡å· ('BUY'/'bullish', 'SELL'/'bearish', 'HOLD'/'neutral')
            actual_return: å®é™…æ”¶ç›Šç‡
        
        Returns:
            æ˜¯å¦é¢„æµ‹æ­£ç¡®
        """
        threshold = 0.005  # 0.5%çš„é˜ˆå€¼
        
        # æ ‡å‡†åŒ–ä¿¡å·æ ¼å¼ï¼ˆæ”¯æŒå¤šç§æ ¼å¼ï¼‰
        signal_lower = signal.lower() if signal else ''
        
        # åˆ¤æ–­æ˜¯å¦ä¸ºçœ‹æ¶¨ä¿¡å·
        is_bullish = signal_lower in ['buy', 'bullish', 'long']
        # åˆ¤æ–­æ˜¯å¦ä¸ºçœ‹è·Œä¿¡å·
        is_bearish = signal_lower in ['sell', 'bearish', 'short']
        # åˆ¤æ–­æ˜¯å¦ä¸ºä¸­æ€§ä¿¡å·
        is_neutral = signal_lower in ['hold', 'neutral']
        
        if is_bullish and actual_return > threshold:
            return True
        elif is_bearish and actual_return < -threshold:
            return True
        elif is_neutral and abs(actual_return) <= threshold:
            return True
        else:
            return False
    
    def _evaluate_pm_decision(self, action: str, actual_return: float) -> bool:
        """
        è¯„ä¼°PMå†³ç­–æ˜¯å¦æ­£ç¡®
        
        Args:
            action: å†³ç­–åŠ¨ä½œ ('buy'/'long', 'sell'/'short', 'hold'/'neutral')
            actual_return: å®é™…æ”¶ç›Šç‡
        
        Returns:
            æ˜¯å¦å†³ç­–æ­£ç¡®
        """
        threshold = 0.005  # 0.5%çš„é˜ˆå€¼
        
        # æ ‡å‡†åŒ–åŠ¨ä½œæ ¼å¼ï¼ˆæ”¯æŒå¤šç§æ ¼å¼ï¼‰
        action_lower = action.lower() if action else 'hold'
        
        # åˆ¤æ–­æ˜¯å¦ä¸ºä¹°å…¥åŠ¨ä½œ
        is_buy = action_lower in ['buy', 'long', 'bullish']
        # åˆ¤æ–­æ˜¯å¦ä¸ºå–å‡ºåŠ¨ä½œ
        is_sell = action_lower in ['sell', 'short', 'bearish']
        # åˆ¤æ–­æ˜¯å¦ä¸ºæŒæœ‰åŠ¨ä½œ
        is_hold = action_lower in ['hold', 'neutral']
        
        if is_buy and actual_return > threshold:
            return True
        elif is_sell and actual_return < -threshold:
            return True
        elif is_hold and abs(actual_return) <= threshold:
            return True
        else:
            return False
    
    def perform_self_reflection(
        self,
        date: str,
        reflection_data: Dict[str, Any],
        context: Optional[Dict[str, Any]] = None
    ) -> Dict[str, Any]:
        """
        æ‰§è¡Œè‡ªæˆ‘å¤ç›˜
        
        Args:
            date: äº¤æ˜“æ—¥æœŸ
            reflection_data: å¤ç›˜æ•°æ®ï¼ˆæ ¹æ®agentç±»å‹ä¸åŒè€Œä¸åŒï¼‰
            context: é¢å¤–ä¸Šä¸‹æ–‡
        
        Returns:
            å¤ç›˜ç»“æœ
        """
        if not self.llm_available:
            return {
                'status': 'skipped',
                'reason': 'LLMä¸å¯ç”¨',
                'agent_id': self.agent_id,
                'date': date
            }
        
        try:
            # æ ¹æ®agentç±»å‹ç”Ÿæˆä¸åŒçš„prompt
            if self.agent_id == 'portfolio_manager':
                prompt = self.generate_pm_reflection_prompt(
                    date=date,
                    pm_decisions=reflection_data.get('pm_decisions', {}),
                    analyst_signals=reflection_data.get('analyst_signals', {}),
                    actual_returns=reflection_data.get('actual_returns', {}),
                    portfolio_summary=reflection_data.get('portfolio_summary', {}),
                    context=context
                )
            else:
                # åˆ†æå¸ˆ
                prompt = self.generate_analyst_reflection_prompt(
                    date=date,
                    my_signals=reflection_data.get('my_signals', {}),
                    actual_returns=reflection_data.get('actual_returns', {}),
                    pm_decisions=reflection_data.get('pm_decisions', {}),
                    context=context
                )
            print(f"\n{'='*60}")
            print(f"ğŸ” {self.agent_role} å¼€å§‹è‡ªæˆ‘å¤ç›˜ ({date})")
            print(f"{'='*60}")
            
            # è°ƒç”¨ LLMï¼ˆä½¿ç”¨ AgentScope æ ¼å¼ï¼‰
            messages = [{"role": "user", "content": prompt}]
            response = self.llm(messages=messages, temperature=0.7)
            
            # è·å–å“åº”å†…å®¹
            if isinstance(response, dict):
                response_content = response.get("content", "")
            elif hasattr(response, 'content'):
                response_content = response.content
            else:
                response_content = str(response)
            
            # è§£æ JSON å“åº”
            import json
            try:
                # å°è¯•æå– JSONï¼ˆå¯èƒ½è¢« markdown åŒ…è£¹ï¼‰
                json_start = response_content.find("{")
                json_end = response_content.rfind("}") + 1
                if json_start != -1 and json_end > json_start:
                    json_str = response_content[json_start:json_end]
                    reflection_data = json.loads(json_str)
                else:
                    # å¦‚æœæ‰¾ä¸åˆ° JSONï¼Œå°è¯•ç›´æ¥è§£æ
                    reflection_data = json.loads(response_content)
            except json.JSONDecodeError as e:
                print(f"âš ï¸ JSON è§£æå¤±è´¥: {e}")
                print(f"åŸå§‹å“åº”: {response_content[:500]}...")
                # ä½¿ç”¨é»˜è®¤å€¼
                reflection_data = {
                    "reflection_summary": response_content,
                    "need_tool": False
                }
            # æå–å¤ç›˜æ€»ç»“
            reflection_summary = reflection_data.get("reflection_summary", response_content)
            need_tool = reflection_data.get("need_tool", False)
            
            # æ‰§è¡Œè®°å¿†å·¥å…·ï¼ˆå¦‚æœ LLM å†³å®šéœ€è¦ï¼‰
            memory_operations = []
            if need_tool and "selected_tool" in reflection_data:
                tool_selection = reflection_data["selected_tool"]
                tool_name = tool_selection.get("tool_name")
                tool_reason = tool_selection.get("reason", "")
                tool_params = tool_selection.get("parameters", {})
                
                # éªŒè¯ analyst_idï¼ˆç¡®ä¿åªæ“ä½œè‡ªå·±çš„è®°å¿†ï¼‰
                if tool_params.get('analyst_id') != self.agent_id:
                    print(f"âš ï¸ è­¦å‘Š: {self.agent_role} è¯•å›¾æ“ä½œå…¶ä»–Agentçš„è®°å¿†ï¼Œå·²é˜»æ­¢")
                    print(f"   æœŸæœ›: {self.agent_id}, å®é™…: {tool_params.get('analyst_id')}")
                else:
                    print(f"ğŸ› ï¸ {self.agent_role} æ™ºèƒ½é€‰æ‹©äº†å·¥å…·: {tool_name}")
                    print(f"   é€‰æ‹©ç†ç”±: {tool_reason}")
                    
                    try:
                        # æ‰§è¡Œå·¥å…·ï¼ˆç±»ä¼¼ analyst çš„ execute_selected_toolsï¼‰
                        result = self.toolkit.call(tool_name, **tool_params)
                        
                        memory_operations.append({
                            'tool_name': tool_name,
                            'selection_reason': tool_reason,
                            'args': tool_params,
                            'result': result
                        })
                        
                        print(f"  âœ… å·¥å…·æ‰§è¡Œå®Œæˆ: {result.get('status', 'unknown')}")
                        
                        # è®°å½•åˆ°æ—¥å¿—
                        self.logger_system.log_operation(
                            agent_id=self.agent_id,
                            operation_type='self_reflection_with_llm_selection',
                            tool_name=tool_name,
                            args=tool_params,
                            result=result,
                            context={
                                'date': date,
                                'selection_reason': tool_reason
                            }
                        )
                        
                    except Exception as e:
                        print(f"  âŒ å·¥å…·æ‰§è¡Œå¤±è´¥: {e}")
                        import traceback
                        traceback.print_exc()
                        
                        # è®°å½•å¤±è´¥
                        memory_operations.append({
                            'tool_name': tool_name,
                            'selection_reason': tool_reason,
                            'args': tool_params,
                            'error': str(e)
                        })
            else:
                print(f"ğŸ’­ {self.agent_role} å†³å®šæ— éœ€è®°å¿†å·¥å…·æ“ä½œ")
            
            # æ˜¾ç¤ºå¤ç›˜æ€»ç»“
            print(f"\nğŸ“ å¤ç›˜æ€»ç»“:")
            print(reflection_summary)
            print(f"{'='*60}\n")
            
            return {
                'status': 'success',
                'agent_id': self.agent_id,
                'agent_role': self.agent_role,
                'date': date,
                'reflection_summary': reflection_summary,
                'memory_operations': memory_operations,
                'operations_count': len(memory_operations)
            }
            
        except Exception as e:
            print(f"âŒ {self.agent_role} è‡ªæˆ‘å¤ç›˜å¤±è´¥: {str(e)}")
            import traceback
            traceback.print_exc()
            
            return {
                'status': 'failed',
                'agent_id': self.agent_id,
                'agent_role': self.agent_role,
                'date': date,
                'error': str(e)
            }


def create_reflection_system(
    agent_id: str,
    base_dir: str = "mock",
    streamer=None
) -> AgentSelfReflectionSystem:
    """
    å·¥å‚å‡½æ•°ï¼šä¸ºæŒ‡å®šAgentåˆ›å»ºè‡ªæˆ‘å¤ç›˜ç³»ç»Ÿ
    
    Args:
        agent_id: Agent ID
        base_dir: åŸºç¡€ç›®å½•ï¼ˆconfig_nameï¼‰
        streamer: æ¶ˆæ¯å¹¿æ’­å™¨
    
    Returns:
        è‡ªæˆ‘å¤ç›˜ç³»ç»Ÿå®ä¾‹
    """
    role_mapping = {
        'technical_analyst': 'Technical Analyst',
        'fundamentals_analyst': 'Fundamentals Analyst',
        'sentiment_analyst': 'Sentiment Analyst',
        'valuation_analyst': 'Valuation Analyst',
        'portfolio_manager': 'Portfolio Manager'
    }
    
    agent_role = role_mapping.get(agent_id, agent_id)
    return AgentSelfReflectionSystem(agent_id, agent_role, base_dir, streamer=streamer)

