#!/usr/bin/env python3
"""
Agentè‡ªæˆ‘å¤ç›˜ç³»ç»Ÿ
æ¯ä¸ªåˆ†æå¸ˆï¼ˆåŒ…æ‹¬PMï¼‰ç‹¬ç«‹è¯„ä¼°è‡ªå·±çš„è¡¨ç°å¹¶ç®¡ç†è®°å¿†
"""

import os
import json
import logging
from typing import Dict, List, Any, Optional
from datetime import datetime
from pathlib import Path

# å°è¯•å¯¼å…¥LangChainç›¸å…³æ¨¡å—
try:
    from langchain_core.messages import HumanMessage
    from src.llm.models import get_model, ModelProvider
    from src.tools.memory_management_tools import get_memory_tools
    LANGCHAIN_AVAILABLE = True
except ImportError as e:
    LANGCHAIN_AVAILABLE = False
    print(f"âš ï¸ LangChainæ¨¡å—æœªå®‰è£…: {e}")

logger = logging.getLogger(__name__)


class MemoryOperationLogger:
    """è®°å¿†æ“ä½œæ—¥å¿—è®°å½•å™¨"""
    
    def __init__(self, base_dir: str):
        """
        åˆå§‹åŒ–æ—¥å¿—è®°å½•å™¨
        
        Args:
            base_dir: åŸºç¡€ç›®å½•ï¼ˆconfig_nameï¼‰
        """
        self.log_dir = Path("logs_and_memory") / base_dir / "memory_operations"
        self.log_dir.mkdir(parents=True, exist_ok=True)
        
        # å½“å‰æ—¥æœŸçš„æ—¥å¿—æ–‡ä»¶
        today = datetime.now().strftime("%Y%m%d")
        self.log_file = self.log_dir / f"memory_ops_{today}.jsonl"
    
    def log_operation(
        self,
        agent_id: str,
        operation_type: str,
        tool_name: str,
        args: Dict[str, Any],
        result: Dict[str, Any],
        context: Optional[Dict[str, Any]] = None
    ):
        """
        è®°å½•è®°å¿†æ“ä½œ
        
        Args:
            agent_id: Agent ID
            operation_type: æ“ä½œç±»å‹ (self_reflection, central_review)
            tool_name: å·¥å…·åç§°
            args: å·¥å…·å‚æ•°
            result: æ‰§è¡Œç»“æœ
            context: é¢å¤–ä¸Šä¸‹æ–‡
        """
        log_entry = {
            'timestamp': datetime.now().isoformat(),
            'agent_id': agent_id,
            'operation_type': operation_type,
            'tool_name': tool_name,
            'args': args,
            'result': result,
            'context': context or {}
        }
        
        try:
            with open(self.log_file, 'a', encoding='utf-8') as f:
                f.write(json.dumps(log_entry, ensure_ascii=False) + '\n')
        except Exception as e:
            logger.error(f"è®°å½•æ—¥å¿—å¤±è´¥: {e}")
    
    def get_today_operations(self, agent_id: Optional[str] = None) -> List[Dict[str, Any]]:
        """
        è·å–ä»Šæ—¥çš„è®°å¿†æ“ä½œè®°å½•
        
        Args:
            agent_id: å¦‚æœæŒ‡å®šï¼Œåªè¿”å›è¯¥Agentçš„æ“ä½œ
        
        Returns:
            æ“ä½œè®°å½•åˆ—è¡¨
        """
        if not self.log_file.exists():
            return []
        
        operations = []
        try:
            with open(self.log_file, 'r', encoding='utf-8') as f:
                for line in f:
                    try:
                        entry = json.loads(line.strip())
                        if agent_id is None or entry.get('agent_id') == agent_id:
                            operations.append(entry)
                    except json.JSONDecodeError:
                        continue
        except Exception as e:
            logger.error(f"è¯»å–æ—¥å¿—å¤±è´¥: {e}")
        
        return operations


class AgentSelfReflectionSystem:
    """åˆ†æå¸ˆè‡ªæˆ‘å¤ç›˜ç³»ç»Ÿ"""
    
    def __init__(
        self,
        agent_id: str,
        agent_role: str,
        base_dir: str = "mock"
    ):
        """
        åˆå§‹åŒ–è‡ªæˆ‘å¤ç›˜ç³»ç»Ÿ
        
        Args:
            agent_id: Agent IDï¼ˆå¦‚ 'technical_analyst' æˆ– 'portfolio_manager'ï¼‰
            agent_role: Agentè§’è‰²æè¿°ï¼ˆå¦‚ 'Technical Analyst'ï¼‰
            base_dir: åŸºç¡€ç›®å½•ï¼ˆconfig_nameï¼‰
        """
        self.agent_id = agent_id
        self.agent_role = agent_role
        self.base_dir = base_dir
        
        # åˆå§‹åŒ–æ—¥å¿—è®°å½•å™¨
        self.logger_system = MemoryOperationLogger(base_dir)
        
        # æ£€æŸ¥LangChainæ˜¯å¦å¯ç”¨
        if not LANGCHAIN_AVAILABLE:
            logger.warning(f"{agent_role} è‡ªæˆ‘å¤ç›˜ç³»ç»Ÿåˆå§‹åŒ–å¤±è´¥ï¼šLangChainä¸å¯ç”¨")
            self.llm_available = False
            return
        
        # åˆå§‹åŒ–LLMï¼ˆä½¿ç”¨ä¸è®°å¿†ç®¡ç†ç›¸åŒçš„é…ç½®ï¼‰
        try:
            model_name = os.getenv('MEMORY_LLM_MODEL', 'gpt-4o-mini')
            model_provider_str = os.getenv('MEMORY_LLM_PROVIDER', 'OPENAI')
            
            # è½¬æ¢ä¸ºModelProvideræšä¸¾
            model_provider = getattr(ModelProvider, model_provider_str, ModelProvider.OPENAI)
            
            api_keys = {}
            if model_provider == ModelProvider.OPENAI:
                api_keys['OPENAI_API_KEY'] = os.getenv('OPENAI_API_KEY')
            elif model_provider == ModelProvider.ANTHROPIC:
                api_keys['ANTHROPIC_API_KEY'] = os.getenv('ANTHROPIC_API_KEY')
            
            # è·å–è®°å¿†ç®¡ç†å·¥å…·
            self.memory_tools = get_memory_tools()
            
            # ç»‘å®šå·¥å…·åˆ°LLM
            self.llm = get_model(model_name, model_provider, api_keys)
            self.llm_with_tools = self.llm.bind_tools(self.memory_tools)
            
            self.llm_available = True
            print(f"âœ… {agent_role} è‡ªæˆ‘å¤ç›˜ç³»ç»Ÿå·²åˆå§‹åŒ–")
            
        except Exception as e:
            logger.error(f"{agent_role} è‡ªæˆ‘å¤ç›˜ç³»ç»Ÿåˆå§‹åŒ–å¤±è´¥: {e}")
            self.llm_available = False
    
    def generate_analyst_reflection_prompt(
        self,
        date: str,
        my_signals: Dict[str, Any],
        actual_returns: Dict[str, float],
        pm_decisions: Dict[str, Any],
        context: Optional[Dict[str, Any]] = None
    ) -> str:
        """
        ç”Ÿæˆåˆ†æå¸ˆè‡ªæˆ‘å¤ç›˜çš„prompt
        
        Args:
            date: äº¤æ˜“æ—¥æœŸ
            my_signals: æˆ‘çš„é¢„æµ‹ä¿¡å·
            actual_returns: å®é™…æ”¶ç›Šç‡
            pm_decisions: PMçš„æœ€ç»ˆå†³ç­–
            context: é¢å¤–ä¸Šä¸‹æ–‡
        """
        prompt = f"""ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„ {self.agent_role}ï¼Œç°åœ¨éœ€è¦å¯¹ {date} çš„åˆ†æè¡¨ç°è¿›è¡Œè‡ªæˆ‘å¤ç›˜ã€‚

# ä½ çš„èŒè´£
ä½œä¸º {self.agent_role}ï¼Œä½ éœ€è¦ï¼š
1. å®¢è§‚è¯„ä¼°è‡ªå·±çš„é¢„æµ‹å‡†ç¡®æ€§
2. åˆ†æé¢„æµ‹é”™è¯¯çš„åŸå› 
3. å†³å®šæ˜¯å¦éœ€è¦æ›´æ–°æˆ–åˆ é™¤é”™è¯¯çš„è®°å¿†
4. æ€»ç»“ç»éªŒæ•™è®­ï¼Œæå‡æœªæ¥è¡¨ç°

# ä»Šæ—¥å¤ç›˜æ•°æ®

## ä½ çš„é¢„æµ‹ä¿¡å·
"""
        
        # æ·»åŠ è‡ªå·±çš„ä¿¡å·
        for ticker, signal_data in my_signals.items():
            actual_return = actual_returns.get(ticker, 0)
            signal = signal_data.get('signal', 'N/A')
            confidence = signal_data.get('confidence', 'N/A')
            reasoning = signal_data.get('reasoning', '')
            
            # åˆ¤æ–­é¢„æµ‹æ˜¯å¦æ­£ç¡®
            is_correct = self._evaluate_prediction(signal, actual_return)
            status_emoji = "âœ…" if is_correct else "âŒ"
            
            prompt += f"""
{ticker}: {status_emoji}
  - ä½ çš„ä¿¡å·: {signal} (ç½®ä¿¡åº¦: {confidence}%)
  - ä½ çš„ç†ç”±: {reasoning[:200] if reasoning else 'N/A'}
  - å®é™…æ”¶ç›Š: {actual_return:.2%}
  - PMæœ€ç»ˆå†³ç­–: {pm_decisions.get(ticker, {}).get('action', 'N/A')}
"""
        
        # æ·»åŠ é¢å¤–ä¸Šä¸‹æ–‡
        if context:
            prompt += "\n## é¢å¤–ä¸Šä¸‹æ–‡\n"
            if 'market_condition' in context:
                prompt += f"- å¸‚åœºç¯å¢ƒ: {context['market_condition']}\n"
        
        prompt += f"""

# è‡ªæˆ‘å¤ç›˜æŒ‡å¯¼

è¯·æŒ‰ä»¥ä¸‹æ ‡å‡†è¯„ä¼°è‡ªå·±çš„è¡¨ç°ï¼š

## è¯„ä¼°æ ‡å‡†
1. **é¢„æµ‹å‡†ç¡®æ€§**: ä¿¡å·æ–¹å‘æ˜¯å¦ä¸å®é™…æ”¶ç›Šä¸€è‡´ï¼Ÿ
2. **ç½®ä¿¡åº¦æ ¡å‡†**: é«˜ç½®ä¿¡åº¦çš„é¢„æµ‹æ˜¯å¦æ›´å‡†ç¡®ï¼Ÿ
3. **åˆ†æé€»è¾‘**: ä½¿ç”¨çš„åˆ†ææ–¹æ³•æ˜¯å¦åˆç†ï¼Ÿ
4. **å¸‚åœºç†è§£**: æ˜¯å¦æ­£ç¡®ç†è§£äº†å¸‚åœºç¯å¢ƒï¼Ÿ

## è®°å¿†ç®¡ç†å†³ç­–

æ ¹æ®è¡¨ç°å†³å®šæ˜¯å¦éœ€è¦è®°å¿†æ“ä½œï¼š

### ğŸ”´ éœ€è¦åˆ é™¤è®°å¿† (ä½¿ç”¨ search_and_delete_analyst_memory)
- è¿ç»­å¤šæ¬¡ä¸¥é‡é¢„æµ‹é”™è¯¯
- ä½¿ç”¨äº†æ ¹æœ¬é”™è¯¯çš„åˆ†æé€»è¾‘
- å¯¹å¸‚åœºçš„ç†è§£å­˜åœ¨é‡å¤§åå·®
- ç¤ºä¾‹: "è¿ç»­3å¤©çœ‹å¤šä½†å¸‚åœºæš´è·Œï¼Œè¯´æ˜å¯¹è¶‹åŠ¿åˆ¤æ–­æœ‰æ ¹æœ¬æ€§é”™è¯¯"

### ğŸŸ¡ éœ€è¦æ›´æ–°è®°å¿† (ä½¿ç”¨ search_and_update_analyst_memory)
- é¢„æµ‹æ–¹å‘é”™è¯¯ä½†ä¸ç®—ç¦»è°±
- åˆ†ææ–¹æ³•éœ€è¦å¾®è°ƒä¼˜åŒ–
- éœ€è¦è¡¥å……æ–°çš„ç»éªŒæ•™è®­
- ç¤ºä¾‹: "æŠ€æœ¯æŒ‡æ ‡æ˜¾ç¤ºè¶…ä¹°ä½†æœªè€ƒè™‘åŸºæœ¬é¢æ”¯æ’‘ï¼Œéœ€è¦ç»¼åˆåˆ¤æ–­"

### ğŸŸ¢ è¡¨ç°è‰¯å¥½ï¼Œæ— éœ€æ“ä½œ
- é¢„æµ‹å‡†ç¡®ï¼Œåˆ†æé€»è¾‘æ­£ç¡®
- å¯ä»¥ç®€å•æ€»ç»“ç»éªŒï¼Œä¸è°ƒç”¨å·¥å…·
- ç¤ºä¾‹: "æˆåŠŸé¢„æµ‹çªç ´ï¼ŒMACDé‡‘å‰ä¿¡å·æœ‰æ•ˆ"

## è¾“å‡ºè¦æ±‚

1. **é¦–å…ˆ**ï¼Œç”¨1-2æ®µè¯æ€»ç»“ä½ çš„è¡¨ç°å’Œåæ€
2. **ç„¶å**ï¼Œå¦‚æœéœ€è¦è®°å¿†æ“ä½œï¼Œç›´æ¥è°ƒç”¨ç›¸åº”çš„å·¥å…·
3. **æœ€å**ï¼Œæå‡º1-2æ¡æ”¹è¿›å»ºè®®

æ³¨æ„ï¼š
- åªç®¡ç†ä½ è‡ªå·± ({self.agent_id}) çš„è®°å¿†
- è¦è¯šå®å®¢è§‚ï¼Œä¸è¦ä¸ºé”™è¯¯æ‰¾å€Ÿå£
- å…³æ³¨å¯æ“ä½œçš„æ”¹è¿›å»ºè®®
"""
        
        return prompt
    
    def generate_pm_reflection_prompt(
        self,
        date: str,
        pm_decisions: Dict[str, Any],
        analyst_signals: Dict[str, Dict[str, Any]],
        actual_returns: Dict[str, float],
        portfolio_summary: Dict[str, Any],
        context: Optional[Dict[str, Any]] = None
    ) -> str:
        """
        ç”ŸæˆPortfolio Managerè‡ªæˆ‘å¤ç›˜çš„prompt
        
        Args:
            date: äº¤æ˜“æ—¥æœŸ
            pm_decisions: PMçš„å†³ç­–
            analyst_signals: æ‰€æœ‰åˆ†æå¸ˆçš„ä¿¡å·
            actual_returns: å®é™…æ”¶ç›Šç‡
            portfolio_summary: Portfolioæ€»ç»“
            context: é¢å¤–ä¸Šä¸‹æ–‡
        """
        prompt = f"""ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„ Portfolio Managerï¼Œç°åœ¨éœ€è¦å¯¹ {date} çš„æŠ•èµ„å†³ç­–è¿›è¡Œè‡ªæˆ‘å¤ç›˜ã€‚

# ä½ çš„èŒè´£
ä½œä¸º Portfolio Managerï¼Œä½ éœ€è¦ï¼š
1. è¯„ä¼°è‡ªå·±çš„å†³ç­–è´¨é‡
2. åˆ†æå†³ç­–å¤±è¯¯çš„åŸå› 
3. åæ€æ˜¯å¦æ­£ç¡®ç»¼åˆäº†åˆ†æå¸ˆæ„è§
4. å†³å®šæ˜¯å¦éœ€è¦æ›´æ–°å†³ç­–è®°å¿†
5. æ€»ç»“ç»éªŒæ•™è®­

# ä»Šæ—¥å¤ç›˜æ•°æ®

## Portfolio è¡¨ç°
"""
        
        if portfolio_summary:
            total_value = portfolio_summary.get('total_value', 0)
            pnl_percent = portfolio_summary.get('pnl_percent', 0)
            cash = portfolio_summary.get('cash', 0)
            
            prompt += f"""
- æ€»èµ„äº§: ${total_value:,.2f}
- æ”¶ç›Šç‡: {pnl_percent:+.2f}%
- ç°é‡‘: ${cash:,.2f}
"""
        
        prompt += "\n## ä½ çš„æŠ•èµ„å†³ç­– vs å®é™…ç»“æœ\n"
        
        # æ·»åŠ PMå†³ç­–å’Œå®é™…ç»“æœ
        for ticker, decision_data in pm_decisions.items():
            actual_return = actual_returns.get(ticker, 0)
            action = decision_data.get('action', 'N/A')
            quantity = decision_data.get('quantity', 0)
            confidence = decision_data.get('confidence', 'N/A')
            reasoning = decision_data.get('reasoning', '')
            
            # åˆ¤æ–­å†³ç­–æ˜¯å¦æ­£ç¡®
            is_correct = self._evaluate_pm_decision(action, actual_return)
            status_emoji = "âœ…" if is_correct else "âŒ"
            
            prompt += f"""
{ticker}: {status_emoji}
  - ä½ çš„å†³ç­–: {action}
  - æ•°é‡: {quantity} è‚¡
  - ç½®ä¿¡åº¦: {confidence}%
  - å†³ç­–ç†ç”±: {reasoning[:200] if reasoning else 'N/A'}
  - å®é™…æ”¶ç›Š: {actual_return:.2%}
"""
            
            # æ·»åŠ åˆ†æå¸ˆæ„è§å¯¹æ¯”
            prompt += "  - åˆ†æå¸ˆæ„è§:\n"
            for analyst_id, signals in analyst_signals.items():
                if ticker in signals:
                    analyst_signal = signals[ticker]
                    prompt += f"    * {analyst_id}: {analyst_signal}\n"
        
        # æ·»åŠ é¢å¤–ä¸Šä¸‹æ–‡
        if context:
            prompt += "\n## é¢å¤–ä¸Šä¸‹æ–‡\n"
            if 'market_condition' in context:
                prompt += f"- å¸‚åœºç¯å¢ƒ: {context['market_condition']}\n"
            if 'risk_metrics' in context:
                prompt += f"- é£é™©æŒ‡æ ‡: {context['risk_metrics']}\n"
        
        prompt += f"""

# è‡ªæˆ‘å¤ç›˜æŒ‡å¯¼

è¯·æŒ‰ä»¥ä¸‹æ ‡å‡†è¯„ä¼°è‡ªå·±çš„è¡¨ç°ï¼š

## è¯„ä¼°æ ‡å‡†
1. **å†³ç­–å‡†ç¡®æ€§**: æŠ•èµ„å†³ç­–æ˜¯å¦å¸¦æ¥æ­£æ”¶ç›Šï¼Ÿ
2. **ä¿¡æ¯æ•´åˆ**: æ˜¯å¦æ­£ç¡®ç»¼åˆäº†åˆ†æå¸ˆæ„è§ï¼Ÿ
3. **é£é™©æ§åˆ¶**: ä»“ä½ç®¡ç†æ˜¯å¦åˆç†ï¼Ÿ
4. **æ‰§è¡Œçºªå¾‹**: æ˜¯å¦éµå¾ªäº†æ—¢å®šç­–ç•¥ï¼Ÿ

## è®°å¿†ç®¡ç†å†³ç­–

æ ¹æ®è¡¨ç°å†³å®šæ˜¯å¦éœ€è¦è®°å¿†æ“ä½œï¼š

### ğŸ”´ éœ€è¦åˆ é™¤è®°å¿† (ä½¿ç”¨ search_and_delete_analyst_memory)
- å†³ç­–å¯¼è‡´é‡å¤§æŸå¤±ï¼ˆå¦‚å•æ—¥æŸå¤±>3%ï¼‰
- ä½¿ç”¨äº†é”™è¯¯çš„å†³ç­–æ¡†æ¶
- å¿½ç•¥äº†æ˜æ˜¾çš„é£é™©ä¿¡å·
- ç¤ºä¾‹: "è¿‡åº¦ä¾èµ–å•ä¸€åˆ†æå¸ˆæ„è§ï¼Œå¯¼è‡´å¿½è§†é£é™©"

### ğŸŸ¡ éœ€è¦æ›´æ–°è®°å¿† (ä½¿ç”¨ search_and_update_analyst_memory)
- å†³ç­–æ–¹å‘é”™è¯¯ä½†æŸå¤±å¯æ§
- ä¿¡æ¯æ•´åˆæ–¹æ³•éœ€è¦ä¼˜åŒ–
- é£é™©æ§åˆ¶éœ€è¦åŠ å¼º
- ç¤ºä¾‹: "æŠ€æœ¯é¢å’ŒåŸºæœ¬é¢å†²çªæ—¶ï¼Œéœ€è¦æ›´è°¨æ…"

### ğŸŸ¢ è¡¨ç°è‰¯å¥½ï¼Œæ— éœ€æ“ä½œ
- å†³ç­–å¸¦æ¥æ­£æ”¶ç›Š
- é£é™©æ§åˆ¶å¾—å½“
- å¯ä»¥æ€»ç»“æˆåŠŸç»éªŒ
- ç¤ºä¾‹: "æˆåŠŸè¯†åˆ«è¶‹åŠ¿ï¼ŒåŠæ—¶è°ƒæ•´ä»“ä½"

## è¾“å‡ºè¦æ±‚

1. **é¦–å…ˆ**ï¼Œç”¨2-3æ®µè¯æ€»ç»“ä½ çš„å†³ç­–è¡¨ç°å’Œåæ€
2. **ç„¶å**ï¼Œå¦‚æœéœ€è¦è®°å¿†æ“ä½œï¼Œç›´æ¥è°ƒç”¨ç›¸åº”çš„å·¥å…·
3. **æœ€å**ï¼Œæå‡º2-3æ¡æ”¹è¿›å»ºè®®

æ³¨æ„ï¼š
- åªç®¡ç†ä½ è‡ªå·± (portfolio_manager) çš„è®°å¿†
- è¦è¯šå®è¯„ä¼°å†³ç­–è´¨é‡
- å…³æ³¨å¯æ“ä½œçš„æ”¹è¿›å»ºè®®
- è€ƒè™‘å¦‚ä½•æ›´å¥½åœ°åˆ©ç”¨åˆ†æå¸ˆæ„è§
"""
        
        return prompt
    
    def _evaluate_prediction(self, signal: str, actual_return: float) -> bool:
        """
        è¯„ä¼°åˆ†æå¸ˆé¢„æµ‹æ˜¯å¦æ­£ç¡®
        
        Args:
            signal: é¢„æµ‹ä¿¡å· ('BUY', 'SELL', 'HOLD')
            actual_return: å®é™…æ”¶ç›Šç‡
        
        Returns:
            æ˜¯å¦é¢„æµ‹æ­£ç¡®
        """
        threshold = 0.005  # 0.5%çš„é˜ˆå€¼
        
        if signal == 'BUY' and actual_return > threshold:
            return True
        elif signal == 'SELL' and actual_return < -threshold:
            return True
        elif signal == 'HOLD' and abs(actual_return) <= threshold:
            return True
        else:
            return False
    
    def _evaluate_pm_decision(self, action: str, actual_return: float) -> bool:
        """
        è¯„ä¼°PMå†³ç­–æ˜¯å¦æ­£ç¡®
        
        Args:
            action: å†³ç­–åŠ¨ä½œ ('buy', 'sell', 'hold')
            actual_return: å®é™…æ”¶ç›Šç‡
        
        Returns:
            æ˜¯å¦å†³ç­–æ­£ç¡®
        """
        threshold = 0.005  # 0.5%çš„é˜ˆå€¼
        
        action_lower = action.lower() if action else 'hold'
        
        if action_lower == 'buy' and actual_return > threshold:
            return True
        elif action_lower == 'sell' and actual_return < -threshold:
            return True
        elif action_lower == 'hold' and abs(actual_return) <= threshold:
            return True
        else:
            return False
    
    def perform_self_reflection(
        self,
        date: str,
        reflection_data: Dict[str, Any],
        context: Optional[Dict[str, Any]] = None
    ) -> Dict[str, Any]:
        """
        æ‰§è¡Œè‡ªæˆ‘å¤ç›˜
        
        Args:
            date: äº¤æ˜“æ—¥æœŸ
            reflection_data: å¤ç›˜æ•°æ®ï¼ˆæ ¹æ®agentç±»å‹ä¸åŒè€Œä¸åŒï¼‰
            context: é¢å¤–ä¸Šä¸‹æ–‡
        
        Returns:
            å¤ç›˜ç»“æœ
        """
        if not self.llm_available:
            return {
                'status': 'skipped',
                'reason': 'LLMä¸å¯ç”¨',
                'agent_id': self.agent_id,
                'date': date
            }
        
        try:
            # æ ¹æ®agentç±»å‹ç”Ÿæˆä¸åŒçš„prompt
            if self.agent_id == 'portfolio_manager':
                prompt = self.generate_pm_reflection_prompt(
                    date=date,
                    pm_decisions=reflection_data.get('pm_decisions', {}),
                    analyst_signals=reflection_data.get('analyst_signals', {}),
                    actual_returns=reflection_data.get('actual_returns', {}),
                    portfolio_summary=reflection_data.get('portfolio_summary', {}),
                    context=context
                )
            else:
                # åˆ†æå¸ˆ
                prompt = self.generate_analyst_reflection_prompt(
                    date=date,
                    my_signals=reflection_data.get('my_signals', {}),
                    actual_returns=reflection_data.get('actual_returns', {}),
                    pm_decisions=reflection_data.get('pm_decisions', {}),
                    context=context
                )
            
            print(f"\n{'='*60}")
            print(f"ğŸ” {self.agent_role} å¼€å§‹è‡ªæˆ‘å¤ç›˜ ({date})")
            print(f"{'='*60}")
            
            # è°ƒç”¨LLM
            messages = [HumanMessage(content=prompt)]
            response = self.llm_with_tools.invoke(messages)
            
            # æå–å¤ç›˜æ€»ç»“
            reflection_summary = response.content if hasattr(response, 'content') else str(response)
            
            # æ£€æŸ¥æ˜¯å¦æœ‰å·¥å…·è°ƒç”¨
            memory_operations = []
            if hasattr(response, 'tool_calls') and response.tool_calls:
                print(f"ğŸ› ï¸ {self.agent_role} å†³å®šæ‰§è¡Œ {len(response.tool_calls)} ä¸ªè®°å¿†æ“ä½œ")
                
                # æ‰§è¡Œå·¥å…·è°ƒç”¨
                for tool_call in response.tool_calls:
                    tool_name = tool_call['name']
                    tool_args = tool_call['args']
                    
                    # ç¡®ä¿åªæ“ä½œè‡ªå·±çš„è®°å¿†
                    if tool_args.get('analyst_id') != self.agent_id:
                        print(f"âš ï¸ è­¦å‘Š: {self.agent_role} è¯•å›¾æ“ä½œå…¶ä»–Agentçš„è®°å¿†ï¼Œå·²é˜»æ­¢")
                        continue
                    
                    print(f"  ğŸ“ æ‰§è¡Œ: {tool_name}")
                    print(f"     å‚æ•°: {tool_args}")
                    
                    # è°ƒç”¨å·¥å…·
                    tool_function = next(
                        (tool for tool in self.memory_tools if tool.name == tool_name),
                        None
                    )
                    
                    if tool_function:
                        result = tool_function.invoke(tool_args)
                        memory_operations.append({
                            'tool_name': tool_name,
                            'args': tool_args,
                            'result': result
                        })
                        print(f"  âœ… æ“ä½œå®Œæˆ: {result.get('status', 'unknown')}")
                        
                        # è®°å½•åˆ°æ—¥å¿—
                        self.logger_system.log_operation(
                            agent_id=self.agent_id,
                            operation_type='individual_review',
                            tool_name=tool_name,
                            args=tool_args,
                            result=result,
                            context={'date': date}
                        )
                    else:
                        print(f"  âŒ æœªæ‰¾åˆ°å·¥å…·: {tool_name}")
            else:
                print(f"ğŸ’­ {self.agent_role} è®¤ä¸ºæ— éœ€è®°å¿†æ“ä½œ")
            
            print(f"\nğŸ“ å¤ç›˜æ€»ç»“:")
            print(f"{reflection_summary[:500]}{'...' if len(reflection_summary) > 500 else ''}")
            print(f"{'='*60}\n")
            
            return {
                'status': 'success',
                'agent_id': self.agent_id,
                'agent_role': self.agent_role,
                'date': date,
                'reflection_summary': reflection_summary,
                'memory_operations': memory_operations,
                'operations_count': len(memory_operations)
            }
            
        except Exception as e:
            print(f"âŒ {self.agent_role} è‡ªæˆ‘å¤ç›˜å¤±è´¥: {str(e)}")
            import traceback
            traceback.print_exc()
            
            return {
                'status': 'failed',
                'agent_id': self.agent_id,
                'agent_role': self.agent_role,
                'date': date,
                'error': str(e)
            }


def create_reflection_system(
    agent_id: str,
    base_dir: str = "mock"
) -> AgentSelfReflectionSystem:
    """
    å·¥å‚å‡½æ•°ï¼šä¸ºæŒ‡å®šAgentåˆ›å»ºè‡ªæˆ‘å¤ç›˜ç³»ç»Ÿ
    
    Args:
        agent_id: Agent ID
        base_dir: åŸºç¡€ç›®å½•ï¼ˆconfig_nameï¼‰
    
    Returns:
        è‡ªæˆ‘å¤ç›˜ç³»ç»Ÿå®ä¾‹
    """
    role_mapping = {
        'technical_analyst': 'Technical Analyst',
        'fundamentals_analyst': 'Fundamentals Analyst',
        'sentiment_analyst': 'Sentiment Analyst',
        'valuation_analyst': 'Valuation Analyst',
        'portfolio_manager': 'Portfolio Manager'
    }
    
    agent_role = role_mapping.get(agent_id, agent_id)
    return AgentSelfReflectionSystem(agent_id, agent_role, base_dir)

