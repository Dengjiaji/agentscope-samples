#!/usr/bin/env python3
"""
ReMe Long-term Memory Implementation
ä½¿ç”¨å…¨å±€å•ä¾‹ ChromaVectorStoreï¼Œé€šè¿‡ workspace_id åŒºåˆ†ä¸åŒç”¨æˆ·
"""

import os
import uuid
import logging
from typing import Dict, List, Any, Optional
from pathlib import Path

from .base import LongTermMemory

from flowllm.storage.vector_store import ChromaVectorStore
from flowllm.embedding_model import OpenAICompatibleEmbeddingModel
from flowllm.schema.vector_node import VectorNode
from src.config.path_config import get_logs_and_memory_dir

logger = logging.getLogger(__name__)


class ReMeMemory(LongTermMemory):
    """
    ReMeé•¿æœŸè®°å¿†å®ç°
    
    è®¾è®¡ç†å¿µï¼š
    - å…¨å±€å…±äº«ä¸€ä¸ª ChromaVectorStore å®ä¾‹ï¼ˆé¿å… Chroma å†²çªï¼‰
    - ä½¿ç”¨ workspace_id = f"{base_dir}_{user_id}" åŒºåˆ†ä¸åŒé…ç½®å’Œç”¨æˆ·
    - æ‰€æœ‰æ•°æ®å­˜å‚¨åœ¨ç»Ÿä¸€çš„æ ¹ç›®å½•ä¸‹
    """
    
    # å…¨å±€å•ä¾‹ï¼šä¸€ä¸ªè¿›ç¨‹åªæœ‰ä¸€ä¸ª ChromaVectorStore
    _global_vector_store: Optional[ChromaVectorStore] = None
    _global_embedding_model: Optional[OpenAICompatibleEmbeddingModel] = None
    _global_store_dir: Optional[str] = None
    
    def __init__(self, base_dir: str):
        """
        åˆå§‹åŒ–ReMeè®°å¿†
        
        Args:
            base_dir: åŸºç¡€ç›®å½•ï¼ˆconfig_nameï¼‰ï¼Œä¼šä½œä¸º workspace_id çš„å‰ç¼€
        """
        self.base_dir = base_dir
        
        # ä½¿ç”¨å…¨å±€ç»Ÿä¸€çš„å­˜å‚¨ç›®å½•
        if ReMeMemory._global_store_dir is None:
            ReMeMemory._global_store_dir = str(get_logs_and_memory_dir() / base_dir / "memory_data" / "reme_vector_store")
            os.makedirs(ReMeMemory._global_store_dir, exist_ok=True)
        
        self.store_dir = ReMeMemory._global_store_dir
        
        # åˆå§‹åŒ–å…¨å±€ embedding æ¨¡å‹ï¼ˆåªåˆ›å»ºä¸€æ¬¡ï¼‰
        if ReMeMemory._global_embedding_model is None:
            embedding_model_name = os.getenv("MEMORY_EMBEDDING_MODEL", "text-embedding-3-small")
            embedding_dim = int(os.getenv("REME_EMBEDDING_DIMENSIONS", "1536"))
            
            logger.info(f"åˆå§‹åŒ–å…¨å±€ Embedding æ¨¡å‹: {embedding_model_name} (dim={embedding_dim})")
            ReMeMemory._global_embedding_model = OpenAICompatibleEmbeddingModel(
                dimensions=embedding_dim,
                model_name=embedding_model_name
            )
        
        # åˆå§‹åŒ–å…¨å±€å‘é‡å­˜å‚¨ï¼ˆåªåˆ›å»ºä¸€æ¬¡ï¼Œè§£å†³ Chroma å†²çªï¼‰
        if ReMeMemory._global_vector_store is None:
            logger.info(f"åˆå§‹åŒ–å…¨å±€ ChromaVectorStore: {self.store_dir}")
            ReMeMemory._global_vector_store = ChromaVectorStore(
                embedding_model=ReMeMemory._global_embedding_model,
                store_dir=self.store_dir,
                batch_size=1024
            )
        
        # å…ˆèµ‹å€¼ vector_storeï¼Œç¡®ä¿åç»­æ–¹æ³•å¯ä»¥è®¿é—®
        self.vector_store = ReMeMemory._global_vector_store
        
        # åªåœ¨ç¬¬ä¸€æ¬¡åˆ›å»ºæ—¶åŠ è½½æ‰€æœ‰å·²æœ‰workspacesï¼ˆä½¿ç”¨æ ‡å¿—ä½é¿å…é‡å¤åŠ è½½ï¼‰
        if not hasattr(ReMeMemory, '_workspaces_loaded'):
            self._load_all_existing_workspaces()
            ReMeMemory._workspaces_loaded = True
        
        logger.info(f"ReMeè®°å¿†å·²åˆå§‹åŒ– (base_dir={base_dir})")
    
    def _load_all_existing_workspaces(self):
        """åŠ è½½æ‰€æœ‰å·²æœ‰çš„workspaceè®°å¿†"""
        jsonl_files = list(Path(self.store_dir).glob("*.jsonl"))
        
        if jsonl_files:
            logger.info(f"å‘ç° {len(jsonl_files)} ä¸ªworkspaceæ–‡ä»¶ï¼Œæ­£åœ¨åŠ è½½...")
            
        for jsonl_file in jsonl_files:
            workspace_id = jsonl_file.stem
            if not self.vector_store.exist_workspace(workspace_id):
                try:
                    self.vector_store.load_workspace(workspace_id, path=self.store_dir)
                    logger.debug(f"âœ“ åŠ è½½ workspace: {workspace_id}")
                except Exception as e:
                    logger.warning(f"âœ— åŠ è½½å¤±è´¥ {workspace_id}: {e}")
    
    
    def _get_workspace_id(self, user_id: str) -> str:
        """
        ç”Ÿæˆå®Œæ•´çš„ workspace_id
        æ ¼å¼: {base_dir}__{user_id}
        è¿™æ ·å¯ä»¥åœ¨å…¨å±€ ChromaVectorStore ä¸­åŒºåˆ†ä¸åŒé…ç½®çš„ç”¨æˆ·
        """
        return f"{user_id}"
    
    def _ensure_workspace(self, user_id: str):
        """ç¡®ä¿workspaceå­˜åœ¨"""
        workspace_id = self._get_workspace_id(user_id)
        
        if not self.vector_store.exist_workspace(workspace_id):
            # å°è¯•åŠ è½½
            workspace_file = os.path.join(self.store_dir, f"{workspace_id}.jsonl")
            if os.path.exists(workspace_file):
                try:
                    self.vector_store.load_workspace(workspace_id, path=self.store_dir)
                    return
                except Exception as e:
                    logger.warning(f"åŠ è½½workspaceå¤±è´¥: {e}")
            
            # åˆ›å»ºæ–°workspace
            self.vector_store.create_workspace(workspace_id)
    
    def add(self, content: str, user_id: str, metadata: Optional[Dict[str, Any]] = None) -> str:
        """æ·»åŠ è®°å¿†"""
        logger.debug(f"â• [ReMeMemory] æ·»åŠ è®°å¿†: user_id={user_id}, content_len={len(content)}")
        
        self._ensure_workspace(user_id)
        workspace_id = self._get_workspace_id(user_id)
        
        logger.debug(f"   workspace_id={workspace_id}")
        
        node_id = str(uuid.uuid4())
        node_metadata = metadata or {}
        node_metadata['user_id'] = user_id
        node_metadata['base_dir'] = self.base_dir
        
        node = VectorNode(
            unique_id=node_id,
            workspace_id=workspace_id,
            content=content,
            metadata=node_metadata
        )
        
        self.vector_store.insert([node], workspace_id)
        self.vector_store.dump_workspace(workspace_id, path=self.store_dir)
        
        logger.debug(f"   âœ… è®°å¿†å·²æ·»åŠ ï¼Œnode_id={node_id}")
        logger.debug(f"   ä¿å­˜è·¯å¾„: {self.store_dir}/{workspace_id}.jsonl")
        
        return node_id
    
    def search(self, query: str, user_id: str, top_k: int = 5) -> List[Dict[str, Any]]:
        """æœç´¢è®°å¿†"""
        logger.debug(f"ğŸ” [ReMeMemory] æœç´¢è®°å¿†: user_id={user_id}, query={query[:100]}...")
        
        self._ensure_workspace(user_id)
        workspace_id = self._get_workspace_id(user_id)
        
        logger.debug(f"   workspace_id={workspace_id}")
        logger.debug(f"   workspaceå­˜åœ¨: {self.vector_store.exist_workspace(workspace_id)}")
        
        if not self.vector_store.exist_workspace(workspace_id):
            logger.warning(f"   âš ï¸ workspaceä¸å­˜åœ¨ï¼Œè¿”å›ç©ºåˆ—è¡¨")
            return []
        
        # æ£€æŸ¥workspaceä¸­çš„èŠ‚ç‚¹æ•°é‡
        try:
            all_nodes = list(self.vector_store.iter_workspace_nodes(workspace_id))
            logger.debug(f"   workspaceä¸­å…±æœ‰ {len(all_nodes)} ä¸ªèŠ‚ç‚¹")
        except Exception as e:
            logger.debug(f"   æ— æ³•ç»Ÿè®¡èŠ‚ç‚¹æ•°é‡: {e}")
        
        nodes = self.vector_store.search(query, workspace_id, top_k=top_k)
        
        logger.debug(f"   æœç´¢ç»“æœ: {len(nodes)} æ¡")
        
        return [
            {
                'id': node.unique_id,
                'content': node.content,
                'metadata': node.metadata
            }
            for node in nodes
        ]
    
    def update(self, memory_id: str, content: str, user_id: str) -> bool:
        """æ›´æ–°è®°å¿†"""
        try:
            self._ensure_workspace(user_id)
            workspace_id = self._get_workspace_id(user_id)
            
            # ReMeæ–¹å¼ï¼šåˆ é™¤æ—§èŠ‚ç‚¹ï¼Œæ’å…¥æ–°èŠ‚ç‚¹
            self.vector_store.delete([memory_id], workspace_id)
            
            node = VectorNode(
                unique_id=memory_id,
                workspace_id=workspace_id,
                content=content,
                metadata={'user_id': user_id, 'base_dir': self.base_dir}
            )
            
            self.vector_store.insert([node], workspace_id)
            self.vector_store.dump_workspace(workspace_id, path=self.store_dir)
            
            return True
        except Exception as e:
            logger.error(f"æ›´æ–°è®°å¿†å¤±è´¥: {e}")
            return False
    
    def delete(self, memory_id: str, user_id: str) -> bool:
        """åˆ é™¤è®°å¿†"""
        try:
            self._ensure_workspace(user_id)
            workspace_id = self._get_workspace_id(user_id)
            self.vector_store.delete([memory_id], workspace_id)
            self.vector_store.dump_workspace(workspace_id, path=self.store_dir)
            return True
        except Exception as e:
            logger.error(f"åˆ é™¤è®°å¿†å¤±è´¥: {e}")
            return False
    
    def get_all(self, user_id: str) -> List[Dict[str, Any]]:
        """è·å–æ‰€æœ‰è®°å¿†"""
        self._ensure_workspace(user_id)
        workspace_id = self._get_workspace_id(user_id)
        
        if not self.vector_store.exist_workspace(workspace_id):
            return []
        
        nodes = list(self.vector_store.iter_workspace_nodes(workspace_id))
        
        return [
            {
                'id': node.unique_id,
                'content': node.content,
                'metadata': node.metadata
            }
            for node in nodes
        ]
    
    def delete_all(self, user_id: str) -> bool:
        """åˆ é™¤æ‰€æœ‰è®°å¿†"""
        try:
            workspace_id = self._get_workspace_id(user_id)
            
            if not self.vector_store.exist_workspace(workspace_id):
                logger.info(f"workspace {workspace_id} ä¸å­˜åœ¨ï¼Œæ— éœ€æ¸…ç©º")
                return True
            
            # è·å–æ‰€æœ‰èŠ‚ç‚¹IDå¹¶åˆ é™¤
            nodes = list(self.vector_store.iter_workspace_nodes(workspace_id))
            node_ids = [node.unique_id for node in nodes]
            
            if node_ids:
                self.vector_store.delete(node_ids, workspace_id)
                self.vector_store.dump_workspace(workspace_id, path=self.store_dir)
                logger.info(f"å·²æ¸…ç©ºç”¨æˆ· {user_id} (workspace {workspace_id}) çš„ {len(node_ids)} æ¡è®°å¿†")
            
            return True
        except Exception as e:
            logger.error(f"æ¸…ç©ºè®°å¿†å¤±è´¥: {e}")
            return False
    
    @classmethod
    def reset_global_store(cls):
        """é‡ç½®å…¨å±€å‘é‡å­˜å‚¨ï¼ˆä¸»è¦ç”¨äºæµ‹è¯•ï¼‰"""
        cls._global_vector_store = None
        cls._global_embedding_model = None
        cls._global_store_dir = None
        logger.info("å…¨å±€ ChromaVectorStore å·²é‡ç½®")

