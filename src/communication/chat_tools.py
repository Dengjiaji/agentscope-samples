#!/usr/bin/env python3
"""
é€šä¿¡å·¥å…· - ç§èŠå’Œå¼€ä¼šåŠŸèƒ½çš„å®ç°
"""

import json
import uuid
import re
from datetime import datetime
from typing import Dict, List, Any, Optional
from pydantic import BaseModel, Field

from src.agents.agentscope_prompts import ChatPromptTemplate
from src.llm.agentscope_models import get_model as get_agentscope_model
from src.utils.api_key import get_api_key_from_state
from src.utils.json_utils import quiet_json_dumps
from src.memory import unified_memory_manager as memory_manager
from src.memory import unified_memory_manager
import pdb
class PrivateChatMessage(BaseModel):
    """ç§èŠæ¶ˆæ¯æ¨¡å‹"""
    id: str = Field(default_factory=lambda: str(uuid.uuid4()))
    sender: str = Field(..., description="å‘é€è€…ID")
    receiver: str = Field(..., description="æ¥æ”¶è€…ID")
    content: str = Field(..., description="æ¶ˆæ¯å†…å®¹")
    timestamp: datetime = Field(default_factory=datetime.now)
    message_type: str = Field(default="chat", description="æ¶ˆæ¯ç±»å‹")




class SignalAdjustment(BaseModel):
    """ä¿¡å·è°ƒæ•´æ¨¡å‹"""
    ticker: str = Field(..., description="è‚¡ç¥¨ä»£ç ")
    original_signal: str = Field(..., description="åŸå§‹ä¿¡å·")
    adjusted_signal: str = Field(..., description="è°ƒæ•´åä¿¡å·")
    original_confidence: int = Field(..., description="åŸå§‹ä¿¡å¿ƒåº¦")
    adjusted_confidence: int = Field(..., description="è°ƒæ•´åä¿¡å¿ƒåº¦")
    adjustment_reasoning: str = Field(..., description="è°ƒæ•´åŸå› ")


class CommunicationDecision(BaseModel):
    """äº¤æµå†³ç­–æ¨¡å‹"""
    should_communicate: bool = Field(..., description="æ˜¯å¦éœ€è¦äº¤æµ")
    communication_type: str = Field(..., description="äº¤æµç±»å‹: private_chat æˆ– meeting")
    target_analysts: List[str] = Field(default_factory=list, description="ç›®æ ‡åˆ†æå¸ˆåˆ—è¡¨")
    discussion_topic: str = Field(..., description="è®¨è®ºè¯é¢˜")
    reasoning: str = Field(..., description="é€‰æ‹©äº¤æµçš„åŸå› ")


class PrivateChatSystem:
    """ç§èŠç³»ç»Ÿ"""
    
    def __init__(self):
        self.chat_histories: Dict[str, List[PrivateChatMessage]] = {}
    
    def start_private_chat(self, manager_id: str, analyst_id: str, 
                          initial_message: str) -> str:
        """å¼€å§‹ç§èŠå¯¹è¯"""
        chat_key = f"{manager_id}_{analyst_id}"
        
        if chat_key not in self.chat_histories:
            self.chat_histories[chat_key] = []
        
        # æ·»åŠ ç®¡ç†è€…çš„åˆå§‹æ¶ˆæ¯
        message = PrivateChatMessage(
            sender=manager_id,
            receiver=analyst_id,
            content=initial_message
        )
        
        self.chat_histories[chat_key].append(message)
        return message.id
    
    def send_message(self, sender: str, receiver: str, content: str) -> str:
        """å‘é€æ¶ˆæ¯"""
        chat_key = f"{sender}_{receiver}" if sender < receiver else f"{receiver}_{sender}"
        
        if chat_key not in self.chat_histories:
            self.chat_histories[chat_key] = []
        
        message = PrivateChatMessage(
            sender=sender,
            receiver=receiver,
            content=content
        )
        
        self.chat_histories[chat_key].append(message)
        return message.id
    
    def get_chat_history(self, participant1: str, participant2: str) -> List[PrivateChatMessage]:
        """è·å–èŠå¤©å†å²"""
        chat_key = f"{participant1}_{participant2}" if participant1 < participant2 else f"{participant2}_{participant1}"
        return self.chat_histories.get(chat_key, [])




class CommunicationManager:
    """äº¤æµç®¡ç†å™¨"""
    
    def __init__(self):
        self.private_chat_system = PrivateChatSystem()
        
    def _get_max_chars(self, state) -> int:
        """è·å–æ²Ÿé€šæ–‡æœ¬æœ€å¤§å­—æ•°ï¼Œé»˜è®¤400ï¼Œå¯é€šè¿‡state.metadata.communication_max_charsè¦†ç›–"""
        try:
            return int(state.get("metadata", {}).get("communication_max_chars", 400))
        except Exception:
            return 400
    
    def _truncate_text(self, text: str, max_chars: int) -> str:
        """æŒ‰å­—æ•°ä¸Šé™æˆªæ–­æ–‡æœ¬ï¼ˆé¢å‘ä¸­æ–‡ï¼‰ï¼Œä¿ç•™å‰max_charsä¸ªå­—ç¬¦"""
        if not isinstance(text, str):
            return text
        return text if len(text) <= max_chars else text[:max_chars]
    
    def _persist_communication_result(self, payload: Dict[str, Any], comm_type: str, state):
        """å°†æ²Ÿé€šç»“æœå†™å…¥å½“å‰ä¼šè¯çš„è¾“å‡ºJSONæ–‡ä»¶ï¼ˆä»state.metadata.output_fileè·å–ï¼‰"""
        default_name = f"/root/wuyue.wy/Project/IA/analysis_results_logs/communications_analysis_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
        log_path = state.get("metadata", {}).get("output_file", default_name)
        try:
            # ç¡®ä¿ç›®å½•å­˜åœ¨
            import os
            os.makedirs("/root/wuyue.wy/Project/IA/analysis_results_logs", exist_ok=True)
            with open(log_path, "r", encoding="utf-8") as f:
                data = json.load(f)
        except Exception:
            data = {}
        
        if "communication_logs" not in data:
            data["communication_logs"] = {"private_chats": [], "meetings": [], "communication_decisions": []}
        
        if comm_type == "private_chat":
            data["communication_logs"].setdefault("private_chats", []).append(payload)
        elif comm_type == "meeting":
            data["communication_logs"].setdefault("meetings", []).append(payload)
        else:
            # å…¶ä»–ç±»å‹ç›´æ¥é™„åŠ åœ¨communication_logsæ ¹éƒ¨ï¼Œå¸¦ä¸Štype
            payload_with_type = {"type": comm_type, **payload}
            data["communication_logs"].setdefault("others", []).append(payload_with_type)
        
        try:
            with open(log_path, "w", encoding="utf-8") as f:
                json.dump(data, f, ensure_ascii=False, indent=2)
            print("å·²å°†æ²Ÿé€šç»“æœå†™å…¥æ—¥å¿—æ–‡ä»¶")
        except Exception as e:
            print(f"é”™è¯¯: å†™å…¥æ²Ÿé€šæ—¥å¿—å¤±è´¥: {e}")
    
    def _get_llm_model(self, state, use_json_mode=False):
        """è·å–LLMæ¨¡å‹å®ä¾‹ï¼ˆä½¿ç”¨ AgentScope æ¨¡å‹åŒ…è£…å™¨ï¼‰"""
        # ä»stateä¸­è·å–APIå¯†é’¥
        api_keys = {}
        if state and "metadata" in state:
            request = state.get("metadata", {}).get("request")
            if request and hasattr(request, 'api_keys'):
                api_keys = request.api_keys
        
        # å¦‚æœmetadataä¸­æ²¡æœ‰ï¼Œå°è¯•ä»dataä¸­è·å–
        if not api_keys and state and "data" in state and "api_keys" in state["data"]:
            api_keys = state["data"]["api_keys"]
        
        model_name = state.get("metadata", {}).get("model_name", "gpt-4o-mini")
        model_provider = state.get("metadata", {}).get("model_provider", "OPENAI")
        
        # ä½¿ç”¨ AgentScope æ¨¡å‹åŒ…è£…å™¨
        llm = get_agentscope_model(model_name, model_provider, api_keys)
        
        # å­˜å‚¨æ˜¯å¦ä½¿ç”¨JSONæ¨¡å¼çš„æ ‡å¿—ï¼Œä¾›è°ƒç”¨æ—¶ä½¿ç”¨
        llm._use_json_mode = use_json_mode
        
        return llm
    
    def decide_communication_strategy(self, manager_signals: Dict[str, Any], 
                                    analyst_signals: Dict[str, Any], 
                                    state) -> CommunicationDecision:
        """å†³å®šäº¤æµç­–ç•¥"""
        
        # æ„å»ºå†³ç­–æç¤º
        # TODO: æ‰€æœ‰ä½¿ç”¨åˆ°ChatPromptTemplateçš„åœ°æ–¹éƒ½æ”¹æˆagentscopeä¸­çš„formatteré€»è¾‘
        #         prompt = await self.formatter.format(
        #             msgs=[
        #                 Msg("system", self.sys_prompt, "system"),
        #                 *await self.memory.get_memory(),
        #             ],
        #         )
        prompt_template = ChatPromptTemplate.from_messages([
            ("system", """You are a portfolio manager responsible for coordinating the analyst team.
        Based on current analysis results, you need to decide whether further communication with analysts is needed.

        There are two communication methods:
        1. private_chat: One-on-one private chat with individual analyst, suitable for in-depth discussion of specific issues
        2. meeting: Organize multiple analysts for group discussion, suitable for collective decision-making or major disagreements

        Must return decision in JSON format, do not include any other text. Please keep any text content within {max_chars} characters."""),
            
            ("human", """Analyst Signal Summary:
        {analyst_signals}

        Please decide whether communication is needed and explain the reason. If communication is needed, please specify:
        - Communication type (private_chat or meeting)
        - Target analyst list (for private_chat: only one analyst, for meeting: multiple analysts)
        - Discussion topic
        - Selection reason

        Return JSON format:
        {{
        "should_communicate": true/false,
        "communication_type": "private_chat" or "meeting",
        "target_analysts": ["analyst1"] (for private_chat) or ["analyst1", "analyst2"] (for meeting),
        "discussion_topic": "discussion topic",
        "reasoning": "selection reason"
        }}""")
        ])
        
        # æ ¼å¼åŒ–åˆ†æå¸ˆä¿¡å·
        signals_summary = {}
        for analyst_id, signal_data in analyst_signals.items():
            if isinstance(signal_data, dict) and 'ticker_signals' in signal_data:
                signals_summary[analyst_id] = signal_data['ticker_signals']
            else:
                signals_summary[analyst_id] = signal_data
        
        # è°ƒç”¨LLM
        messages = prompt_template.format_messages(
            analyst_signals=quiet_json_dumps(signals_summary, ensure_ascii=False, indent=2),
            max_chars=self._get_max_chars(state)
        )
        
        # è·å–LLMæ¨¡å‹ï¼ˆå¯ç”¨JSONæ¨¡å¼ï¼‰
        llm = self._get_llm_model(state, use_json_mode=True)
        
        # è°ƒç”¨æ¨¡å‹ï¼ˆä½¿ç”¨ AgentScope æ–¹å¼ï¼‰
        response = llm(
            messages=messages,
            temperature=0.7,
            response_format={"type": "json_object"} if llm._use_json_mode else None
        )
        
        # ä½¿ç”¨æ›´å¥å£®çš„JSONè§£ææ–¹æ³•
        try:
            # é¦–å…ˆå°è¯•ç›´æ¥è§£æ
            decision_data = json.loads(response["content"])
            return CommunicationDecision(**decision_data)
        except json.JSONDecodeError as e:
            print(f"è­¦å‘Š: é€šä¿¡å†³ç­–JSONè§£æå¤±è´¥: {str(e)}")
            print(f"å“åº”å†…å®¹: {response['content'][:200]}...")
            
            # ä½¿ç”¨å¤‡ç”¨è§£ææ–¹æ³•
            parsed_response = self._extract_and_clean_json(response["content"])
            if parsed_response:
                print("ä½¿ç”¨å¤‡ç”¨æ–¹æ³•æˆåŠŸè§£æé€šä¿¡å†³ç­–JSON")
                return CommunicationDecision(**parsed_response)
            else:
                print("é”™è¯¯: æ‰€æœ‰é€šä¿¡å†³ç­–JSONè§£ææ–¹æ³•éƒ½å¤±è´¥ï¼Œè¿”å›é»˜è®¤å†³ç­–")
                # è¿”å›é»˜è®¤ä¸é€šä¿¡å†³ç­–
                return CommunicationDecision(
                    should_communicate=False,
                    communication_type="none",
                    target_analysts=[],
                    discussion_topic="è§£æå¤±è´¥",
                    reasoning="LLMå“åº”è§£æå¤±è´¥ï¼Œé»˜è®¤ä¸è¿›è¡Œé€šä¿¡"
                )
    
    def conduct_private_chat(self, manager_id: str, analyst_id: str, 
                           topic: str, analyst_signal: Dict[str, Any], 
                           state, max_rounds: int = 1, streamer=None) -> Dict[str, Any]:
        """è¿›è¡Œç§èŠ"""
        print(f"å¼€å§‹ç§èŠ: {manager_id} <-> {analyst_id}")
        print(f"è¯é¢˜: {topic}")
        
        # è¾“å‡ºç§èŠä¿¡æ¯åˆ°å‰ç«¯
        if streamer:
            streamer.print("system", f"å¼€å§‹ç§èŠ: {manager_id} <-> {analyst_id}\nè¯é¢˜: {topic}")
        
        # åœ¨åˆ†æå¸ˆè®°å¿†ä¸­è®°å½•é€šä¿¡å¼€å§‹
        analyst_memory = memory_manager.get_analyst_memory(analyst_id)
        communication_id = None
        if analyst_memory:
            # è·å– trading_date ä½œä¸º analysis_date
            analysis_date = state.get("metadata", {}).get("trading_date") or state.get("data", {}).get("end_date")
            communication_id = analyst_memory.start_communication(
                communication_type="private_chat",
                participants=[manager_id, analyst_id],
                topic=topic,
                analysis_date=analysis_date
            )
        
        # å¼€å§‹ç§èŠ
        initial_message = f"Regarding {topic}, I would like to discuss your analysis results with you. Your current signal is: {quiet_json_dumps(analyst_signal, ensure_ascii=False)}"
        
        chat_id = self.private_chat_system.start_private_chat(
            manager_id, analyst_id, initial_message
        )
        
        # è®°å½•åˆå§‹æ¶ˆæ¯åˆ°åˆ†æå¸ˆè®°å¿†
        if analyst_memory and communication_id:
            analyst_memory.add_communication_message(
                communication_id, manager_id, initial_message
            )
        
        conversation_history = []
        current_analyst_signal = analyst_signal.copy()
        adjustments_made_counter = 0
        
        max_chars = self._get_max_chars(state)
        for round_num in range(max_rounds):
            print(f"\nç§èŠç¬¬{round_num + 1}è½®:")
            
            # è¾“å‡ºè½®æ¬¡åˆ°å‰ç«¯
            if streamer:
                streamer.print("system", f"--- ç¬¬ {round_num + 1} è½®å¯¹è¯ ---")
            
            # åˆ†æå¸ˆå›åº”
            analyst_response = self._get_analyst_chat_response(
                analyst_id, topic, conversation_history, 
                current_analyst_signal, state, streamer=streamer
            )
            # # æˆªæ–­åˆ†æå¸ˆå›åº”
            # if isinstance(analyst_response, dict) and "response" in analyst_response:
            #     analyst_response["response"] = self._truncate_text(analyst_response["response"], max_chars)
            # pdb.set_trace()
            conversation_history.append({
                "speaker": analyst_id,
                "content": analyst_response["response"],
                "round": round_num + 1
            })
            
            print(f"ğŸ—£ï¸ {analyst_id}: {analyst_response['response']}")
            
            # è¾“å‡ºåˆ†æå¸ˆå›åº”åˆ°å‰ç«¯
            if streamer:
                response_text = analyst_response.get("response", "")
                # é™åˆ¶è¾“å‡ºé•¿åº¦
                max_display_length = 300
                if len(response_text) > max_display_length:
                    response_text = response_text[:max_display_length] + "..."
                streamer.print("agent", response_text, role_key=analyst_id)
            
            # è®°å½•åˆ†æå¸ˆå›åº”åˆ°è®°å¿†
            # if analyst_memory and communication_id:
            #     analyst_memory.add_communication_message(
            #         communication_id, analyst_id, analyst_response['response']
            #     )
            
            # æ£€æŸ¥æ˜¯å¦æœ‰ä¿¡å·è°ƒæ•´
            if analyst_response.get("signal_adjustment") and analyst_response.get("adjusted_signal"):
                original_signal = current_analyst_signal
                current_analyst_signal = analyst_response["adjusted_signal"]
                print(f"ä¿¡å·å·²è°ƒæ•´: {analyst_response['signal_adjustment']}")
                adjustments_made_counter += 1
                
                # è¾“å‡ºä¿¡å·è°ƒæ•´åˆ°å‰ç«¯
                if streamer:
                    # è§£æè°ƒæ•´å‰åçš„ä¿¡å·
                    adjusted_signal = analyst_response.get("adjusted_signal", {})
                    
                    # å¤„ç†ä¸¤ç§å¯èƒ½çš„ä¿¡å·æ ¼å¼
                    if isinstance(adjusted_signal, dict):
                        # æ ¼å¼1: {ticker: {signal: ..., confidence: ...}}
                        if 'ticker_signals' in adjusted_signal:
                            # æ ¼å¼2: {ticker_signals: [{ticker: ..., signal: ..., confidence: ...}]}
                            adjustment_details = []
                            for ticker_signal in adjusted_signal.get('ticker_signals', []):
                                ticker = ticker_signal.get('ticker', 'N/A')
                                new_signal = ticker_signal.get('signal', 'N/A')
                                new_confidence = ticker_signal.get('confidence', 'N/A')
                                
                                # è·å–åŸå§‹ä¿¡å·
                                original_ticker_signal = {}
                                if isinstance(original_signal, dict):
                                    if 'ticker_signals' in original_signal:
                                        original_ticker_signal = next(
                                            (s for s in original_signal.get('ticker_signals', []) if s.get('ticker') == ticker),
                                            {}
                                        )
                                    elif ticker in original_signal:
                                        original_ticker_signal = original_signal.get(ticker, {})
                                
                                old_signal = original_ticker_signal.get('signal', 'N/A')
                                old_confidence = original_ticker_signal.get('confidence', 'N/A')
                                
                                adjustment_details.append(
                                    f"  {ticker}: {old_signal}({old_confidence}%) â†’ {new_signal}({new_confidence}%)"
                                )
                            
                            if adjustment_details:
                                streamer.print("agent", 
                                    f"æˆ‘è°ƒæ•´äº†ä¿¡å·:\n" + "\n".join(adjustment_details),
                                    role_key=analyst_id
                                )
                            else:
                                streamer.print("agent", "æˆ‘è°ƒæ•´äº†ä¿¡å·", role_key=analyst_id)
                        else:
                            # ç®€å•çš„ ticker: {signal, confidence} æ ¼å¼
                            adjustment_details = []
                            for ticker, signal_data in adjusted_signal.items():
                                if isinstance(signal_data, dict) and 'signal' in signal_data:
                                    new_signal = signal_data.get('signal', 'N/A')
                                    new_confidence = signal_data.get('confidence', 'N/A')
                                    
                                    old_signal_data = original_signal.get(ticker, {})
                                    old_signal = old_signal_data.get('signal', 'N/A')
                                    old_confidence = old_signal_data.get('confidence', 'N/A')
                                    
                                    adjustment_details.append(
                                        f"  {ticker}: {old_signal}({old_confidence}%) â†’ {new_signal}({new_confidence}%)"
                                    )
                            
                            if adjustment_details:
                                streamer.print("agent", 
                                    f"æˆ‘è°ƒæ•´äº†ä¿¡å·:\n" + "\n".join(adjustment_details),
                                    role_key=analyst_id
                                )
                            else:
                                streamer.print("agent", "æˆ‘è°ƒæ•´äº†ä¿¡å·", role_key=analyst_id)
                    else:
                        streamer.print("agent", "æˆ‘è°ƒæ•´äº†ä¿¡å·", role_key=analyst_id)
                
                # # è®°å½•ä¿¡å·è°ƒæ•´åˆ°è®°å¿†
                # if analyst_memory and communication_id:
                #     analyst_memory.record_signal_adjustment(
                #         communication_id, 
                #         original_signal, 
                #         current_analyst_signal,
                #         f"ç§èŠè®¨è®º{topic}åçš„è°ƒæ•´"
                #     )
            
            # ç®¡ç†è€…å›åº”ï¼ˆå¦‚æœä¸æ˜¯æœ€åä¸€è½®ï¼‰
            if round_num < max_rounds - 1:
                manager_response = self._get_manager_chat_response(
                    manager_id, analyst_id, conversation_history, 
                    current_analyst_signal, state
                )
                manager_response = self._truncate_text(manager_response, max_chars)
                
                conversation_history.append({
                    "speaker": manager_id,
                    "content": manager_response,
                    "round": round_num + 1
                })
                
                print(f"ğŸ—£ï¸ {manager_id}: {manager_response}")
                
                # è¾“å‡ºç®¡ç†è€…å›åº”åˆ°å‰ç«¯
                if streamer:
                    max_display_length = 300
                    manager_display = manager_response if len(manager_response) <= max_display_length else manager_response[:max_display_length] + "..."
                    streamer.print("agent", manager_display, role_key=manager_id)
                
                # # è®°å½•ç®¡ç†è€…å›åº”åˆ°è®°å¿†
                # if analyst_memory and communication_id:
                #     analyst_memory.add_communication_message(
                #         communication_id, manager_id, manager_response
                #     )
        
        # pdb.set_trace()
        print("ç§èŠç»“æŸ")
        
        # è¾“å‡ºç§èŠç»“æŸåˆ°å‰ç«¯
        if streamer:
            streamer.print("system", f"ç§èŠç»“æŸï¼Œå…±è¿›è¡Œ {max_rounds} è½®å¯¹è¯ï¼Œ{adjustments_made_counter} æ¬¡ä¿¡å·è°ƒæ•´")
        
        memory_format = self._convert_private_chat_to_memory_format(
            conversation_history, manager_id, analyst_id, topic, chat_id
        )

        # å°†å¯¹è¯å†å²å­˜å‚¨åˆ°åˆ†æå¸ˆmemoryä¸­
        if analyst_memory and communication_id:
            from src.memory.unified_memory import safe_memory_add
            
            # å°†messageså’Œmetadataå­˜å‚¨åˆ°memory
            result = safe_memory_add(
                memory_instance=analyst_memory.memory,
                messages=memory_format["messages"],
                user_id=analyst_id,
                metadata=memory_format["metadata"],
                infer=False,
                operation_name=f"ç§èŠè®°å½•å­˜å‚¨-{analyst_id}"
            )
            
            
            # å®Œæˆé€šä¿¡è®°å½•
            analyst_memory.complete_communication(communication_id)

      
        # pdb.set_trace()
        result = {
            "chat_history": conversation_history,
            "final_analyst_signal": current_analyst_signal,
            "adjustments_made": adjustments_made_counter,
        }

        return result
    
    def conduct_meeting(self, manager_id: str, analyst_ids: List[str], 
                       topic: str, analyst_signals: Dict[str, Any], 
                       state, max_rounds: int = 2, streamer=None) -> Dict[str, Any]:
        """è¿›è¡Œä¼šè®®"""
        meeting_id = str(uuid.uuid4())
        print(f"å¼€å§‹ä¼šè®®: {meeting_id}")
        print(f"è¯é¢˜: {topic}")
        print(f"å‚ä¸è€…: {', '.join([manager_id] + analyst_ids)}")


        
        # è¾“å‡ºä¼šè®®IDåˆ°å‰ç«¯
        if streamer:
            streamer.print("conference_start", title=topic, conferenceId=meeting_id,
                           participants=[manager_id] + analyst_ids)
        
        # ä¸ºæ¯ä¸ªåˆ†æå¸ˆè®°å½•ä¼šè®®å¼€å§‹
        # è·å– trading_date ä½œä¸º analysis_date
        analysis_date = state.get("metadata", {}).get("trading_date") or state.get("data", {}).get("end_date")
        
        communication_ids = {}
        for analyst_id in analyst_ids:
            analyst_memory = memory_manager.get_analyst_memory(analyst_id)
            if analyst_memory:
                comm_id = analyst_memory.start_communication(
                    communication_type="meeting",
                    participants=[manager_id] + analyst_ids,
                    topic=topic,
                    analysis_date=analysis_date
                )
                communication_ids[analyst_id] = comm_id
        
        # åˆå§‹åŒ–ä¼šè®®ä¿¡æ¯ï¼ˆåªç”¨äºæ—¥å¿—è®°å½•ï¼‰
        print(f"ä¼šè®®åˆ›å»ºæˆåŠŸ - ID: {meeting_id}")
        
        current_signals = analyst_signals.copy()
        meeting_transcript = []
        adjustments_made_counter = 0
        
        # ç®¡ç†è€…å¼€åœº
        opening_message = f"Let's discuss {topic}. Please share your viewpoints and analysis results."
        meeting_transcript.append({
            "speaker": manager_id,
            "content": opening_message,
            "round": 1,
            "timestamp": datetime.now().isoformat()
        })
        
        # è¾“å‡ºå¼€åœºå‘è¨€åˆ°å‰ç«¯
        if streamer:
            streamer.print("agent", f"[å¼€åœº] {opening_message}", role_key=manager_id)
        
        max_chars = self._get_max_chars(state)
        for round_num in range(max_rounds):
            print(f"\nä¼šè®®ç¬¬{round_num + 1}è½®å‘è¨€:")
            
            # è¾“å‡ºè½®æ¬¡åˆ°å‰ç«¯
            if streamer:
                streamer.print("system", f"--- ç¬¬ {round_num + 1} è½®å‘è¨€ ---")
            
            # è°ƒè¯•ï¼šæ‰“å°å½“å‰ä¼šè®®è®°å½•çŠ¶æ€
            if round_num > 0:
                print(f"å½“å‰ä¼šè®®è®°å½•æ¡æ•°: {len(meeting_transcript)}")
                # if meeting_transcript:
                #     print(f"æœ€åä¸€æ¡è®°å½•: {meeting_transcript[-1]}")
            
            # æ¯ä¸ªåˆ†æå¸ˆå‘è¨€
            for analyst_id in analyst_ids:
                analyst_response = self._get_analyst_meeting_response(
                    analyst_id, topic, meeting_transcript, 
                    current_signals.get(analyst_id, {}), 
                    current_signals, state, round_num + 1, streamer=streamer
                )
                # # æˆªæ–­åˆ†æå¸ˆå‘è¨€
                # if isinstance(analyst_response, dict) and "response" in analyst_response:
                #     analyst_response["response"] = self._truncate_text(analyst_response["response"], max_chars)
                
                meeting_transcript.append({
                    "speaker": analyst_id,
                    "content": analyst_response["response"],
                    "round": round_num + 1,
                    "timestamp": datetime.now().isoformat()
                })
                
                # print(f"{analyst_id}: {analyst_response['response']}") 
                print(f"{analyst_id}: {analyst_response}")
                
                # è¾“å‡ºåˆ†æå¸ˆå‘è¨€åˆ°å‰ç«¯
                if streamer:
                    response_text = analyst_response.get("response", "")
                    # é™åˆ¶è¾“å‡ºé•¿åº¦ï¼Œé¿å…è¿‡é•¿
                    max_display_length = 300
                    if len(response_text) > max_display_length:
                        response_text = response_text[:max_display_length] + "..."
                    streamer.print("agent", response_text, role_key=analyst_id)

                # è®°å½•å‘è¨€åˆ°åˆ†æå¸ˆè®°å¿†
                # analyst_memory = memory_manager.get_analyst_memory(analyst_id)
                # if analyst_memory and analyst_id in communication_ids:
                #     analyst_memory.add_communication_message(
                #         communication_ids[analyst_id], analyst_id, analyst_response['response']
                #     )
                
                # æ£€æŸ¥ä¿¡å·è°ƒæ•´
                if analyst_response.get("signal_adjustment") and analyst_response.get("adjusted_signal"):
                    original_signal = current_signals[analyst_id]
                    current_signals[analyst_id] = analyst_response["adjusted_signal"]
                    print(f"{analyst_id} è°ƒæ•´äº†ä¿¡å·")
                    adjustments_made_counter += 1
                    
                    # è¾“å‡ºä¿¡å·è°ƒæ•´åˆ°å‰ç«¯
                    if streamer:
                        # è§£æè°ƒæ•´å‰åçš„ä¿¡å·
                        adjusted_signal = analyst_response.get("adjusted_signal", {})
                        
                        # å¤„ç†ä¸¤ç§å¯èƒ½çš„ä¿¡å·æ ¼å¼
                        if isinstance(adjusted_signal, dict):
                            # æ ¼å¼1: {ticker: {signal: ..., confidence: ...}}
                            if 'ticker_signals' in adjusted_signal:
                                # æ ¼å¼2: {ticker_signals: [{ticker: ..., signal: ..., confidence: ...}]}
                                adjustment_details = []
                                for ticker_signal in adjusted_signal.get('ticker_signals', []):
                                    ticker = ticker_signal.get('ticker', 'N/A')
                                    new_signal = ticker_signal.get('signal', 'N/A')
                                    new_confidence = ticker_signal.get('confidence', 'N/A')
                                    
                                    # è·å–åŸå§‹ä¿¡å·
                                    original_ticker_signal = {}
                                    if isinstance(original_signal, dict):
                                        if 'ticker_signals' in original_signal:
                                            original_ticker_signal = next(
                                                (s for s in original_signal.get('ticker_signals', []) if s.get('ticker') == ticker),
                                                {}
                                            )
                                        elif ticker in original_signal:
                                            original_ticker_signal = original_signal.get(ticker, {})
                                    
                                    old_signal = original_ticker_signal.get('signal', 'N/A')
                                    old_confidence = original_ticker_signal.get('confidence', 'N/A')
                                    
                                    adjustment_details.append(
                                        f"  {ticker}: {old_signal}({old_confidence}%) â†’ {new_signal}({new_confidence}%)"
                                    )
                                
                                if adjustment_details:
                                    streamer.print("agent", 
                                        f"æˆ‘è°ƒæ•´äº†ä¿¡å·:\n" + "\n".join(adjustment_details),
                                        role_key=analyst_id
                                    )
                                else:
                                    streamer.print("agent", "æˆ‘è°ƒæ•´äº†ä¿¡å·", role_key=analyst_id)
                            else:
                                # ç®€å•çš„ ticker: {signal, confidence} æ ¼å¼
                                adjustment_details = []
                                for ticker, signal_data in adjusted_signal.items():
                                    if isinstance(signal_data, dict) and 'signal' in signal_data:
                                        new_signal = signal_data.get('signal', 'N/A')
                                        new_confidence = signal_data.get('confidence', 'N/A')
                                        
                                        old_signal_data = original_signal.get(ticker, {})
                                        old_signal = old_signal_data.get('signal', 'N/A')
                                        old_confidence = old_signal_data.get('confidence', 'N/A')
                                        
                                        adjustment_details.append(
                                            f"  {ticker}: {old_signal}({old_confidence}%) â†’ {new_signal}({new_confidence}%)"
                                        )
                                
                                if adjustment_details:
                                    streamer.print("agent", 
                                        f"æˆ‘è°ƒæ•´äº†ä¿¡å·:\n" + "\n".join(adjustment_details),
                                        role_key=analyst_id
                                    )
                                else:
                                    streamer.print("agent", "æˆ‘è°ƒæ•´äº†ä¿¡å·", role_key=analyst_id)
                        else:
                            streamer.print("agent", "æˆ‘è°ƒæ•´äº†ä¿¡å·", role_key=analyst_id)
                    
                    # è®°å½•ä¿¡å·è°ƒæ•´åˆ°è®°å¿†
                    # if analyst_memory and analyst_id in communication_ids:
                    #     analyst_memory.record_signal_adjustment(
                    #         communication_ids[analyst_id],
                    #         original_signal,
                    #         analyst_response["adjusted_signal"],
                    #         f"ä¼šè®®è®¨è®º{topic}åçš„è°ƒæ•´"
                    #     )
            
            # è¿›å…¥ä¸‹ä¸€è½®å‘è¨€ï¼ˆè½®æ¬¡ç®¡ç†åœ¨meeting_transcriptä¸­è‡ªåŠ¨å¤„ç†ï¼‰
        
        # ç®¡ç†è€…æ€»ç»“
        summary = self._get_manager_meeting_summary(
            manager_id, meeting_transcript, current_signals, state
        )
        summary = self._truncate_text(summary, max_chars)
        
        meeting_transcript.append({
            "speaker": manager_id,
            "content": summary,
            "round": round_num,
            "timestamp": datetime.now().isoformat()
        })
        
        print(f"ä¼šè®®æ€»ç»“: {summary}")
        
        # è¾“å‡ºä¼šè®®æ€»ç»“åˆ°å‰ç«¯
        if streamer:
            streamer.print("system", "--- ä¼šè®®æ€»ç»“ ---")
            # é™åˆ¶æ€»ç»“é•¿åº¦
            max_summary_length = 400
            summary_display = summary if len(summary) <= max_summary_length else summary[:max_summary_length] + "..."
            streamer.print("agent", f"[æ€»ç»“] {summary_display}", role_key=manager_id)
        
        print("ä¼šè®®ç»“æŸ")
        streamer.print("conference_end",conference_id=meeting_id)
        memory_format = self._convert_transcript_to_memory_format(
            meeting_transcript, meeting_id, topic, max_rounds
        )

        # å®Œæˆæ‰€æœ‰åˆ†æå¸ˆçš„é€šä¿¡è®°å½•
        for analyst_id in analyst_ids:
            if analyst_id in communication_ids:
                analyst_memory = memory_manager.get_analyst_memory(analyst_id)
                if analyst_memory:
                    from src.memory.unified_memory import safe_memory_add
                    
                    # å°†messageså’Œmetadataå­˜å‚¨åˆ°memory
                    result = safe_memory_add(
                        memory_instance=analyst_memory.memory,
                        messages=memory_format["messages"],
                        user_id=analyst_id,
                        metadata=memory_format["metadata"],
                        infer=False,
                        operation_name=f"ä¼šè®®è®°å½•å­˜å‚¨-{analyst_id}"
                    )
                    
                    analyst_memory.complete_communication(communication_ids[analyst_id])
        # pdb.set_trace()

        result = {
            "meeting_id": meeting_id,
            "transcript": meeting_transcript,
            "final_signals": current_signals,
            "adjustments_made": adjustments_made_counter
        }
        return result
    
    def _get_analyst_chat_response(self, analyst_id: str, topic: str, 
                                 conversation_history: List[Dict], 
                                 current_signal: Dict[str, Any], 
                                 state, streamer=None) -> Dict[str, Any]:
        """è·å–åˆ†æå¸ˆåœ¨ç§èŠä¸­çš„å›åº”ï¼ˆä¸¤é˜¶æ®µè®°å¿†æ£€ç´¢ï¼‰"""
        
        # ========== ç¬¬ä¸€é˜¶æ®µï¼šè®©analystç”Ÿæˆè®°å¿†æŸ¥è¯¢query â­â­â­ ==========
        analyst_memory = memory_manager.get_analyst_memory(analyst_id)
        relevant_memories = ""
        
        if analyst_memory:
            tickers = state.get("data", {}).get("tickers", [])
            
            # 1. ç”Ÿæˆè®°å¿†æŸ¥è¯¢query
            memory_query = self._generate_memory_query_for_chat(
                analyst_id, topic, conversation_history, tickers, state
            )
            
            # 2. ä½¿ç”¨ç”Ÿæˆçš„queryæ£€ç´¢ç›¸å…³è®°å¿†
            if memory_query:
                try:
                    # å¹¿æ’­memoryæœç´¢æ“ä½œ
                    if streamer:
                        streamer.print(
                            "memory",
                            f"æœç´¢è®°å¿†: {memory_query[:60]}...",
                            agent_id=analyst_id,
                            operation_type="search"
                        )
                    
                    search_results = analyst_memory.memory.search(
                        query=memory_query,
                        user_id=analyst_id,
                        top_k=1  # â­ ä¿®æ­£å‚æ•°åï¼šlimit -> top_k (remeæ¡†æ¶æ ‡å‡†å‚æ•°)
                    )
                    
                    if search_results and search_results.get('results'):
                        relevant_memories = "\n".join([
                            f"- {mem.get('memory', '')}" 
                            for mem in search_results['results']
                        ])
                        print(f"âœ… {analyst_id} æ£€ç´¢åˆ° {len(search_results['results'])} æ¡ç›¸å…³è®°å¿†")
                        
                        # å¹¿æ’­æœç´¢æˆåŠŸ
                        if streamer:
                            streamer.print(
                                "memory",
                                f"æ‰¾åˆ° {len(search_results['results'])} æ¡ç›¸å…³è®°å¿†",
                                agent_id=analyst_id,
                                operation_type="search_success"
                            )
                        # print(relevant_memories)
                    else:
                        print(f"âš ï¸ {analyst_id} æœªæ£€ç´¢åˆ°ç›¸å…³è®°å¿†")
                        if streamer:
                            streamer.print(
                                "memory",
                                "æœªæ‰¾åˆ°ç›¸å…³è®°å¿†",
                                agent_id=analyst_id,
                                operation_type="search_empty"
                            )
                except Exception as e:
                    print(f"âš ï¸ {analyst_id} è®°å¿†æ£€ç´¢å¤±è´¥: {e}")
                    relevant_memories = ""
                    if streamer:
                        streamer.print(
                            "memory",
                            f"è®°å¿†æ£€ç´¢å¤±è´¥: {str(e)[:50]}",
                            agent_id=analyst_id,
                            operation_type="search_error"
                        )
        
        # ========== ç¬¬äºŒé˜¶æ®µï¼šåŸºäºæ£€ç´¢åˆ°çš„è®°å¿†ç”Ÿæˆå›åº” â­â­â­ ==========
        prompt_template = ChatPromptTemplate.from_messages([
    ("system", """You are {analyst_id} analyst. You are having a one-on-one discussion with the portfolio manager.

Your relevant memories and past experiences (retrieved based on this conversation topic):
{relevant_memories}

Based on your relevant memories, conversation history and current analysis signal, please:
1. Respond to the manager's questions or viewpoints
2. Explain your analysis logic (you can reference your previous analysis process)
3. If necessary, adjust your signal, confidence level or reasoning based on new information

Current signal for the topic:
{current_signal}

If you need to adjust the signal, please clearly state the adjustment content and reason in your response.

Please must return your response in JSON format, strictly following the JSON structure below, do not include any other text:

Important: ticker_signals must be an object array, not a string array!

{{
  "response": "your response content",
  "signal_adjustment": true/false,
  "adjusted_signal": {{
    "analyst_id": "{analyst_id}",
    "analyst_name": "your analyst name",
    "ticker_signals": [
      {{"ticker": "AAPL", "signal": "bearish", "confidence": 85, "reasoning": "adjustment reason"}},
      {{"ticker": "MSFT", "signal": "neutral", "confidence": 70, "reasoning": "adjustment reason"}}
    ]
  }}
}}

Prohibited incorrect format:
{{"ticker_signals": ["ticker_signals: [...]"]}}

Must use correct format:
{{"ticker_signals": [{{"ticker": "AAPL", "signal": "bearish", "confidence": 85}}]}}

Note: Please keep the "response" field text content within {max_chars} characters."""),
    
    ("human", """Conversation topic: {topic}

Current conversation history:
{conversation_history}

Please respond to the latest conversation content based on your complete memory and analysis history.""")
])
        
        messages = prompt_template.format_messages(
            analyst_id=analyst_id,
            relevant_memories=relevant_memories if relevant_memories else "No relevant past memories found for this topic.",
            current_signal=quiet_json_dumps(current_signal, ensure_ascii=False),
            topic=topic,
            conversation_history=self._format_conversation_history(conversation_history),
            max_chars=self._get_max_chars(state)
        )
        
        # è·å–LLMæ¨¡å‹ï¼ˆå¯ç”¨JSONæ¨¡å¼ï¼‰
        llm = self._get_llm_model(state, use_json_mode=True)
        
        # è°ƒç”¨æ¨¡å‹ï¼ˆä½¿ç”¨ AgentScope æ–¹å¼ï¼‰
        response = llm(
            messages=messages,
            temperature=0.7,
            response_format={"type": "json_object"} if llm._use_json_mode else None
        )
        
        # ä½¿ç”¨æ›´å¥å£®çš„JSONè§£ææ–¹æ³•
        try:
            # é¦–å…ˆå°è¯•ç›´æ¥è§£æ
            return json.loads(response["content"])
        except json.JSONDecodeError as e:
            print(f"è­¦å‘Š: åˆ†æå¸ˆèŠå¤©å“åº”JSONè§£æå¤±è´¥: {str(e)}")
            print(f"å“åº”å†…å®¹: {response['content'][:200]}...")
            
            # ä½¿ç”¨å¤‡ç”¨è§£ææ–¹æ³•
            parsed_response = self._extract_and_clean_json(response["content"])
            if parsed_response:
                print("ä½¿ç”¨å¤‡ç”¨æ–¹æ³•æˆåŠŸè§£æåˆ†æå¸ˆèŠå¤©å“åº”JSON")
                return parsed_response
            else:
                print("é”™è¯¯: æ‰€æœ‰åˆ†æå¸ˆèŠå¤©å“åº”JSONè§£ææ–¹æ³•éƒ½å¤±è´¥")
                # è¿”å›é»˜è®¤å“åº”
                return {
                    "response": "è§£æå“åº”å¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤å›åº”",
                    "signal_adjustment": False
                }
    
    def _convert_transcript_to_memory_format(self, meeting_transcript: List[Dict], 
                                        meeting_id: str, topic: str, 
                                        total_rounds: int) -> Dict[str, Any]:
        """
        å°†meeting_transcriptè½¬æ¢ä¸ºé€‚åˆmemoryç³»ç»Ÿçš„æ ¼å¼
        
        Args:
            meeting_transcript: åŸå§‹ä¼šè®®è®°å½•
            meeting_id: ä¼šè®®ID  
            topic: ä¼šè®®ä¸»é¢˜
            total_rounds: æ€»è½®æ•°
            
        Returns:
            è½¬æ¢åçš„æ ¼å¼ï¼ŒåŒ…å«messageså’Œmetadata
        """
        messages = []
        
        # å°†æ¯ä¸ªå‘è¨€è½¬æ¢ä¸ºuser roleçš„æ¶ˆæ¯æ ¼å¼
        for entry in meeting_transcript:
            speaker = entry["speaker"]
            content = entry["content"]
            
            # æ ¼å¼åŒ–å†…å®¹ï¼šå‘è¨€è€…åç§° + å‘è¨€å†…å®¹
            formatted_content = f"{speaker}: {content}"
            
            # æ‰€æœ‰å‘è¨€éƒ½ä»¥userè§’è‰²å­˜å‚¨ï¼Œä¾¿äºç»Ÿä¸€ç®¡ç†
            message = {
                "role": "user",
                "content": formatted_content
            }
            
            messages.append(message)
        
        # æ„å»ºmetadata
        metadata = {
            "meeting_id": meeting_id,
            "topic": topic,
            "total_rounds": total_rounds,
            "total_messages": len(meeting_transcript),
            "participants": list(set([entry["speaker"] for entry in meeting_transcript])),
            "communication_type": "meeting"
        }
        
        return {
            "messages": messages,
            "metadata": metadata
        }

    def _convert_private_chat_to_memory_format(self, conversation_history: List[Dict],
                                            manager_id: str, analyst_id: str,
                                            topic: str, chat_id: str) -> Dict[str, Any]:
        """
        å°†ç§èŠå¯¹è¯å†å²è½¬æ¢ä¸ºé€‚åˆmemoryç³»ç»Ÿçš„æ ¼å¼
        
        Args:
            conversation_history: å¯¹è¯å†å²
            manager_id: ç®¡ç†è€…ID
            analyst_id: åˆ†æå¸ˆID
            topic: å¯¹è¯ä¸»é¢˜
            chat_id: å¯¹è¯ID
            
        Returns:
            è½¬æ¢åçš„æ ¼å¼ï¼ŒåŒ…å«messageså’Œmetadata
        """
        messages = []
        
        # æ·»åŠ åˆå§‹æ¶ˆæ¯ï¼ˆç®¡ç†è€…å¼€åœºï¼‰
        initial_message = f"Regarding {topic}, I would like to discuss your analysis results with you."
        messages.append({
            "role": "user",
            "content": f"{manager_id}: {initial_message}"
        })
        
        # å°†æ¯ä¸ªå¯¹è¯è½¬æ¢ä¸ºuser roleçš„æ¶ˆæ¯æ ¼å¼
        for entry in conversation_history:
            speaker = entry["speaker"]
            content = entry["content"]
            
            # æ ¼å¼åŒ–å†…å®¹ï¼šå‘è¨€è€…åç§° + å‘è¨€å†…å®¹
            formatted_content = f"{speaker}: {content}"
            
            # æ‰€æœ‰å‘è¨€éƒ½ä»¥userè§’è‰²å­˜å‚¨ï¼Œä¾¿äºç»Ÿä¸€ç®¡ç†
            message = {
                "role": "user",
                "content": formatted_content
            }
            
            messages.append(message)
        
        # æ„å»ºmetadata
        metadata = {
            "chat_id": chat_id,
            "topic": topic,
            "total_rounds": len([entry for entry in conversation_history if entry["speaker"] == analyst_id]),
            "total_messages": len(conversation_history) + 1,  # +1 for initial message
            "participants": [manager_id, analyst_id],
            "communication_type": "private_chat",
            "manager_id": manager_id,
            "analyst_id": analyst_id
        }
        
        return {
            "messages": messages,
            "metadata": metadata
        }   
    def _get_manager_chat_response(self, manager_id: str, analyst_id: str,
                                 conversation_history: List[Dict],
                                 current_signal: Dict[str, Any], 
                                 state) -> str:
        """è·å–ç®¡ç†è€…åœ¨ç§èŠä¸­çš„å›åº”"""
        
        prompt_template = ChatPromptTemplate.from_messages([
    ("system", """You are a portfolio manager having a one-on-one discussion with an analyst.
Based on the analyst's response, continue the conversation, ask questions or give suggestions.
Maintain a professional and constructive conversation style. Please keep your response within {max_chars} characters."""),
    
    ("human", """Conversation history:
{conversation_history}

Analyst's current signal:
{current_signal}

Please respond to the analyst's latest statement.""")
])
        
        messages = prompt_template.format_messages(
            conversation_history=self._format_conversation_history(conversation_history),
            current_signal=quiet_json_dumps(current_signal, ensure_ascii=False),
            max_chars=self._get_max_chars(state)
        )
        
        # è·å–LLMæ¨¡å‹
        llm = self._get_llm_model(state)
        
        # è°ƒç”¨æ¨¡å‹ï¼ˆä½¿ç”¨ AgentScope æ–¹å¼ï¼‰
        response = llm(messages=messages, temperature=0.7)
        return response["content"]
    
    def _get_analyst_meeting_response(self, analyst_id: str, topic: str,
                                    meeting_transcript: List[Dict],
                                    current_signal: Dict[str, Any],
                                    all_signals: Dict[str, Any],
                                    state, round_num: int, streamer=None) -> Dict[str, Any]:
        """è·å–åˆ†æå¸ˆåœ¨ä¼šè®®ä¸­çš„å‘è¨€ï¼ˆä¸¤é˜¶æ®µè®°å¿†æ£€ç´¢ï¼‰"""
        
        # ========== ç¬¬ä¸€é˜¶æ®µï¼šè®©analystç”Ÿæˆè®°å¿†æŸ¥è¯¢query â­â­â­ ==========
        analyst_memory = memory_manager.get_analyst_memory(analyst_id)
        relevant_memories = ""
        
        if analyst_memory:
            tickers = state.get("data", {}).get("tickers", [])
            
            # 1. ç”Ÿæˆè®°å¿†æŸ¥è¯¢query
            memory_query = self._generate_memory_query_for_meeting(
                analyst_id, topic, meeting_transcript, tickers, state
            )
            
            # 2. ä½¿ç”¨ç”Ÿæˆçš„queryæ£€ç´¢ç›¸å…³è®°å¿†
            if memory_query:
                try:
                    # å¹¿æ’­memoryæœç´¢æ“ä½œ
                    if streamer:
                        streamer.print(
                            "memory",
                            f"æœç´¢è®°å¿†: {memory_query[:60]}...",
                            agent_id=analyst_id,
                            operation_type="search"
                        )
                    
                    search_results = analyst_memory.memory.search(
                        query=memory_query,
                        user_id=analyst_id,
                        top_k=1  # â­ ä¿®æ­£å‚æ•°åï¼šlimit -> top_k (remeæ¡†æ¶æ ‡å‡†å‚æ•°)
                    )
                    
                    if search_results and search_results.get('results'):
                        relevant_memories = "\n".join([
                            f"- {mem.get('memory', '')}" 
                            for mem in search_results['results']
                        ])
                        print(f"âœ… {analyst_id} åœ¨ä¼šè®®ä¸­æ£€ç´¢åˆ° {len(search_results['results'])} æ¡ç›¸å…³è®°å¿†")
                        print(relevant_memories)
                        
                        # å¹¿æ’­æœç´¢æˆåŠŸ
                        if streamer:
                            streamer.print(
                                "memory",
                                f"æ‰¾åˆ° {len(search_results['results'])} æ¡ç›¸å…³è®°å¿†",
                                agent_id=analyst_id,
                                operation_type="search_success"
                            )
                    else:
                        print(f"âš ï¸ {analyst_id} åœ¨ä¼šè®®ä¸­æœªæ£€ç´¢åˆ°ç›¸å…³è®°å¿†")
                        if streamer:
                            streamer.print(
                                "memory",
                                "æœªæ‰¾åˆ°ç›¸å…³è®°å¿†",
                                agent_id=analyst_id,
                                operation_type="search_empty"
                            )
                except Exception as e:
                    print(f"âš ï¸ {analyst_id} ä¼šè®®è®°å¿†æ£€ç´¢å¤±è´¥: {e}")
                    relevant_memories = ""
                    if streamer:
                        streamer.print(
                            "memory",
                            f"è®°å¿†æ£€ç´¢å¤±è´¥: {str(e)[:50]}",
                            agent_id=analyst_id,
                            operation_type="search_error"
                        )
        
        # ========== ç¬¬äºŒé˜¶æ®µï¼šåŸºäºæ£€ç´¢åˆ°çš„è®°å¿†ç”Ÿæˆå‘è¨€ â­â­â­ ==========
        prompt_template = ChatPromptTemplate.from_messages([
    ("system", """You are {analyst_id} analyst participating in an investment meeting.

Your relevant memories and past experiences (retrieved based on this meeting topic):
{relevant_memories}

Your current analysis signal:
{current_signal}

Please must return your response in JSON format, strictly following the JSON structure below, do not include any other text:

Important: ticker_signals must be an object array, not a string array!

{{
  "response": "your speech content",
  "signal_adjustment": true/false,
  "adjusted_signal": {{
    "analyst_id": "{analyst_id}",
    "analyst_name": "your analyst name",
    "ticker_signals": [
      {{"ticker": "AAPL", "signal": "bearish", "confidence": 85, "reasoning": "adjustment reason"}},
      {{"ticker": "MSFT", "signal": "neutral", "confidence": 70, "reasoning": "adjustment reason"}}
    ]
  }}
}}

Prohibited incorrect format:
{{"ticker_signals": ["ticker_signals: [...]"]}}

Must use correct format:
{{"ticker_signals": [{{"ticker": "AAPL", "signal": "bearish", "confidence": 85}}]}}

Note: Please keep the "response" field text content within {max_chars} characters."""),
    
    ("human", """Meeting topic: {topic}

This is round {round_num} of speeches.

Meeting transcript (Important! Please read carefully and respond):
{meeting_transcript}

Other analysts' signals:
{other_signals}

Speech requirements:
1. If this is round 1: Share your viewpoints and analysis basis
2. If this is round 2 or more:
   - Must explicitly respond to specific viewpoints from other analysts in previous rounds
   - State whether you agree or disagree with their analysis, and give reasons
   - Consider whether to adjust your signal based on discussion content
   - Avoid repeating round 1 speech content

Please speak based on meeting transcript and discussion content, showing genuine interaction and critical thinking process.""")
])
        
        messages = prompt_template.format_messages(
            analyst_id=analyst_id,
            relevant_memories=relevant_memories if relevant_memories else "No relevant past memories found for this topic.",
            round_num=round_num,
            current_signal=quiet_json_dumps(current_signal, ensure_ascii=False),
            topic=topic,
            meeting_transcript=self._format_meeting_transcript(meeting_transcript),
            other_signals=quiet_json_dumps({k: v for k, v in all_signals.items() if k != analyst_id}, ensure_ascii=False, indent=2),
            max_chars=self._get_max_chars(state)
        )
        # pdb.set_trace()
        # è·å–LLMæ¨¡å‹ï¼ˆå¯ç”¨JSONæ¨¡å¼ï¼‰
        llm = self._get_llm_model(state, use_json_mode=True)
        
        # è°ƒç”¨æ¨¡å‹ï¼ˆä½¿ç”¨ AgentScope æ–¹å¼ï¼‰
        response = llm(
            messages=messages,
            temperature=0.7,
            response_format={"type": "json_object"} if llm._use_json_mode else None
        )
        
        # ä½¿ç”¨æ›´å¥å£®çš„JSONè§£ææ–¹æ³•
        try:
            # é¦–å…ˆå°è¯•ç›´æ¥è§£æ
            return json.loads(response["content"])
        except json.JSONDecodeError as e:
            print(f"è­¦å‘Š: åˆ†æå¸ˆä¼šè®®å“åº”JSONè§£æå¤±è´¥: {str(e)}")
            print(f"å“åº”å†…å®¹: {response['content'][:200]}...")
            
            # ä½¿ç”¨å¤‡ç”¨è§£ææ–¹æ³•
            parsed_response = self._extract_and_clean_json(response["content"])
            if parsed_response:
                print("ä½¿ç”¨å¤‡ç”¨æ–¹æ³•æˆåŠŸè§£æåˆ†æå¸ˆä¼šè®®å“åº”JSON")
                return parsed_response
            else:
                print("é”™è¯¯: æ‰€æœ‰åˆ†æå¸ˆä¼šè®®å“åº”JSONè§£ææ–¹æ³•éƒ½å¤±è´¥")
                # è¿”å›é»˜è®¤å“åº”
                return {
                    "response": "è§£æå“åº”å¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤å›åº”",
                    "signal_adjustment": False
                }
    
    def _get_manager_meeting_summary(self, manager_id: str, 
                                   meeting_transcript: List[Dict],
                                   final_signals: Dict[str, Any], 
                                   state) -> str:
        """è·å–ç®¡ç†è€…çš„ä¼šè®®æ€»ç»“"""
        
        prompt_template = ChatPromptTemplate.from_messages([
            ("system", """You are a portfolio manager summarizing meeting content.
        Please concisely summarize discussion points and final consensus reached. Please keep the summary within {max_chars} characters."""),
            
            ("human", """Meeting transcript:
        {meeting_transcript}

        Final signals:
        {final_signals}

        Please summarize this meeting.""")
        ])
        
        messages = prompt_template.format_messages(
            meeting_transcript=self._format_meeting_transcript(meeting_transcript),
            final_signals=quiet_json_dumps(final_signals, ensure_ascii=False, indent=2),
            max_chars=self._get_max_chars(state)
        )
        
        # è·å–LLMæ¨¡å‹
        llm = self._get_llm_model(state)
        
        # è°ƒç”¨æ¨¡å‹ï¼ˆä½¿ç”¨ AgentScope æ–¹å¼ï¼‰
        response = llm(messages=messages, temperature=0.7)
        return response["content"]
    
    def _format_conversation_history(self, history: List[Dict]) -> str:
        """æ ¼å¼åŒ–å¯¹è¯å†å²"""
        formatted = []
        for entry in history:
            formatted.append(f"{entry['speaker']}: {entry['content']}")
        return "\n".join(formatted)
    
    def _format_meeting_transcript(self, transcript: List[Dict]) -> str:
        """æ ¼å¼åŒ–ä¼šè®®è®°å½•"""
        formatted = []
        for entry in transcript:
            round_info = f"ç¬¬{entry['round']}è½®" if isinstance(entry['round'], int) else entry['round']
            formatted.append(f"[{round_info}] {entry['speaker']}: {entry['content']}")
        return "\n".join(formatted)
    
    def _generate_memory_query_for_chat(self, analyst_id: str, topic: str, 
                                       conversation_history: List[Dict],
                                       tickers: List[str], state) -> str:
        """
        ç¬¬ä¸€é˜¶æ®µï¼šè®©analystæ ¹æ®ç§èŠè¯é¢˜å’Œä¸Šä¸‹æ–‡ç”Ÿæˆè®°å¿†æŸ¥è¯¢query
        
        Args:
            analyst_id: åˆ†æå¸ˆID
            topic: ç§èŠè¯é¢˜
            conversation_history: å¯¹è¯å†å²
            tickers: è‚¡ç¥¨ä»£ç åˆ—è¡¨
            state: ç³»ç»ŸçŠ¶æ€
            
        Returns:
            è®°å¿†æŸ¥è¯¢queryå­—ç¬¦ä¸²
        """
        prompt_template = ChatPromptTemplate.from_messages([
            ("system", """You are {analyst_id} analyst. You are about to respond in a private chat with the portfolio manager.

Before responding, you need to search your past analysis experiences and memories to inform your response.

Please generate a concise search query (in Chinese or English, 1-2 sentences) to retrieve relevant memories from your past experiences.

The query should focus on:
1. The specific stocks being discussed: {tickers}
2. The conversation topic: {topic}
3. Key themes from recent conversation
4. Similar analysis scenarios or lessons learned

Return ONLY the search query text, no explanations or extra formatting."""),
            
            ("human", """Conversation topic: {topic}
Stocks: {tickers}

Recent conversation:
{conversation_history}

Generate a focused search query to retrieve relevant past memories and experiences.""")
        ])
        
        messages = prompt_template.format_messages(
            analyst_id=analyst_id,
            topic=topic,
            tickers=", ".join(tickers),
            conversation_history=self._format_conversation_history(conversation_history[-3:]) if conversation_history else "No previous conversation"
        )
        
        try:
            llm = self._get_llm_model(state)
            response = llm(messages=messages, temperature=0.7)
            query = response["content"].strip()
            print(f"ğŸ“ {analyst_id} ç”Ÿæˆè®°å¿†æŸ¥è¯¢: {query}")
            return query
        except Exception as e:
            print(f"âš ï¸ {analyst_id} ç”Ÿæˆè®°å¿†æŸ¥è¯¢å¤±è´¥: {e}")
            # è¿”å›é»˜è®¤æŸ¥è¯¢
            return f"{topic} {' '.join(tickers)} åˆ†æç»éªŒ"
    
    def _generate_memory_query_for_meeting(self, analyst_id: str, topic: str,
                                          meeting_transcript: List[Dict],
                                          tickers: List[str], state) -> str:
        """
        ç¬¬ä¸€é˜¶æ®µï¼šè®©analystæ ¹æ®ä¼šè®®è¯é¢˜å’Œä¸Šä¸‹æ–‡ç”Ÿæˆè®°å¿†æŸ¥è¯¢query
        
        Args:
            analyst_id: åˆ†æå¸ˆID
            topic: ä¼šè®®è¯é¢˜
            meeting_transcript: ä¼šè®®è®°å½•
            tickers: è‚¡ç¥¨ä»£ç åˆ—è¡¨
            state: ç³»ç»ŸçŠ¶æ€
            
        Returns:
            è®°å¿†æŸ¥è¯¢queryå­—ç¬¦ä¸²
        """
        prompt_template = ChatPromptTemplate.from_messages([
            ("system", """You are {analyst_id} analyst. You are about to speak in an investment meeting.

Before speaking, you need to search your past analysis experiences and memories to inform your contribution.

Please generate a concise search query (in Chinese or English, 1-2 sentences) to retrieve relevant memories from your past experiences.

The query should focus on:
1. The specific stocks being discussed: {tickers}
2. The meeting topic: {topic}
3. Key themes from meeting discussion so far
4. Similar analysis scenarios or lessons learned

Return ONLY the search query text, no explanations or extra formatting."""),
            
            ("human", """Meeting topic: {topic}
Stocks: {tickers}

Recent meeting discussion:
{meeting_transcript}

Generate a focused search query to retrieve relevant past memories and experiences.""")
        ])
        
        messages = prompt_template.format_messages(
            analyst_id=analyst_id,
            topic=topic,
            tickers=", ".join(tickers),
            meeting_transcript=self._format_meeting_transcript(meeting_transcript[-5:]) if meeting_transcript else "Meeting just started"
        )
        
        try:
            llm = self._get_llm_model(state)
            response = llm(messages=messages, temperature=0.7)
            query = response["content"].strip()
            print(f"ğŸ“ {analyst_id} åœ¨ä¼šè®®ä¸­ç”Ÿæˆè®°å¿†æŸ¥è¯¢: {query}")
            return query
        except Exception as e:
            print(f"âš ï¸ {analyst_id} ä¼šè®®è®°å¿†æŸ¥è¯¢ç”Ÿæˆå¤±è´¥: {e}")
            # è¿”å›é»˜è®¤æŸ¥è¯¢
            return f"{topic} {' '.join(tickers)} åˆ†æç»éªŒ"
    
    def _extract_and_clean_json(self, content: str) -> Optional[Dict[str, Any]]:
        """ä»å“åº”ä¸­æå–å’Œæ¸…ç†JSON"""
        try:
            # ç§»é™¤markdownä»£ç å—
            content = re.sub(r'```json\s*\n?', '', content)
            content = re.sub(r'\n?\s*```', '', content)
            
            # æŸ¥æ‰¾JSONéƒ¨åˆ†
            json_match = re.search(r'\{.*\}', content, re.DOTALL)
            if json_match:
                json_str = json_match.group()
                
                # ç§»é™¤æ³¨é‡Š
                json_str = re.sub(r'//.*', '', json_str)
                
                # å°è¯•è§£æ
                return json.loads(json_str)
            
            # å¦‚æœæ‰¾ä¸åˆ°å®Œæ•´JSONï¼Œå°è¯•æå–å…³é”®å­—æ®µ
            response_match = re.search(r'"response"\s*:\s*"([^"]*)"', content)
            adjustment_match = re.search(r'"signal_adjustment"\s*:\s*(true|false)', content)
            
            if response_match:
                return {
                    "response": response_match.group(1),
                    "signal_adjustment": adjustment_match.group(1) == 'true' if adjustment_match else False
                }
                
        except Exception as e:
            print(f"JSONæå–è¿‡ç¨‹å‡ºé”™: {str(e)}")
            
        return None


# åˆ›å»ºå…¨å±€å®ä¾‹
communication_manager = CommunicationManager()
