#!/usr/bin/env python3
"""
é€šä¿¡å·¥å…· - ç§èŠå’Œå¼€ä¼šåŠŸèƒ½çš„å®ç°
"""

import json
import uuid
import re
from datetime import datetime
from typing import Dict, List, Any, Optional
from pydantic import BaseModel, Field
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.messages import HumanMessage, AIMessage

from src.llm.models import get_model
from src.utils.api_key import get_api_key_from_state
from .analyst_memory import memory_manager


class PrivateChatMessage(BaseModel):
    """ç§èŠæ¶ˆæ¯æ¨¡å‹"""
    id: str = Field(default_factory=lambda: str(uuid.uuid4()))
    sender: str = Field(..., description="å‘é€è€…ID")
    receiver: str = Field(..., description="æ¥æ”¶è€…ID")
    content: str = Field(..., description="æ¶ˆæ¯å†…å®¹")
    timestamp: datetime = Field(default_factory=datetime.now)
    message_type: str = Field(default="chat", description="æ¶ˆæ¯ç±»å‹")


class MeetingMessage(BaseModel):
    """ä¼šè®®æ¶ˆæ¯æ¨¡å‹"""
    id: str = Field(default_factory=lambda: str(uuid.uuid4()))
    speaker: str = Field(..., description="å‘è¨€è€…ID")
    content: str = Field(..., description="å‘è¨€å†…å®¹")
    timestamp: datetime = Field(default_factory=datetime.now)
    round: int = Field(..., description="å‘è¨€è½®æ¬¡")


class SignalAdjustment(BaseModel):
    """ä¿¡å·è°ƒæ•´æ¨¡å‹"""
    ticker: str = Field(..., description="è‚¡ç¥¨ä»£ç ")
    original_signal: str = Field(..., description="åŸå§‹ä¿¡å·")
    adjusted_signal: str = Field(..., description="è°ƒæ•´åä¿¡å·")
    original_confidence: int = Field(..., description="åŸå§‹ä¿¡å¿ƒåº¦")
    adjusted_confidence: int = Field(..., description="è°ƒæ•´åä¿¡å¿ƒåº¦")
    adjustment_reasoning: str = Field(..., description="è°ƒæ•´åŸå› ")


class CommunicationDecision(BaseModel):
    """äº¤æµå†³ç­–æ¨¡å‹"""
    should_communicate: bool = Field(..., description="æ˜¯å¦éœ€è¦äº¤æµ")
    communication_type: str = Field(..., description="äº¤æµç±»å‹: private_chat æˆ– meeting")
    target_analysts: List[str] = Field(default_factory=list, description="ç›®æ ‡åˆ†æå¸ˆåˆ—è¡¨")
    discussion_topic: str = Field(..., description="è®¨è®ºè¯é¢˜")
    reasoning: str = Field(..., description="é€‰æ‹©äº¤æµçš„åŸå› ")


class PrivateChatSystem:
    """ç§èŠç³»ç»Ÿ"""
    
    def __init__(self):
        self.chat_histories: Dict[str, List[PrivateChatMessage]] = {}
    
    def start_private_chat(self, manager_id: str, analyst_id: str, 
                          initial_message: str) -> str:
        """å¼€å§‹ç§èŠå¯¹è¯"""
        chat_key = f"{manager_id}_{analyst_id}"
        
        if chat_key not in self.chat_histories:
            self.chat_histories[chat_key] = []
        
        # æ·»åŠ ç®¡ç†è€…çš„åˆå§‹æ¶ˆæ¯
        message = PrivateChatMessage(
            sender=manager_id,
            receiver=analyst_id,
            content=initial_message
        )
        
        self.chat_histories[chat_key].append(message)
        return message.id
    
    def send_message(self, sender: str, receiver: str, content: str) -> str:
        """å‘é€æ¶ˆæ¯"""
        chat_key = f"{sender}_{receiver}" if sender < receiver else f"{receiver}_{sender}"
        
        if chat_key not in self.chat_histories:
            self.chat_histories[chat_key] = []
        
        message = PrivateChatMessage(
            sender=sender,
            receiver=receiver,
            content=content
        )
        
        self.chat_histories[chat_key].append(message)
        return message.id
    
    def get_chat_history(self, participant1: str, participant2: str) -> List[PrivateChatMessage]:
        """è·å–èŠå¤©å†å²"""
        chat_key = f"{participant1}_{participant2}" if participant1 < participant2 else f"{participant2}_{participant1}"
        return self.chat_histories.get(chat_key, [])


class MeetingSystem:
    """ä¼šè®®ç³»ç»Ÿ"""
    
    def __init__(self):
        self.meetings: Dict[str, Dict[str, Any]] = {}
    
    def create_meeting(self, meeting_id: str, host: str, participants: List[str], 
                      topic: str) -> str:
        """åˆ›å»ºä¼šè®®"""
        self.meetings[meeting_id] = {
            "id": meeting_id,
            "host": host,
            "participants": participants,
            "topic": topic,
            "messages": [],
            "current_round": 1,
            "status": "active",
            "created_at": datetime.now()
        }
        return meeting_id
    
    def add_message(self, meeting_id: str, speaker: str, content: str) -> str:
        """æ·»åŠ ä¼šè®®å‘è¨€"""
        if meeting_id not in self.meetings:
            raise ValueError(f"ä¼šè®® {meeting_id} ä¸å­˜åœ¨")
        
        meeting = self.meetings[meeting_id]
        message = MeetingMessage(
            speaker=speaker,
            content=content,
            round=meeting["current_round"]
        )
        
        meeting["messages"].append(message)
        return message.id
    
    def next_round(self, meeting_id: str):
        """è¿›å…¥ä¸‹ä¸€è½®å‘è¨€"""
        if meeting_id in self.meetings:
            self.meetings[meeting_id]["current_round"] += 1
    
    def end_meeting(self, meeting_id: str):
        """ç»“æŸä¼šè®®"""
        if meeting_id in self.meetings:
            self.meetings[meeting_id]["status"] = "ended"
    
    def get_meeting_transcript(self, meeting_id: str) -> List[MeetingMessage]:
        """è·å–ä¼šè®®è®°å½•"""
        if meeting_id not in self.meetings:
            return []
        return self.meetings[meeting_id]["messages"]


class CommunicationManager:
    """äº¤æµç®¡ç†å™¨"""
    
    def __init__(self):
        self.private_chat_system = PrivateChatSystem()
        self.meeting_system = MeetingSystem()
    
    def _get_llm_model(self, state, use_json_mode=False):
        """è·å–LLMæ¨¡å‹å®ä¾‹"""
        try:
            # ä»stateä¸­è·å–APIå¯†é’¥
            api_keys = {}
            if state and "data" in state and "api_keys" in state["data"]:
                api_keys = state["data"]["api_keys"]
            
            model_name = state.get("metadata", {}).get("model_name", "gpt-3.5-turbo")
            model_provider = state.get("metadata", {}).get("model_provider", "OpenAI")
            
            llm = get_model(model_name, model_provider, api_keys)
            
            # å¦‚æœéœ€è¦JSONæ¨¡å¼ï¼Œé…ç½®ç»“æ„åŒ–è¾“å‡º
            if use_json_mode and hasattr(llm, 'bind'):
                try:
                    llm = llm.bind(response_format={"type": "json_object"})
                except Exception:
                    # å¦‚æœä¸æ”¯æŒJSONæ¨¡å¼ï¼Œç»§ç»­ä½¿ç”¨å¸¸è§„æ¨¡å¼
                    pass
            
            return llm
        except Exception as e:
            print(f"âŒ è·å–LLMæ¨¡å‹å¤±è´¥: {str(e)}")
            # ä½¿ç”¨é»˜è®¤é…ç½®
            return get_model("gpt-3.5-turbo", "OpenAI", None)
    
    def decide_communication_strategy(self, manager_signals: Dict[str, Any], 
                                    analyst_signals: Dict[str, Any], 
                                    state) -> CommunicationDecision:
        """å†³å®šäº¤æµç­–ç•¥"""
        
        # æ„å»ºå†³ç­–æç¤º
        prompt_template = ChatPromptTemplate.from_messages([
            ("system", """ä½ æ˜¯ä¸€ä¸ªæŠ•èµ„ç»„åˆç®¡ç†è€…ï¼Œè´Ÿè´£åè°ƒåˆ†æå¸ˆå›¢é˜Ÿã€‚
åŸºäºå½“å‰çš„åˆ†æç»“æœï¼Œä½ éœ€è¦å†³å®šæ˜¯å¦éœ€è¦ä¸åˆ†æå¸ˆè¿›è¡Œè¿›ä¸€æ­¥äº¤æµã€‚

äº¤æµæ–¹å¼æœ‰ä¸¤ç§ï¼š
1. private_chat: ä¸å•ä¸ªåˆ†æå¸ˆä¸€å¯¹ä¸€ç§èŠï¼Œé€‚ç”¨äºéœ€è¦æ·±å…¥è®¨è®ºç‰¹å®šé—®é¢˜
2. meeting: ç»„ç»‡å¤šä¸ªåˆ†æå¸ˆå¼€ä¼šè®¨è®ºï¼Œé€‚ç”¨äºéœ€è¦é›†ä½“å†³ç­–æˆ–å­˜åœ¨é‡å¤§åˆ†æ­§

å¿…é¡»ä»¥JSONæ ¼å¼è¿”å›å†³ç­–ï¼Œä¸è¦åŒ…å«ä»»ä½•å…¶ä»–æ–‡æœ¬ã€‚"""),
            
            ("human", """åˆ†æå¸ˆä¿¡å·æ±‡æ€»:
{analyst_signals}

è¯·å†³å®šæ˜¯å¦éœ€è¦äº¤æµï¼Œå¹¶è¯´æ˜åŸå› ã€‚å¦‚æœéœ€è¦äº¤æµï¼Œè¯·æŒ‡å®šï¼š
- äº¤æµç±»å‹ (private_chat æˆ– meeting)
- ç›®æ ‡åˆ†æå¸ˆåˆ—è¡¨
- è®¨è®ºè¯é¢˜
- é€‰æ‹©åŸå› 

è¿”å›JSONæ ¼å¼ï¼š
{{
  "should_communicate": true/false,
  "communication_type": "private_chat" æˆ– "meeting",
  "target_analysts": ["analyst1", "analyst2"],
  "discussion_topic": "è®¨è®ºè¯é¢˜",
  "reasoning": "é€‰æ‹©åŸå› "
}}""")
        ])
        
        try:
            # æ ¼å¼åŒ–åˆ†æå¸ˆä¿¡å·
            signals_summary = {}
            for analyst_id, signal_data in analyst_signals.items():
                if isinstance(signal_data, dict) and 'ticker_signals' in signal_data:
                    signals_summary[analyst_id] = signal_data['ticker_signals']
                else:
                    signals_summary[analyst_id] = signal_data
            
            # è°ƒç”¨LLM
            messages = prompt_template.format_messages(
                analyst_signals=json.dumps(signals_summary, ensure_ascii=False, indent=2)
            )
            
            # è·å–LLMæ¨¡å‹ï¼ˆå¯ç”¨JSONæ¨¡å¼ï¼‰
            llm = self._get_llm_model(state, use_json_mode=True)
            
            # è°ƒç”¨æ¨¡å‹
            response = llm.invoke(messages)
            
            # å°è¯•è§£æJSON
            try:
                decision_data = json.loads(response.content)
            except json.JSONDecodeError as e:
                print(f"âŒ JSONè§£æå¤±è´¥: {str(e)}")
                print(f"å“åº”å†…å®¹: {response.content}")
                # è¿”å›é»˜è®¤å†³ç­–
                return CommunicationDecision(
                    should_communicate=False,
                    communication_type="none",
                    target_analysts=[],
                    discussion_topic="",
                    reasoning="JSONè§£æå¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤å†³ç­–"
                )
            
            return CommunicationDecision(**decision_data)
            
        except Exception as e:
            print(f"âŒ äº¤æµå†³ç­–å¤±è´¥: {str(e)}")
            return CommunicationDecision(
                should_communicate=False,
                communication_type="none",
                target_analysts=[],
                discussion_topic="",
                reasoning=f"å†³ç­–è¿‡ç¨‹å‡ºé”™: {str(e)}"
            )
    
    def conduct_private_chat(self, manager_id: str, analyst_id: str, 
                           topic: str, analyst_signal: Dict[str, Any], 
                           state, max_rounds: int = 3) -> Dict[str, Any]:
        """è¿›è¡Œç§èŠ"""
        print(f"ğŸ’¬ å¼€å§‹ç§èŠ: {manager_id} <-> {analyst_id}")
        print(f"ğŸ“‹ è¯é¢˜: {topic}")
        
        # åœ¨åˆ†æå¸ˆè®°å¿†ä¸­è®°å½•é€šä¿¡å¼€å§‹
        analyst_memory = memory_manager.get_analyst_memory(analyst_id)
        communication_id = None
        if analyst_memory:
            communication_id = analyst_memory.start_communication(
                communication_type="private_chat",
                participants=[manager_id, analyst_id],
                topic=topic
            )
        
        # å¼€å§‹ç§èŠ
        initial_message = f"å…³äº{topic}ï¼Œæˆ‘æƒ³å’Œä½ è®¨è®ºä¸€ä¸‹ä½ çš„åˆ†æç»“æœã€‚ä½ ç›®å‰çš„ä¿¡å·æ˜¯ï¼š{json.dumps(analyst_signal, ensure_ascii=False)}"
        
        chat_id = self.private_chat_system.start_private_chat(
            manager_id, analyst_id, initial_message
        )
        
        # è®°å½•åˆå§‹æ¶ˆæ¯åˆ°åˆ†æå¸ˆè®°å¿†
        if analyst_memory and communication_id:
            analyst_memory.add_communication_message(
                communication_id, manager_id, initial_message
            )
        
        conversation_history = []
        current_analyst_signal = analyst_signal.copy()
        
        for round_num in range(max_rounds):
            print(f"\nğŸ’¬ ç§èŠç¬¬{round_num + 1}è½®:")
            
            # åˆ†æå¸ˆå›åº”
            analyst_response = self._get_analyst_chat_response(
                analyst_id, topic, conversation_history, 
                current_analyst_signal, state
            )
            
            conversation_history.append({
                "speaker": analyst_id,
                "content": analyst_response["response"],
                "round": round_num + 1
            })
            
            print(f"ğŸ—£ï¸ {analyst_id}: {analyst_response['response']}")
            
            # è®°å½•åˆ†æå¸ˆå›åº”åˆ°è®°å¿†
            if analyst_memory and communication_id:
                analyst_memory.add_communication_message(
                    communication_id, analyst_id, analyst_response['response']
                )
            
            # æ£€æŸ¥æ˜¯å¦æœ‰ä¿¡å·è°ƒæ•´
            if analyst_response.get("signal_adjustment") and analyst_response.get("adjusted_signal"):
                original_signal = current_analyst_signal
                current_analyst_signal = analyst_response["adjusted_signal"]
                print(f"ğŸ“Š ä¿¡å·å·²è°ƒæ•´: {analyst_response['signal_adjustment']}")
                
                # è®°å½•ä¿¡å·è°ƒæ•´åˆ°è®°å¿†
                if analyst_memory and communication_id:
                    analyst_memory.record_signal_adjustment(
                        communication_id, 
                        original_signal, 
                        current_analyst_signal,
                        f"ç§èŠè®¨è®º{topic}åçš„è°ƒæ•´"
                    )
            
            # ç®¡ç†è€…å›åº”ï¼ˆå¦‚æœä¸æ˜¯æœ€åä¸€è½®ï¼‰
            if round_num < max_rounds - 1:
                manager_response = self._get_manager_chat_response(
                    manager_id, analyst_id, conversation_history, 
                    current_analyst_signal, state
                )
                
                conversation_history.append({
                    "speaker": manager_id,
                    "content": manager_response,
                    "round": round_num + 1
                })
                
                print(f"ğŸ—£ï¸ {manager_id}: {manager_response}")
                
                # è®°å½•ç®¡ç†è€…å›åº”åˆ°è®°å¿†
                if analyst_memory and communication_id:
                    analyst_memory.add_communication_message(
                        communication_id, manager_id, manager_response
                    )
        
        print("âœ… ç§èŠç»“æŸ")
        
        # å®Œæˆé€šä¿¡è®°å½•
        if analyst_memory and communication_id:
            analyst_memory.complete_communication(communication_id)
        
        return {
            "chat_history": conversation_history,
            "final_analyst_signal": current_analyst_signal,
            "adjustments_made": len([h for h in conversation_history if "è°ƒæ•´" in h.get("content", "")])
        }
    
    def conduct_meeting(self, manager_id: str, analyst_ids: List[str], 
                       topic: str, analyst_signals: Dict[str, Any], 
                       state, max_rounds: int = 2) -> Dict[str, Any]:
        """è¿›è¡Œä¼šè®®"""
        meeting_id = str(uuid.uuid4())
        print(f"ğŸ¢ å¼€å§‹ä¼šè®®: {meeting_id}")
        print(f"ğŸ“‹ è¯é¢˜: {topic}")
        print(f"ğŸ‘¥ å‚ä¸è€…: {', '.join([manager_id] + analyst_ids)}")
        
        # ä¸ºæ¯ä¸ªåˆ†æå¸ˆè®°å½•ä¼šè®®å¼€å§‹
        communication_ids = {}
        for analyst_id in analyst_ids:
            analyst_memory = memory_manager.get_analyst_memory(analyst_id)
            if analyst_memory:
                comm_id = analyst_memory.start_communication(
                    communication_type="meeting",
                    participants=[manager_id] + analyst_ids,
                    topic=topic
                )
                communication_ids[analyst_id] = comm_id
        
        # åˆ›å»ºä¼šè®®
        self.meeting_system.create_meeting(
            meeting_id, manager_id, analyst_ids, topic
        )
        
        current_signals = analyst_signals.copy()
        meeting_transcript = []
        
        # ç®¡ç†è€…å¼€åœº
        opening_message = f"æˆ‘ä»¬æ¥è®¨è®º{topic}ã€‚è¯·å„ä½åˆ†æå¸ˆåˆ†äº«ä½ ä»¬çš„è§‚ç‚¹å’Œåˆ†æç»“æœã€‚"
        self.meeting_system.add_message(meeting_id, manager_id, opening_message)
        meeting_transcript.append({
            "speaker": manager_id,
            "content": opening_message,
            "round": 1
        })
        
        for round_num in range(max_rounds):
            print(f"\nğŸ¢ ä¼šè®®ç¬¬{round_num + 1}è½®å‘è¨€:")
            
            # æ¯ä¸ªåˆ†æå¸ˆå‘è¨€
            for analyst_id in analyst_ids:
                analyst_response = self._get_analyst_meeting_response(
                    analyst_id, topic, meeting_transcript, 
                    current_signals.get(analyst_id, {}), 
                    current_signals, state, round_num + 1
                )
                
                self.meeting_system.add_message(
                    meeting_id, analyst_id, analyst_response["response"]
                )
                
                meeting_transcript.append({
                    "speaker": analyst_id,
                    "content": analyst_response["response"],
                    "round": round_num + 1
                })
                
                print(f"ğŸ—£ï¸ {analyst_id}: {analyst_response['response']}")
                
                # è®°å½•å‘è¨€åˆ°åˆ†æå¸ˆè®°å¿†
                analyst_memory = memory_manager.get_analyst_memory(analyst_id)
                if analyst_memory and analyst_id in communication_ids:
                    analyst_memory.add_communication_message(
                        communication_ids[analyst_id], analyst_id, analyst_response['response']
                    )
                
                # æ£€æŸ¥ä¿¡å·è°ƒæ•´
                if analyst_response.get("signal_adjustment") and analyst_response.get("adjusted_signal"):
                    original_signal = current_signals[analyst_id]
                    current_signals[analyst_id] = analyst_response["adjusted_signal"]
                    print(f"ğŸ“Š {analyst_id} è°ƒæ•´äº†ä¿¡å·")
                    
                    # è®°å½•ä¿¡å·è°ƒæ•´åˆ°è®°å¿†
                    if analyst_memory and analyst_id in communication_ids:
                        analyst_memory.record_signal_adjustment(
                            communication_ids[analyst_id],
                            original_signal,
                            analyst_response["adjusted_signal"],
                            f"ä¼šè®®è®¨è®º{topic}åçš„è°ƒæ•´"
                        )
            
            self.meeting_system.next_round(meeting_id)
        
        # ç®¡ç†è€…æ€»ç»“
        summary = self._get_manager_meeting_summary(
            manager_id, meeting_transcript, current_signals, state
        )
        
        self.meeting_system.add_message(meeting_id, manager_id, summary)
        meeting_transcript.append({
            "speaker": manager_id,
            "content": summary,
            "round": "summary"
        })
        
        print(f"ğŸ“‹ ä¼šè®®æ€»ç»“: {summary}")
        
        self.meeting_system.end_meeting(meeting_id)
        print("âœ… ä¼šè®®ç»“æŸ")
        
        # å®Œæˆæ‰€æœ‰åˆ†æå¸ˆçš„é€šä¿¡è®°å½•
        for analyst_id in analyst_ids:
            if analyst_id in communication_ids:
                analyst_memory = memory_manager.get_analyst_memory(analyst_id)
                if analyst_memory:
                    analyst_memory.complete_communication(communication_ids[analyst_id])
        
        return {
            "meeting_id": meeting_id,
            "transcript": meeting_transcript,
            "final_signals": current_signals,
            "adjustments_made": len([t for t in meeting_transcript if "è°ƒæ•´" in t.get("content", "")])
        }
    
    def _get_analyst_chat_response(self, analyst_id: str, topic: str, 
                                 conversation_history: List[Dict], 
                                 current_signal: Dict[str, Any], 
                                 state) -> Dict[str, Any]:
        """è·å–åˆ†æå¸ˆåœ¨ç§èŠä¸­çš„å›åº”"""
        
        # è·å–åˆ†æå¸ˆçš„å®Œæ•´è®°å¿†ä¸Šä¸‹æ–‡
        analyst_memory = memory_manager.get_analyst_memory(analyst_id)
        full_context = ""
        if analyst_memory:
            tickers = state.get("data", {}).get("tickers", [])
            full_context = analyst_memory.get_full_context_for_communication(tickers)
        
        prompt_template = ChatPromptTemplate.from_messages([
            ("system", f"""ä½ æ˜¯{analyst_id}åˆ†æå¸ˆã€‚ä½ æ­£åœ¨ä¸æŠ•èµ„ç»„åˆç®¡ç†è€…è¿›è¡Œä¸€å¯¹ä¸€è®¨è®ºã€‚

ä½ çš„å®Œæ•´è®°å¿†å’Œåˆ†æå†å²ï¼š
{full_context}

åŸºäºä½ çš„è®°å¿†ã€å¯¹è¯å†å²å’Œå½“å‰åˆ†æä¿¡å·ï¼Œè¯·ï¼š
1. å›åº”ç®¡ç†è€…çš„é—®é¢˜æˆ–è§‚ç‚¹
2. è§£é‡Šä½ çš„åˆ†æé€»è¾‘ï¼ˆå¯ä»¥å¼•ç”¨ä½ ä¹‹å‰çš„åˆ†æè¿‡ç¨‹ï¼‰
3. å¦‚æœæœ‰å¿…è¦ï¼ŒåŸºäºæ–°ä¿¡æ¯è°ƒæ•´ä½ çš„ä¿¡å·ã€ä¿¡å¿ƒåº¦æˆ–reasoning

å½“å‰è¯é¢˜çš„ä¿¡å·ï¼š{json.dumps(current_signal, ensure_ascii=False)}

å¦‚æœéœ€è¦è°ƒæ•´ä¿¡å·ï¼Œè¯·åœ¨å›åº”ä¸­æ˜ç¡®è¯´æ˜è°ƒæ•´å†…å®¹å’ŒåŸå› ã€‚

å¿…é¡»ä»¥JSONæ ¼å¼è¿”å›ï¼Œä¸è¦åŒ…å«ä»»ä½•å…¶ä»–æ–‡æœ¬ï¼š
{{
  "response": "ä½ çš„å›åº”å†…å®¹",
  "signal_adjustment": true/false,
  "adjusted_signal": {{...}} // å¦‚æœæœ‰è°ƒæ•´çš„è¯
}}"""),
            
            ("human", f"""å¯¹è¯è¯é¢˜ï¼š{topic}

å½“å‰å¯¹è¯å†å²ï¼š
{self._format_conversation_history(conversation_history)}

è¯·åŸºäºä½ çš„å®Œæ•´è®°å¿†å’Œåˆ†æå†å²å›åº”æœ€æ–°çš„å¯¹è¯å†…å®¹ã€‚""")
        ])
        
        try:
            messages = prompt_template.format_messages()
            
            # è·å–LLMæ¨¡å‹ï¼ˆå¯ç”¨JSONæ¨¡å¼ï¼‰
            llm = self._get_llm_model(state, use_json_mode=True)
            
            # è°ƒç”¨æ¨¡å‹
            response = llm.invoke(messages)
            
            # å°è¯•è§£æJSON
            try:
                return json.loads(response.content)
            except json.JSONDecodeError as e:
                print(f"âŒ åˆ†æå¸ˆå›åº”JSONè§£æå¤±è´¥: {str(e)}")
                print(f"å“åº”å†…å®¹: {response.content}")
                return {
                    "response": f"æˆ‘ç†è§£ä½ çš„è§‚ç‚¹ï¼ŒåŸºäºå½“å‰åˆ†æä¿æŒåŸæœ‰ç«‹åœºã€‚",
                    "signal_adjustment": False
                }
            
        except Exception as e:
            print(f"âŒ è·å–åˆ†æå¸ˆå›åº”å¤±è´¥: {str(e)}")
            return {
                "response": f"æŠ±æ­‰ï¼Œæˆ‘åœ¨å¤„ç†å›åº”æ—¶é‡åˆ°äº†é—®é¢˜ï¼š{str(e)}",
                "signal_adjustment": False
            }
    
    def _get_manager_chat_response(self, manager_id: str, analyst_id: str,
                                 conversation_history: List[Dict],
                                 current_signal: Dict[str, Any], 
                                 state) -> str:
        """è·å–ç®¡ç†è€…åœ¨ç§èŠä¸­çš„å›åº”"""
        
        prompt_template = ChatPromptTemplate.from_messages([
            ("system", """ä½ æ˜¯æŠ•èµ„ç»„åˆç®¡ç†è€…ï¼Œæ­£åœ¨ä¸åˆ†æå¸ˆè¿›è¡Œä¸€å¯¹ä¸€è®¨è®ºã€‚
åŸºäºåˆ†æå¸ˆçš„å›åº”ï¼Œç»§ç»­å¯¹è¯ï¼Œæå‡ºé—®é¢˜æˆ–ç»™å‡ºå»ºè®®ã€‚
ä¿æŒä¸“ä¸šå’Œå»ºè®¾æ€§çš„å¯¹è¯é£æ ¼ã€‚"""),
            
            ("human", f"""å¯¹è¯å†å²ï¼š
{self._format_conversation_history(conversation_history)}

åˆ†æå¸ˆå½“å‰ä¿¡å·ï¼š{json.dumps(current_signal, ensure_ascii=False)}

è¯·å›åº”åˆ†æå¸ˆæœ€æ–°çš„å‘è¨€ã€‚""")
        ])
        
        try:
            messages = prompt_template.format_messages()
            
            # è·å–LLMæ¨¡å‹
            llm = self._get_llm_model(state)
            
            # è°ƒç”¨æ¨¡å‹
            response = llm.invoke(messages)
            return response.content
            
        except Exception as e:
            print(f"âŒ è·å–ç®¡ç†è€…å›åº”å¤±è´¥: {str(e)}")
            return f"æˆ‘éœ€è¦æ›´å¤šæ—¶é—´æ€è€ƒè¿™ä¸ªé—®é¢˜ã€‚"
    
    def _get_analyst_meeting_response(self, analyst_id: str, topic: str,
                                    meeting_transcript: List[Dict],
                                    current_signal: Dict[str, Any],
                                    all_signals: Dict[str, Any],
                                    state, round_num: int) -> Dict[str, Any]:
        """è·å–åˆ†æå¸ˆåœ¨ä¼šè®®ä¸­çš„å‘è¨€"""
        
        # è·å–åˆ†æå¸ˆçš„å®Œæ•´è®°å¿†ä¸Šä¸‹æ–‡
        analyst_memory = memory_manager.get_analyst_memory(analyst_id)
        full_context = ""
        if analyst_memory:
            tickers = state.get("data", {}).get("tickers", [])
            full_context = analyst_memory.get_full_context_for_communication(tickers)
        
        prompt_template = ChatPromptTemplate.from_messages([
            ("system", f"""ä½ æ˜¯{analyst_id}åˆ†æå¸ˆï¼Œæ­£åœ¨å‚åŠ ä¸€ä¸ªæŠ•èµ„ä¼šè®®ã€‚

ä½ çš„å®Œæ•´è®°å¿†å’Œåˆ†æå†å²ï¼š
{full_context}

è¿™æ˜¯ç¬¬{round_num}è½®å‘è¨€ã€‚åŸºäºä½ çš„è®°å¿†å’Œåˆ†æå†å²ï¼Œè¯·ï¼š
1. åˆ†äº«ä½ çš„è§‚ç‚¹å’Œåˆ†æï¼ˆå¯ä»¥å¼•ç”¨ä½ ä¹‹å‰çš„åˆ†æè¿‡ç¨‹å’Œç»“è®ºï¼‰
2. å›åº”å…¶ä»–ä¸ä¼šè€…çš„è§‚ç‚¹
3. å¦‚æœå¬åˆ°æœ‰è¯´æœåŠ›çš„è®ºæ®ï¼ŒåŸºäºæ–°ä¿¡æ¯è€ƒè™‘è°ƒæ•´ä½ çš„ä¿¡å·
4. ä¿æŒä½ ä½œä¸º{analyst_id}çš„ä¸“ä¸šç‰¹è‰²å’Œä¸€è‡´æ€§

ä½ å½“å‰çš„åˆ†æä¿¡å·ï¼š{json.dumps(current_signal, ensure_ascii=False)}

å¿…é¡»ä»¥JSONæ ¼å¼è¿”å›ï¼Œä¸è¦åŒ…å«ä»»ä½•å…¶ä»–æ–‡æœ¬ï¼š
{{
  "response": "ä½ çš„å‘è¨€å†…å®¹",
  "signal_adjustment": true/false,
  "adjusted_signal": {{...}} // å¦‚æœæœ‰è°ƒæ•´çš„è¯
}}"""),
            
            ("human", f"""ä¼šè®®è¯é¢˜ï¼š{topic}

ä¼šè®®è®°å½•ï¼š
{self._format_meeting_transcript(meeting_transcript)}

å…¶ä»–åˆ†æå¸ˆçš„ä¿¡å·ï¼š
{json.dumps({k: v for k, v in all_signals.items() if k != analyst_id}, ensure_ascii=False, indent=2)}

è¯·åŸºäºä½ çš„å®Œæ•´è®°å¿†å’Œä¸“ä¸šèƒŒæ™¯å‘è¨€ã€‚""")
        ])
        
        try:
            messages = prompt_template.format_messages()
            
            # è·å–LLMæ¨¡å‹ï¼ˆå¯ç”¨JSONæ¨¡å¼ï¼‰
            llm = self._get_llm_model(state, use_json_mode=True)
            
            # è°ƒç”¨æ¨¡å‹
            response = llm.invoke(messages)
            
            # å°è¯•è§£æJSON
            try:
                return json.loads(response.content)
            except json.JSONDecodeError as e:
                print(f"âŒ ä¼šè®®å‘è¨€JSONè§£æå¤±è´¥: {str(e)}")
                print(f"å“åº”å†…å®¹: {response.content}")
                return {
                    "response": f"åŸºäºæˆ‘çš„åˆ†æï¼Œæˆ‘è®¤ä¸ºå½“å‰ç­–ç•¥æ˜¯åˆç†çš„ã€‚",
                    "signal_adjustment": False
                }
            
        except Exception as e:
            print(f"âŒ è·å–åˆ†æå¸ˆä¼šè®®å‘è¨€å¤±è´¥: {str(e)}")
            return {
                "response": f"æˆ‘åŒæ„ä¹‹å‰çš„åˆ†æè§‚ç‚¹ã€‚",
                "signal_adjustment": False
            }
    
    def _get_manager_meeting_summary(self, manager_id: str, 
                                   meeting_transcript: List[Dict],
                                   final_signals: Dict[str, Any], 
                                   state) -> str:
        """è·å–ç®¡ç†è€…çš„ä¼šè®®æ€»ç»“"""
        
        prompt_template = ChatPromptTemplate.from_messages([
            ("system", """ä½ æ˜¯æŠ•èµ„ç»„åˆç®¡ç†è€…ï¼Œæ­£åœ¨æ€»ç»“ä¼šè®®å†…å®¹ã€‚
è¯·ç®€æ´åœ°æ€»ç»“è®¨è®ºè¦ç‚¹å’Œæœ€ç»ˆè¾¾æˆçš„å…±è¯†ã€‚"""),
            
            ("human", f"""ä¼šè®®è®°å½•ï¼š
{self._format_meeting_transcript(meeting_transcript)}

æœ€ç»ˆä¿¡å·ï¼š
{json.dumps(final_signals, ensure_ascii=False, indent=2)}

è¯·æ€»ç»“è¿™æ¬¡ä¼šè®®ã€‚""")
        ])
        
        try:
            messages = prompt_template.format_messages()
            
            # è·å–LLMæ¨¡å‹
            llm = self._get_llm_model(state)
            
            # è°ƒç”¨æ¨¡å‹
            response = llm.invoke(messages)
            return response.content
            
        except Exception as e:
            print(f"âŒ è·å–ä¼šè®®æ€»ç»“å¤±è´¥: {str(e)}")
            return "ä¼šè®®è®¨è®ºäº†æŠ•èµ„ç­–ç•¥ï¼Œå„åˆ†æå¸ˆè¡¨è¾¾äº†è§‚ç‚¹ã€‚"
    
    def _format_conversation_history(self, history: List[Dict]) -> str:
        """æ ¼å¼åŒ–å¯¹è¯å†å²"""
        formatted = []
        for entry in history:
            formatted.append(f"{entry['speaker']}: {entry['content']}")
        return "\n".join(formatted)
    
    def _format_meeting_transcript(self, transcript: List[Dict]) -> str:
        """æ ¼å¼åŒ–ä¼šè®®è®°å½•"""
        formatted = []
        for entry in transcript:
            round_info = f"ç¬¬{entry['round']}è½®" if isinstance(entry['round'], int) else entry['round']
            formatted.append(f"[{round_info}] {entry['speaker']}: {entry['content']}")
        return "\n".join(formatted)


# åˆ›å»ºå…¨å±€å®ä¾‹
communication_manager = CommunicationManager()
