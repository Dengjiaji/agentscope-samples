#!/usr/bin/env python3
"""
é€šä¿¡å·¥å…· - ç§èŠå’Œå¼€ä¼šåŠŸèƒ½çš„å®ç°
"""

import json
import uuid
import re
from datetime import datetime
from typing import Dict, List, Any, Optional
from pydantic import BaseModel, Field
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.messages import HumanMessage, AIMessage

from src.llm.models import get_model
from src.utils.api_key import get_api_key_from_state
from src.utils.json_utils import quiet_json_dumps
from .analyst_memory import memory_manager


class PrivateChatMessage(BaseModel):
    """ç§èŠæ¶ˆæ¯æ¨¡å‹"""
    id: str = Field(default_factory=lambda: str(uuid.uuid4()))
    sender: str = Field(..., description="å‘é€è€…ID")
    receiver: str = Field(..., description="æ¥æ”¶è€…ID")
    content: str = Field(..., description="æ¶ˆæ¯å†…å®¹")
    timestamp: datetime = Field(default_factory=datetime.now)
    message_type: str = Field(default="chat", description="æ¶ˆæ¯ç±»å‹")


class MeetingMessage(BaseModel):
    """ä¼šè®®æ¶ˆæ¯æ¨¡å‹"""
    id: str = Field(default_factory=lambda: str(uuid.uuid4()))
    speaker: str = Field(..., description="å‘è¨€è€…ID")
    content: str = Field(..., description="å‘è¨€å†…å®¹")
    timestamp: datetime = Field(default_factory=datetime.now)
    round: int = Field(..., description="å‘è¨€è½®æ¬¡")


class SignalAdjustment(BaseModel):
    """ä¿¡å·è°ƒæ•´æ¨¡å‹"""
    ticker: str = Field(..., description="è‚¡ç¥¨ä»£ç ")
    original_signal: str = Field(..., description="åŸå§‹ä¿¡å·")
    adjusted_signal: str = Field(..., description="è°ƒæ•´åä¿¡å·")
    original_confidence: int = Field(..., description="åŸå§‹ä¿¡å¿ƒåº¦")
    adjusted_confidence: int = Field(..., description="è°ƒæ•´åä¿¡å¿ƒåº¦")
    adjustment_reasoning: str = Field(..., description="è°ƒæ•´åŸå› ")


class CommunicationDecision(BaseModel):
    """äº¤æµå†³ç­–æ¨¡å‹"""
    should_communicate: bool = Field(..., description="æ˜¯å¦éœ€è¦äº¤æµ")
    communication_type: str = Field(..., description="äº¤æµç±»å‹: private_chat æˆ– meeting")
    target_analysts: List[str] = Field(default_factory=list, description="ç›®æ ‡åˆ†æå¸ˆåˆ—è¡¨")
    discussion_topic: str = Field(..., description="è®¨è®ºè¯é¢˜")
    reasoning: str = Field(..., description="é€‰æ‹©äº¤æµçš„åŸå› ")


class PrivateChatSystem:
    """ç§èŠç³»ç»Ÿ"""
    
    def __init__(self):
        self.chat_histories: Dict[str, List[PrivateChatMessage]] = {}
    
    def start_private_chat(self, manager_id: str, analyst_id: str, 
                          initial_message: str) -> str:
        """å¼€å§‹ç§èŠå¯¹è¯"""
        chat_key = f"{manager_id}_{analyst_id}"
        
        if chat_key not in self.chat_histories:
            self.chat_histories[chat_key] = []
        
        # æ·»åŠ ç®¡ç†è€…çš„åˆå§‹æ¶ˆæ¯
        message = PrivateChatMessage(
            sender=manager_id,
            receiver=analyst_id,
            content=initial_message
        )
        
        self.chat_histories[chat_key].append(message)
        return message.id
    
    def send_message(self, sender: str, receiver: str, content: str) -> str:
        """å‘é€æ¶ˆæ¯"""
        chat_key = f"{sender}_{receiver}" if sender < receiver else f"{receiver}_{sender}"
        
        if chat_key not in self.chat_histories:
            self.chat_histories[chat_key] = []
        
        message = PrivateChatMessage(
            sender=sender,
            receiver=receiver,
            content=content
        )
        
        self.chat_histories[chat_key].append(message)
        return message.id
    
    def get_chat_history(self, participant1: str, participant2: str) -> List[PrivateChatMessage]:
        """è·å–èŠå¤©å†å²"""
        chat_key = f"{participant1}_{participant2}" if participant1 < participant2 else f"{participant2}_{participant1}"
        return self.chat_histories.get(chat_key, [])


class MeetingSystem:
    """ä¼šè®®ç³»ç»Ÿ"""
    
    def __init__(self):
        self.meetings: Dict[str, Dict[str, Any]] = {}
    
    def create_meeting(self, meeting_id: str, host: str, participants: List[str], 
                      topic: str) -> str:
        """åˆ›å»ºä¼šè®®"""
        self.meetings[meeting_id] = {
            "id": meeting_id,
            "host": host,
            "participants": participants,
            "topic": topic,
            "messages": [],
            "current_round": 1,
            "status": "active",
            "created_at": datetime.now()
        }
        return meeting_id
    
    def add_message(self, meeting_id: str, speaker: str, content: str) -> str:
        """æ·»åŠ ä¼šè®®å‘è¨€"""
        if meeting_id not in self.meetings:
            raise ValueError(f"ä¼šè®® {meeting_id} ä¸å­˜åœ¨")
        
        meeting = self.meetings[meeting_id]
        message = MeetingMessage(
            speaker=speaker,
            content=content,
            round=meeting["current_round"]
        )
        
        meeting["messages"].append(message)
        return message.id
    
    def next_round(self, meeting_id: str):
        """è¿›å…¥ä¸‹ä¸€è½®å‘è¨€"""
        if meeting_id in self.meetings:
            self.meetings[meeting_id]["current_round"] += 1
    
    def end_meeting(self, meeting_id: str):
        """ç»“æŸä¼šè®®"""
        if meeting_id in self.meetings:
            self.meetings[meeting_id]["status"] = "ended"
    
    def get_meeting_transcript(self, meeting_id: str) -> List[MeetingMessage]:
        """è·å–ä¼šè®®è®°å½•"""
        if meeting_id not in self.meetings:
            return []
        return self.meetings[meeting_id]["messages"]


class CommunicationManager:
    """äº¤æµç®¡ç†å™¨"""
    
    def __init__(self):
        self.private_chat_system = PrivateChatSystem()
        self.meeting_system = MeetingSystem()
        
    def _get_max_chars(self, state) -> int:
        """è·å–æ²Ÿé€šæ–‡æœ¬æœ€å¤§å­—æ•°ï¼Œé»˜è®¤400ï¼Œå¯é€šè¿‡state.metadata.communication_max_charsè¦†ç›–"""
        try:
            return int(state.get("metadata", {}).get("communication_max_chars", 400))
        except Exception:
            return 400
    
    def _truncate_text(self, text: str, max_chars: int) -> str:
        """æŒ‰å­—æ•°ä¸Šé™æˆªæ–­æ–‡æœ¬ï¼ˆé¢å‘ä¸­æ–‡ï¼‰ï¼Œä¿ç•™å‰max_charsä¸ªå­—ç¬¦"""
        if not isinstance(text, str):
            return text
        return text if len(text) <= max_chars else text[:max_chars]
    
    def _persist_communication_result(self, payload: Dict[str, Any], comm_type: str, state):
        """å°†æ²Ÿé€šç»“æœå†™å…¥å½“å‰ä¼šè¯çš„è¾“å‡ºJSONæ–‡ä»¶ï¼ˆä»state.metadata.output_fileè·å–ï¼‰"""
        default_name = f"/root/wuyue.wy/Project/IA/analysis_results_logs/communications_analysis_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
        log_path = state.get("metadata", {}).get("output_file", default_name)
        try:
            # ç¡®ä¿ç›®å½•å­˜åœ¨
            import os
            os.makedirs("/root/wuyue.wy/Project/IA/analysis_results_logs", exist_ok=True)
            with open(log_path, "r", encoding="utf-8") as f:
                data = json.load(f)
        except Exception:
            data = {}
        
        if "communication_logs" not in data:
            data["communication_logs"] = {"private_chats": [], "meetings": [], "communication_decisions": []}
        
        if comm_type == "private_chat":
            data["communication_logs"].setdefault("private_chats", []).append(payload)
        elif comm_type == "meeting":
            data["communication_logs"].setdefault("meetings", []).append(payload)
        else:
            # å…¶ä»–ç±»å‹ç›´æ¥é™„åŠ åœ¨communication_logsæ ¹éƒ¨ï¼Œå¸¦ä¸Štype
            payload_with_type = {"type": comm_type, **payload}
            data["communication_logs"].setdefault("others", []).append(payload_with_type)
        
        try:
            with open(log_path, "w", encoding="utf-8") as f:
                json.dump(data, f, ensure_ascii=False, indent=2)
            print("å·²å°†æ²Ÿé€šç»“æœå†™å…¥æ—¥å¿—æ–‡ä»¶")
        except Exception as e:
            print(f"é”™è¯¯: å†™å…¥æ²Ÿé€šæ—¥å¿—å¤±è´¥: {e}")
    
    def _get_llm_model(self, state, use_json_mode=False):
        """è·å–LLMæ¨¡å‹å®ä¾‹"""
        # ä»stateä¸­è·å–APIå¯†é’¥
        api_keys = {}
        if state and "data" in state and "api_keys" in state["data"]:
            api_keys = state["data"]["api_keys"]
        
        model_name = state.get("metadata", {}).get("model_name", "gpt-3.5-turbo")
        model_provider = state.get("metadata", {}).get("model_provider", "OpenAI")
        
        llm = get_model(model_name, model_provider, api_keys)
        
        # å¦‚æœéœ€è¦JSONæ¨¡å¼ï¼Œé…ç½®ç»“æ„åŒ–è¾“å‡º
        if use_json_mode:
            # å°è¯•å¤šç§JSONæ¨¡å¼ç»‘å®šæ–¹å¼
            if hasattr(llm, 'bind'):
                llm = llm.bind(response_format={"type": "json_object"})
            elif hasattr(llm, 'with_config'):
                llm = llm.with_config({"response_format": {"type": "json_object"}})
            # print(f"JSONæ¨¡å¼å·²å¯ç”¨ for {model_name}")
        
        return llm
    
    def decide_communication_strategy(self, manager_signals: Dict[str, Any], 
                                    analyst_signals: Dict[str, Any], 
                                    state) -> CommunicationDecision:
        """å†³å®šäº¤æµç­–ç•¥"""
        
        # æ„å»ºå†³ç­–æç¤º
        prompt_template = ChatPromptTemplate.from_messages([
            ("system", """You are a portfolio manager responsible for coordinating the analyst team.
        Based on current analysis results, you need to decide whether further communication with analysts is needed.

        There are two communication methods:
        1. private_chat: One-on-one private chat with individual analyst, suitable for in-depth discussion of specific issues
        2. meeting: Organize multiple analysts for group discussion, suitable for collective decision-making or major disagreements

        Must return decision in JSON format, do not include any other text. Please keep any text content within {max_chars} characters."""),
            
            ("human", """Analyst Signal Summary:
        {analyst_signals}

        Please decide whether communication is needed and explain the reason. If communication is needed, please specify:
        - Communication type (private_chat or meeting)
        - Target analyst list
        - Discussion topic
        - Selection reason

        Return JSON format:
        {{
        "should_communicate": true/false,
        "communication_type": "private_chat" or "meeting",
        "target_analysts": ["analyst1", "analyst2"],
        "discussion_topic": "discussion topic",
        "reasoning": "selection reason"
        }}""")
        ])
        
        # æ ¼å¼åŒ–åˆ†æå¸ˆä¿¡å·
        signals_summary = {}
        for analyst_id, signal_data in analyst_signals.items():
            if isinstance(signal_data, dict) and 'ticker_signals' in signal_data:
                signals_summary[analyst_id] = signal_data['ticker_signals']
            else:
                signals_summary[analyst_id] = signal_data
        
        # è°ƒç”¨LLM
        messages = prompt_template.format_messages(
            analyst_signals=quiet_json_dumps(signals_summary, ensure_ascii=False, indent=2),
            max_chars=self._get_max_chars(state)
        )
        
        # è·å–LLMæ¨¡å‹ï¼ˆå¯ç”¨JSONæ¨¡å¼ï¼‰
        llm = self._get_llm_model(state, use_json_mode=True)
        
        # è°ƒç”¨æ¨¡å‹
        response = llm.invoke(messages)
        
        # ä½¿ç”¨æ›´å¥å£®çš„JSONè§£ææ–¹æ³•
        try:
            # é¦–å…ˆå°è¯•ç›´æ¥è§£æ
            decision_data = json.loads(response.content)
            return CommunicationDecision(**decision_data)
        except json.JSONDecodeError as e:
            print(f"è­¦å‘Š: é€šä¿¡å†³ç­–JSONè§£æå¤±è´¥: {str(e)}")
            print(f"å“åº”å†…å®¹: {response.content[:200]}...")
            
            # ä½¿ç”¨å¤‡ç”¨è§£ææ–¹æ³•
            parsed_response = self._extract_and_clean_json(response.content)
            if parsed_response:
                print("ä½¿ç”¨å¤‡ç”¨æ–¹æ³•æˆåŠŸè§£æé€šä¿¡å†³ç­–JSON")
                return CommunicationDecision(**parsed_response)
            else:
                print("é”™è¯¯: æ‰€æœ‰é€šä¿¡å†³ç­–JSONè§£ææ–¹æ³•éƒ½å¤±è´¥ï¼Œè¿”å›é»˜è®¤å†³ç­–")
                # è¿”å›é»˜è®¤ä¸é€šä¿¡å†³ç­–
                return CommunicationDecision(
                    should_communicate=False,
                    communication_type="none",
                    target_analysts=[],
                    discussion_topic="è§£æå¤±è´¥",
                    reasoning="LLMå“åº”è§£æå¤±è´¥ï¼Œé»˜è®¤ä¸è¿›è¡Œé€šä¿¡"
                )
    
    def conduct_private_chat(self, manager_id: str, analyst_id: str, 
                           topic: str, analyst_signal: Dict[str, Any], 
                           state, max_rounds: int = 3) -> Dict[str, Any]:
        """è¿›è¡Œç§èŠ"""
        print(f"å¼€å§‹ç§èŠ: {manager_id} <-> {analyst_id}")
        print(f"è¯é¢˜: {topic}")
        
        # åœ¨åˆ†æå¸ˆè®°å¿†ä¸­è®°å½•é€šä¿¡å¼€å§‹
        analyst_memory = memory_manager.get_analyst_memory(analyst_id)
        communication_id = None
        if analyst_memory:
            communication_id = analyst_memory.start_communication(
                communication_type="private_chat",
                participants=[manager_id, analyst_id],
                topic=topic
            )
        
        # å¼€å§‹ç§èŠ
        initial_message = f"Regarding {topic}, I would like to discuss your analysis results with you. Your current signal is: {quiet_json_dumps(analyst_signal, ensure_ascii=False)}"
        
        chat_id = self.private_chat_system.start_private_chat(
            manager_id, analyst_id, initial_message
        )
        
        # è®°å½•åˆå§‹æ¶ˆæ¯åˆ°åˆ†æå¸ˆè®°å¿†
        if analyst_memory and communication_id:
            analyst_memory.add_communication_message(
                communication_id, manager_id, initial_message
            )
        
        conversation_history = []
        current_analyst_signal = analyst_signal.copy()
        adjustments_made_counter = 0
        
        max_chars = self._get_max_chars(state)
        for round_num in range(max_rounds):
            print(f"\nç§èŠç¬¬{round_num + 1}è½®:")
            
            # åˆ†æå¸ˆå›åº”
            analyst_response = self._get_analyst_chat_response(
                analyst_id, topic, conversation_history, 
                current_analyst_signal, state
            )
            # æˆªæ–­åˆ†æå¸ˆå›åº”
            if isinstance(analyst_response, dict) and "response" in analyst_response:
                analyst_response["response"] = self._truncate_text(analyst_response["response"], max_chars)
            
            conversation_history.append({
                "speaker": analyst_id,
                "content": analyst_response["response"],
                "round": round_num + 1
            })
            
            print(f"ğŸ—£ï¸ {analyst_id}: {analyst_response['response']}")
            
            # è®°å½•åˆ†æå¸ˆå›åº”åˆ°è®°å¿†
            if analyst_memory and communication_id:
                analyst_memory.add_communication_message(
                    communication_id, analyst_id, analyst_response['response']
                )
            
            # æ£€æŸ¥æ˜¯å¦æœ‰ä¿¡å·è°ƒæ•´
            if analyst_response.get("signal_adjustment") and analyst_response.get("adjusted_signal"):
                original_signal = current_analyst_signal
                current_analyst_signal = analyst_response["adjusted_signal"]
                print(f"ä¿¡å·å·²è°ƒæ•´: {analyst_response['signal_adjustment']}")
                adjustments_made_counter += 1
                
                # è®°å½•ä¿¡å·è°ƒæ•´åˆ°è®°å¿†
                if analyst_memory and communication_id:
                    analyst_memory.record_signal_adjustment(
                        communication_id, 
                        original_signal, 
                        current_analyst_signal,
                        f"ç§èŠè®¨è®º{topic}åçš„è°ƒæ•´"
                    )
            
            # ç®¡ç†è€…å›åº”ï¼ˆå¦‚æœä¸æ˜¯æœ€åä¸€è½®ï¼‰
            if round_num < max_rounds - 1:
                manager_response = self._get_manager_chat_response(
                    manager_id, analyst_id, conversation_history, 
                    current_analyst_signal, state
                )
                manager_response = self._truncate_text(manager_response, max_chars)
                
                conversation_history.append({
                    "speaker": manager_id,
                    "content": manager_response,
                    "round": round_num + 1
                })
                
                print(f"ğŸ—£ï¸ {manager_id}: {manager_response}")
                
                # è®°å½•ç®¡ç†è€…å›åº”åˆ°è®°å¿†
                if analyst_memory and communication_id:
                    analyst_memory.add_communication_message(
                        communication_id, manager_id, manager_response
                    )
        
        print("ç§èŠç»“æŸ")
        
        # å®Œæˆé€šä¿¡è®°å½•
        if analyst_memory and communication_id:
            analyst_memory.complete_communication(communication_id)
        
        result = {
            "chat_history": conversation_history,
            "final_analyst_signal": current_analyst_signal,
            "adjustments_made": adjustments_made_counter
        }
        # æŒä¹…åŒ–å†™å…¥æ—¥å¿—
        payload = {
            "timestamp": datetime.now().isoformat(),
            "participants": [manager_id, analyst_id],
            "topic": topic,
            "result": result
        }
        self._persist_communication_result(payload, comm_type="private_chat", state=state)
        return result
    
    def conduct_meeting(self, manager_id: str, analyst_ids: List[str], 
                       topic: str, analyst_signals: Dict[str, Any], 
                       state, max_rounds: int = 2) -> Dict[str, Any]:
        """è¿›è¡Œä¼šè®®"""
        meeting_id = str(uuid.uuid4())
        print(f"å¼€å§‹ä¼šè®®: {meeting_id}")
        print(f"è¯é¢˜: {topic}")
        print(f"å‚ä¸è€…: {', '.join([manager_id] + analyst_ids)}")
        
        # ä¸ºæ¯ä¸ªåˆ†æå¸ˆè®°å½•ä¼šè®®å¼€å§‹
        communication_ids = {}
        for analyst_id in analyst_ids:
            analyst_memory = memory_manager.get_analyst_memory(analyst_id)
            if analyst_memory:
                comm_id = analyst_memory.start_communication(
                    communication_type="meeting",
                    participants=[manager_id] + analyst_ids,
                    topic=topic
                )
                communication_ids[analyst_id] = comm_id
        
        # åˆ›å»ºä¼šè®®
        self.meeting_system.create_meeting(
            meeting_id, manager_id, analyst_ids, topic
        )
        
        current_signals = analyst_signals.copy()
        meeting_transcript = []
        adjustments_made_counter = 0
        
        # ç®¡ç†è€…å¼€åœº
        opening_message = f"Let's discuss {topic}. Please share your viewpoints and analysis results."
        self.meeting_system.add_message(meeting_id, manager_id, opening_message)
        meeting_transcript.append({
            "speaker": manager_id,
            "content": opening_message,
            "round": 1
        })
        
        max_chars = self._get_max_chars(state)
        for round_num in range(max_rounds):
            print(f"\nä¼šè®®ç¬¬{round_num + 1}è½®å‘è¨€:")
            
            # è°ƒè¯•ï¼šæ‰“å°å½“å‰ä¼šè®®è®°å½•çŠ¶æ€
            if round_num > 0:
                print(f"å½“å‰ä¼šè®®è®°å½•æ¡æ•°: {len(meeting_transcript)}")
                # if meeting_transcript:
                #     print(f"æœ€åä¸€æ¡è®°å½•: {meeting_transcript[-1]}")
            
            # æ¯ä¸ªåˆ†æå¸ˆå‘è¨€
            for analyst_id in analyst_ids:
                analyst_response = self._get_analyst_meeting_response(
                    analyst_id, topic, meeting_transcript, 
                    current_signals.get(analyst_id, {}), 
                    current_signals, state, round_num + 1
                )
                # æˆªæ–­åˆ†æå¸ˆå‘è¨€
                if isinstance(analyst_response, dict) and "response" in analyst_response:
                    analyst_response["response"] = self._truncate_text(analyst_response["response"], max_chars)
                
                self.meeting_system.add_message(
                    meeting_id, analyst_id, analyst_response["response"]
                )
                
                meeting_transcript.append({
                    "speaker": analyst_id,
                    "content": analyst_response["response"],
                    "round": round_num + 1
                })
                
                # print(f"{analyst_id}: {analyst_response['response']}") 
                print(f"{analyst_id}: {analyst_response}")

                # è®°å½•å‘è¨€åˆ°åˆ†æå¸ˆè®°å¿†
                analyst_memory = memory_manager.get_analyst_memory(analyst_id)
                if analyst_memory and analyst_id in communication_ids:
                    analyst_memory.add_communication_message(
                        communication_ids[analyst_id], analyst_id, analyst_response['response']
                    )
                
                # æ£€æŸ¥ä¿¡å·è°ƒæ•´
                if analyst_response.get("signal_adjustment") and analyst_response.get("adjusted_signal"):
                    original_signal = current_signals[analyst_id]
                    current_signals[analyst_id] = analyst_response["adjusted_signal"]
                    print(f"{analyst_id} è°ƒæ•´äº†ä¿¡å·")
                    adjustments_made_counter += 1
                    
                    # è®°å½•ä¿¡å·è°ƒæ•´åˆ°è®°å¿†
                    if analyst_memory and analyst_id in communication_ids:
                        analyst_memory.record_signal_adjustment(
                            communication_ids[analyst_id],
                            original_signal,
                            analyst_response["adjusted_signal"],
                            f"ä¼šè®®è®¨è®º{topic}åçš„è°ƒæ•´"
                        )
            
            self.meeting_system.next_round(meeting_id)
        
        # ç®¡ç†è€…æ€»ç»“
        summary = self._get_manager_meeting_summary(
            manager_id, meeting_transcript, current_signals, state
        )
        summary = self._truncate_text(summary, max_chars)
        
        self.meeting_system.add_message(meeting_id, manager_id, summary)
        meeting_transcript.append({
            "speaker": manager_id,
            "content": summary,
            "round": "summary"
        })
        
        print(f"ä¼šè®®æ€»ç»“: {summary}")
        
        self.meeting_system.end_meeting(meeting_id)
        print("ä¼šè®®ç»“æŸ")
        
        # å®Œæˆæ‰€æœ‰åˆ†æå¸ˆçš„é€šä¿¡è®°å½•
        for analyst_id in analyst_ids:
            if analyst_id in communication_ids:
                analyst_memory = memory_manager.get_analyst_memory(analyst_id)
                if analyst_memory:
                    analyst_memory.complete_communication(communication_ids[analyst_id])
        
        result = {
            "meeting_id": meeting_id,
            "transcript": meeting_transcript,
            "final_signals": current_signals,
            "adjustments_made": adjustments_made_counter
        }
        # æŒä¹…åŒ–å†™å…¥æ—¥å¿—
        payload = {
            "timestamp": datetime.now().isoformat(),
            "meeting_id": meeting_id,
            "host": manager_id,
            "participants": analyst_ids,
            "topic": topic,
            "result": result
        }
        self._persist_communication_result(payload, comm_type="meeting", state=state)
        return result
    
    def _get_analyst_chat_response(self, analyst_id: str, topic: str, 
                                 conversation_history: List[Dict], 
                                 current_signal: Dict[str, Any], 
                                 state) -> Dict[str, Any]:
        """è·å–åˆ†æå¸ˆåœ¨ç§èŠä¸­çš„å›åº”"""
        
        # è·å–åˆ†æå¸ˆçš„å®Œæ•´è®°å¿†ä¸Šä¸‹æ–‡
        analyst_memory = memory_manager.get_analyst_memory(analyst_id)
        full_context = ""
        if analyst_memory:
            tickers = state.get("data", {}).get("tickers", [])
            full_context = analyst_memory.get_full_context_for_communication(tickers)
        
        prompt_template = ChatPromptTemplate.from_messages([
    ("system", """You are {analyst_id} analyst. You are having a one-on-one discussion with the portfolio manager.

Your complete memory and analysis history:
{full_context}

Based on your memory, conversation history and current analysis signal, please:
1. Respond to the manager's questions or viewpoints
2. Explain your analysis logic (you can reference your previous analysis process)
3. If necessary, adjust your signal, confidence level or reasoning based on new information

Current signal for the topic:
{current_signal}

If you need to adjust the signal, please clearly state the adjustment content and reason in your response.

Please must return your response in JSON format, strictly following the JSON structure below, do not include any other text:

Important: ticker_signals must be an object array, not a string array!

{{
  "response": "your response content",
  "signal_adjustment": true/false,
  "adjusted_signal": {{
    "analyst_id": "{analyst_id}",
    "analyst_name": "your analyst name",
    "ticker_signals": [
      {{"ticker": "AAPL", "signal": "bearish", "confidence": 85, "reasoning": "adjustment reason"}},
      {{"ticker": "MSFT", "signal": "neutral", "confidence": 70, "reasoning": "adjustment reason"}}
    ]
  }}
}}

Prohibited incorrect format:
{{"ticker_signals": ["ticker_signals: [...]"]}}

Must use correct format:
{{"ticker_signals": [{{"ticker": "AAPL", "signal": "bearish", "confidence": 85}}]}}

Note: Please keep the "response" field text content within {max_chars} characters."""),
    
    ("human", """Conversation topic: {topic}

Current conversation history:
{conversation_history}

Please respond to the latest conversation content based on your complete memory and analysis history.""")
])
        
        messages = prompt_template.format_messages(
            analyst_id=analyst_id,
            full_context=full_context,
            current_signal=quiet_json_dumps(current_signal, ensure_ascii=False),
            topic=topic,
            conversation_history=self._format_conversation_history(conversation_history),
            max_chars=self._get_max_chars(state)
        )
        
        # è·å–LLMæ¨¡å‹ï¼ˆå¯ç”¨JSONæ¨¡å¼ï¼‰
        llm = self._get_llm_model(state, use_json_mode=True)
        
        # è°ƒç”¨æ¨¡å‹
        response = llm.invoke(messages)
        
        # ä½¿ç”¨æ›´å¥å£®çš„JSONè§£ææ–¹æ³•
        try:
            # é¦–å…ˆå°è¯•ç›´æ¥è§£æ
            return json.loads(response.content)
        except json.JSONDecodeError as e:
            print(f"è­¦å‘Š: åˆ†æå¸ˆèŠå¤©å“åº”JSONè§£æå¤±è´¥: {str(e)}")
            print(f"å“åº”å†…å®¹: {response.content[:200]}...")
            
            # ä½¿ç”¨å¤‡ç”¨è§£ææ–¹æ³•
            parsed_response = self._extract_and_clean_json(response.content)
            if parsed_response:
                print("ä½¿ç”¨å¤‡ç”¨æ–¹æ³•æˆåŠŸè§£æåˆ†æå¸ˆèŠå¤©å“åº”JSON")
                return parsed_response
            else:
                print("é”™è¯¯: æ‰€æœ‰åˆ†æå¸ˆèŠå¤©å“åº”JSONè§£ææ–¹æ³•éƒ½å¤±è´¥")
                # è¿”å›é»˜è®¤å“åº”
                return {
                    "response": "è§£æå“åº”å¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤å›åº”",
                    "signal_adjustment": False
                }
    
    def _get_manager_chat_response(self, manager_id: str, analyst_id: str,
                                 conversation_history: List[Dict],
                                 current_signal: Dict[str, Any], 
                                 state) -> str:
        """è·å–ç®¡ç†è€…åœ¨ç§èŠä¸­çš„å›åº”"""
        
        prompt_template = ChatPromptTemplate.from_messages([
    ("system", """You are a portfolio manager having a one-on-one discussion with an analyst.
Based on the analyst's response, continue the conversation, ask questions or give suggestions.
Maintain a professional and constructive conversation style. Please keep your response within {max_chars} characters."""),
    
    ("human", """Conversation history:
{conversation_history}

Analyst's current signal:
{current_signal}

Please respond to the analyst's latest statement.""")
])
        
        messages = prompt_template.format_messages(
            conversation_history=self._format_conversation_history(conversation_history),
            current_signal=quiet_json_dumps(current_signal, ensure_ascii=False),
            max_chars=self._get_max_chars(state)
        )
        
        # è·å–LLMæ¨¡å‹
        llm = self._get_llm_model(state)
        
        # è°ƒç”¨æ¨¡å‹
        response = llm.invoke(messages)
        return response.content
    
    def _get_analyst_meeting_response(self, analyst_id: str, topic: str,
                                    meeting_transcript: List[Dict],
                                    current_signal: Dict[str, Any],
                                    all_signals: Dict[str, Any],
                                    state, round_num: int) -> Dict[str, Any]:
        """è·å–åˆ†æå¸ˆåœ¨ä¼šè®®ä¸­çš„å‘è¨€"""
        
        # è·å–åˆ†æå¸ˆçš„å®Œæ•´è®°å¿†ä¸Šä¸‹æ–‡
        analyst_memory = memory_manager.get_analyst_memory(analyst_id)
        full_context = ""
        if analyst_memory:
            tickers = state.get("data", {}).get("tickers", [])
            full_context = analyst_memory.get_full_context_for_communication(tickers)
        
        prompt_template = ChatPromptTemplate.from_messages([
    ("system", """You are {analyst_id} analyst participating in an investment meeting.

Your complete memory and analysis history:
{full_context}

Your current analysis signal:
{current_signal}

Please must return your response in JSON format, strictly following the JSON structure below, do not include any other text:

Important: ticker_signals must be an object array, not a string array!

{{
  "response": "your speech content",
  "signal_adjustment": true/false,
  "adjusted_signal": {{
    "analyst_id": "{analyst_id}",
    "analyst_name": "your analyst name",
    "ticker_signals": [
      {{"ticker": "AAPL", "signal": "bearish", "confidence": 85, "reasoning": "adjustment reason"}},
      {{"ticker": "MSFT", "signal": "neutral", "confidence": 70, "reasoning": "adjustment reason"}}
    ]
  }}
}}

Prohibited incorrect format:
{{"ticker_signals": ["ticker_signals: [...]"]}}

Must use correct format:
{{"ticker_signals": [{{"ticker": "AAPL", "signal": "bearish", "confidence": 85}}]}}

Note: Please keep the "response" field text content within {max_chars} characters."""),
    
    ("human", """Meeting topic: {topic}

This is round {round_num} of speeches.

Meeting transcript (Important! Please read carefully and respond):
{meeting_transcript}

Other analysts' signals:
{other_signals}

Speech requirements:
1. If this is round 1: Share your viewpoints and analysis basis
2. If this is round 2 or more:
   - Must explicitly respond to specific viewpoints from other analysts in previous rounds
   - State whether you agree or disagree with their analysis, and give reasons
   - Consider whether to adjust your signal based on discussion content
   - Avoid repeating round 1 speech content

Please speak based on meeting transcript and discussion content, showing genuine interaction and critical thinking process.""")
])
        
        messages = prompt_template.format_messages(
            analyst_id=analyst_id,
            full_context=full_context,
            round_num=round_num,
            current_signal=quiet_json_dumps(current_signal, ensure_ascii=False),
            topic=topic,
            meeting_transcript=self._format_meeting_transcript(meeting_transcript),
            other_signals=quiet_json_dumps({k: v for k, v in all_signals.items() if k != analyst_id}, ensure_ascii=False, indent=2),
            max_chars=self._get_max_chars(state)
        )
        
        # è·å–LLMæ¨¡å‹ï¼ˆå¯ç”¨JSONæ¨¡å¼ï¼‰
        llm = self._get_llm_model(state, use_json_mode=True)
        
        # è°ƒç”¨æ¨¡å‹
        response = llm.invoke(messages)
        
        # ä½¿ç”¨æ›´å¥å£®çš„JSONè§£ææ–¹æ³•
        try:
            # é¦–å…ˆå°è¯•ç›´æ¥è§£æ
            return json.loads(response.content)
        except json.JSONDecodeError as e:
            print(f"è­¦å‘Š: åˆ†æå¸ˆä¼šè®®å“åº”JSONè§£æå¤±è´¥: {str(e)}")
            print(f"å“åº”å†…å®¹: {response.content[:200]}...")
            
            # ä½¿ç”¨å¤‡ç”¨è§£ææ–¹æ³•
            parsed_response = self._extract_and_clean_json(response.content)
            if parsed_response:
                print("ä½¿ç”¨å¤‡ç”¨æ–¹æ³•æˆåŠŸè§£æåˆ†æå¸ˆä¼šè®®å“åº”JSON")
                return parsed_response
            else:
                print("é”™è¯¯: æ‰€æœ‰åˆ†æå¸ˆä¼šè®®å“åº”JSONè§£ææ–¹æ³•éƒ½å¤±è´¥")
                # è¿”å›é»˜è®¤å“åº”
                return {
                    "response": "è§£æå“åº”å¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤å›åº”",
                    "signal_adjustment": False
                }
    
    def _get_manager_meeting_summary(self, manager_id: str, 
                                   meeting_transcript: List[Dict],
                                   final_signals: Dict[str, Any], 
                                   state) -> str:
        """è·å–ç®¡ç†è€…çš„ä¼šè®®æ€»ç»“"""
        
        prompt_template = ChatPromptTemplate.from_messages([
            ("system", """You are a portfolio manager summarizing meeting content.
        Please concisely summarize discussion points and final consensus reached. Please keep the summary within {max_chars} characters."""),
            
            ("human", """Meeting transcript:
        {meeting_transcript}

        Final signals:
        {final_signals}

        Please summarize this meeting.""")
        ])
        
        messages = prompt_template.format_messages(
            meeting_transcript=self._format_meeting_transcript(meeting_transcript),
            final_signals=quiet_json_dumps(final_signals, ensure_ascii=False, indent=2),
            max_chars=self._get_max_chars(state)
        )
        
        # è·å–LLMæ¨¡å‹
        llm = self._get_llm_model(state)
        
        # è°ƒç”¨æ¨¡å‹
        response = llm.invoke(messages)
        return response.content
    
    def _format_conversation_history(self, history: List[Dict]) -> str:
        """æ ¼å¼åŒ–å¯¹è¯å†å²"""
        formatted = []
        for entry in history:
            formatted.append(f"{entry['speaker']}: {entry['content']}")
        return "\n".join(formatted)
    
    def _format_meeting_transcript(self, transcript: List[Dict]) -> str:
        """æ ¼å¼åŒ–ä¼šè®®è®°å½•"""
        formatted = []
        for entry in transcript:
            round_info = f"ç¬¬{entry['round']}è½®" if isinstance(entry['round'], int) else entry['round']
            formatted.append(f"[{round_info}] {entry['speaker']}: {entry['content']}")
        return "\n".join(formatted)
    
    def _extract_and_clean_json(self, content: str) -> Optional[Dict[str, Any]]:
        """ä»å“åº”ä¸­æå–å’Œæ¸…ç†JSON"""
        try:
            # ç§»é™¤markdownä»£ç å—
            content = re.sub(r'```json\s*\n?', '', content)
            content = re.sub(r'\n?\s*```', '', content)
            
            # æŸ¥æ‰¾JSONéƒ¨åˆ†
            json_match = re.search(r'\{.*\}', content, re.DOTALL)
            if json_match:
                json_str = json_match.group()
                
                # ç§»é™¤æ³¨é‡Š
                json_str = re.sub(r'//.*', '', json_str)
                
                # å°è¯•è§£æ
                return json.loads(json_str)
            
            # å¦‚æœæ‰¾ä¸åˆ°å®Œæ•´JSONï¼Œå°è¯•æå–å…³é”®å­—æ®µ
            response_match = re.search(r'"response"\s*:\s*"([^"]*)"', content)
            adjustment_match = re.search(r'"signal_adjustment"\s*:\s*(true|false)', content)
            
            if response_match:
                return {
                    "response": response_match.group(1),
                    "signal_adjustment": adjustment_match.group(1) == 'true' if adjustment_match else False
                }
                
        except Exception as e:
            print(f"JSONæå–è¿‡ç¨‹å‡ºé”™: {str(e)}")
            
        return None


# åˆ›å»ºå…¨å±€å®ä¾‹
communication_manager = CommunicationManager()
