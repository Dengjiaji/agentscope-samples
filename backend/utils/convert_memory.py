#!/usr/bin/env python3
"""
ä¸€æ¬¡æ€§è¿ç§»è„šæœ¬ï¼šJSONL -> SQLite
å°† reme_vector_store ç›®å½•ä¸‹çš„ .jsonl æ–‡ä»¶å¯¼å…¥åˆ° ChromaDB SQLite
"""
import os
import sys
from pathlib import Path

BASE_DIR = Path(__file__).resolve().parents[2]
sys.path.insert(0, str(BASE_DIR))

from dotenv import load_dotenv
load_dotenv()

import chromadb
from chromadb.config import Settings
from flowllm.storage.vector_store import ChromaVectorStore
from flowllm.embedding_model import OpenAICompatibleEmbeddingModel
from backend.config.path_config import get_logs_and_memory_dir

def migrate_jsonl_to_sqlite(config_name: str = "mock"):
    """ä»Ž JSONL è¿ç§»åˆ° SQLite"""
    
    # æºç›®å½•ï¼ˆJSONL æ–‡ä»¶ä½ç½®ï¼‰
    source_dir = get_logs_and_memory_dir() / config_name / "memory_data" / "reme_vector_store"
    
    if not source_dir.exists():
        print(f"âŒ Source directory not found: {source_dir}")
        return
    
    print(f"ðŸ“‚ Source directory: {source_dir}")
    
    # æŸ¥æ‰¾æ‰€æœ‰ .jsonl æ–‡ä»¶
    jsonl_files = list(source_dir.glob("*.jsonl"))
    
    if not jsonl_files:
        print("âŒ No .jsonl files found")
        return
    
    print(f"ðŸ“„ Found {len(jsonl_files)} .jsonl files\n")
    
    # åˆ›å»º embedding model
    embedding_model = OpenAICompatibleEmbeddingModel(
        dimensions=int(os.getenv("REME_EMBEDDING_DIMENSIONS", "64")),
        model_name=os.getenv("MEMORY_EMBEDDING_MODEL", "text-embedding-v4")
    )
    
    # åˆ›å»º vector store
    vector_store = ChromaVectorStore(
        embedding_model=embedding_model,
        store_dir=str(source_dir),
        batch_size=1024
    )
    
    # æ›¿æ¢ä¸º PersistentClient
    vector_store.collections.clear()
    vector_store._client = chromadb.PersistentClient(
        path=str(source_dir),
        settings=Settings(anonymized_telemetry=False)
    )
    
    print(f"ðŸ—„ï¸  Using SQLite database: {source_dir}/chroma.sqlite3\n")
    
    # é€ä¸ªå¯¼å…¥
    for jsonl_file in jsonl_files:
        workspace_id = jsonl_file.stem  # æ–‡ä»¶åä½œä¸º workspace_id
        
        print(f"ðŸ“¥ Importing: {jsonl_file.name} -> workspace '{workspace_id}'")
        
        try:
            # åŠ è½½ JSONL åˆ° vector store
            vector_store.load_workspace(workspace_id, path=str(source_dir))
            
            # æ£€æŸ¥å¯¼å…¥çš„èŠ‚ç‚¹æ•°é‡
            if vector_store.exist_workspace(workspace_id):
                nodes = list(vector_store.iter_workspace_nodes(workspace_id))
                print(f"   âœ… Imported {len(nodes)} nodes\n")
            else:
                print(f"   âš ï¸  Workspace not found after import\n")
                
        except Exception as e:
            print(f"   âŒ Error: {e}\n")
    
    # æ˜¾ç¤ºæœ€ç»ˆç»Ÿè®¡
    all_collections = vector_store._client.list_collections()
    print(f"=" * 60)
    print(f"âœ… Migration complete!")
    print(f"ðŸ“Š Total workspaces in SQLite: {len(all_collections)}")
    
    for collection in all_collections:
        count = collection.count()
        print(f"   - {collection.name}: {count} nodes")
    
    print(f"\nðŸ’¾ SQLite database: {source_dir}/chroma.sqlite3")
    print(f"=" * 60)


if __name__ == "__main__":
    # å¯ä»¥é€šè¿‡å‘½ä»¤è¡Œå‚æ•°æŒ‡å®š config_name
    config_name = sys.argv[1] if len(sys.argv) > 1 else "mock"
    
    print(f"ðŸš€ Starting JSONL -> SQLite migration")
    print(f"ðŸ“¦ Config: {config_name}\n")
    
    migrate_jsonl_to_sqlite(config_name)

